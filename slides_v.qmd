---
title: "Initiation √† Spark avec R en mode cluster"
format: revealjs
---

## Au programme

1.  MiDAS : une base de donn√©es volumineuse

2.  Utiliser MiDAS avec R : un d√©fi

3.  Sparklyr : l'outil ergonomique de spark en R

4.  Optimiser la m√©moire : pourquoi et comment

5.  Les bonnes pratiques

6.  Pour aller plus loin

# Un rapide tour de table üí¨

# MiDAS : une base de donn√©es volumineuses

## Qu'est-ce que MiDAS ?

![](/images/midas_traj_1.PNG){fig-align="right" width="900"}

![](/images/midas_traj_2.PNG){fig-align="right" width="780"}

## Une des bases les plus volumineuses du SSP {.smaller}

![](/images/donnees_ssp.PNG){fig-align="center"}

Les administrations dont les donn√©es sont comparables √† MiDAS utilisent un cluster Spark : Insee, Drees, Acoss...

‚ñ∂Ô∏èLe cluster spark est une solution la tr√®s efficiente pour traiter des donn√©es de cette ampleur.

## Concr√®tement, qu'est-ce que MiDAS ? {.smaller}

![](/images/structure_midas.png){fig-align="center"}

::: callout-tip
## Pourquoi Spark ?

La manipulation des donn√©es MiDAS en l'√©tat implique de nombreuses op√©rations de jointures qui n√©cessitent une puissance de calcul et un temps certains.
:::

## O√π est MiDAS sur la bulle ? {.smaller}

Disponible dans l'espace commun (= Documents publics) : C:\\Users\\Public\\Documents\\MiDAS_parquet\\Vague X

<br>

Au format **parquet** :

-   **compression** efficace des donn√©es : taux de compression de 5 √† 10 par rapport au format csv

-   orient√© **colonnes**

-   chargement efficace **en m√©moire** des donn√©es

-   **stockage partitionn√©** des donn√©es avec `write_dataset()`

-   traiter des donn√©es **sur disque**

-   **ind√©pendant du logiciel** utilis√© : R, python, spark...

## La documentation en ligne {.smaller}

<br>

::: columns
::: {.column width="35%"}
[Documentation en ligne](https://documentationmidas.github.io/Documentation_MiDAS/Presentation/pr%C3%A9sentation.html)

-   Dictionnaire des donn√©es

-   Fiches pr√©sentant les concepts de l'indemnisation, du retour √† l'emploi

-   Exemples d'impl√©mentation en R

-   Conseils quallit√© des variables
:::

::: {.column width="65%"}
![](/images/documentation_midas.PNG){fig-align="center"}
:::
:::

# Et vous, quels sont vos usages de MiDAS ? üëÅÔ∏è‚Äçüó®Ô∏è

# Traiter MiDAS en R : un d√©fi üë®‚Äçüíª

## Une bulle CASD {.smaller}

Des ressources partag√©es entre tous les utilsateurs simultan√©s :

-   512 Go de m√©moire vive (ou RAM) : passage √† 256 Go
-   Un processeur (ou CPU) compos√© de 32 coeurs : passage √† 16 coeurs

![](/images/schema_ordinateur.png){fig-align="center"}

## Une bulle CASD {.smaller}

::: panel-tabset
### La m√©moire vive

La m√©moire vive, aussi appel√©e **RAM**, se distingue de la m√©moire de stockage (disque) :

-   par sa **rapidit√©**, notamment pour fournir des donn√©es au processeur pour effectuer des calculs

-   par sa **volatilit√©** (toutes les donn√©es sont perdues si l'ordinateur n'est plus aliment√©)

-   par l'acc√®s direct aux informations qui y sont stock√©es, **quasi instantann√©**.

### Le processeur

Le processeur :

-   permet d'**ex√©cuter des t√¢ches et des programmes** : convertir un fichier, ex√©cuter un logiciel

-   est compos√© d'un ou de plusieurs **coeurs** : un coeur ne peut ex√©cuter qu'une seule t√¢che √† la fois. Si le processeur contient plusieurs coeurs, il peut ex√©cuter autant de t√¢ches en parall√®le qu'il a de coeurs

-   se caract√©rise aussi par sa **fr√©quence** : elle est globalement proportionnelle au nombre d'op√©rations qu'il est capable d'effetuer par seconde.
:::

## Traiter MiDAS en R : les limites

1.  Charger les donn√©es en m√©moire vive

```{r}
#| eval: false
#| echo: true
  
  path_fna <- "C:/Users/Public/Documents/MiDAS_parquet/Vague 4/FNA/"
  
  PJC <- read_parquet(paste0(path_fna, "pjc.parquet"), memory = TRUE)
  ODD <- read_parquet(paste0(path_fna, "odd.parquet"), memory = TRUE)


```

. . .

2.  R√©aliser des op√©rations co√ªteuses en ressources

```{r}
#| eval: false
#| echo: true
  
jointure <- PJC %>%
  rename(KROD1 = KROD3) %>%
  left_join(ODD, by = c("id_midas", "KROD1"))


```

. . .

3.  Le partage des ressources de la bulle

Chaque utilisateur peut mobiliser toutes les ressouces de la bulle.

## Traitement l√©ger versus co√ªteux {.smaller}

::: panel-tabset
## MAP = l√©ger {.smaller}

![](/images/formation%20sparklyr-Page-1.drawio.png){fig-align="center"}

::: notes
Ce traitement est peu co√ªteux :

-   chargement d'une seule colonne en RAM : format parquet orient√© colonnes

-   peu de m√©moire d'ex√©cution : R est un langage vectoris√©
:::

## REDUCE = co√ªteux {.smaller}

![](/images/formation%20sparklyr-Page-2.drawio.png){fig-align="center"}

::: notes
Ce traitement n√©cessite :

-   le chargement de davantage de colonnes en m√©moire vive ;

-   davantage de m√©moire d'ex√©cution pour effectuer l'intersection (`inner_join()`).
:::

## REDUCE en R

-   les jointures

-   les op√©rations en `group_by()`

-   `distinct()`

    ‚ñ∂Ô∏è Ex√©cution s√©quentielle sur un coeur du processeur + beaucoup de m√©moire vive (donn√©es temporaires)

    ‚ñ∂Ô∏è Erreur "out of memory".
:::

## Pourquoi spark ? {.smaller}

+------------------------+------------------------+----------------------------------+
| Solution test√©e        | Avantage               | Limites rencontr√©e               |
+========================+========================+==================================+
| Package ¬´ data.table ¬ª | Calculs parall√©lis√©s   | pour bases \< RAM                |
|                        |                        |                                  |
|                        |                        | Syntaxe tr√®s diff√©rente de dplyr |
+------------------------+------------------------+----------------------------------+
| Format ¬´ parquet ¬ª +   | Stockage moins lourd   | Taille en m√©moire inchang√©e      |
|                        |                        |                                  |
| package ¬´ arrow ¬ª      | Chargement efficient   |                                  |
+------------------------+------------------------+----------------------------------+
| DuckDB                 | Gestionnaire de BDD    | Pour des bases \< 100 Go         |
|                        |                        |                                  |
|                        |                        | Fonctions et options non cod√©es  |
+------------------------+------------------------+----------------------------------+
| Spark en mode local    | Traitements distribu√©s | Consomme beaucoup de ressources  |
|                        |                        |                                  |
|                        |                        | Inadapt√© pour une unique bulle   |
|                        |                        |                                  |
|                        |                        | N√©cessite le ¬´ collect() ¬ª       |
+------------------------+------------------------+----------------------------------+

## Un gain de temps consid√©rable {.smaller}

<br>

+---------------------+-----------------------------------------+---------------------------------------------+
|                     | Calcul de la dur√©e moyenne d'un contrat | Retour √† l'emploi salari√© des indemnisables |
+=====================+=========================================+=============================================+
| Classique R         | 4 heures                                | Crash                                       |
+---------------------+-----------------------------------------+---------------------------------------------+
| Arrow + duckdb      | 8 minutes                               | 3 heures seul sur la bulle                  |
+---------------------+-----------------------------------------+---------------------------------------------+
| Arrow + spark local | 1 minute                                | 2 minutes                                   |
+---------------------+-----------------------------------------+---------------------------------------------+

Mais alors, pourquoi le cluster ? ü§î

# Et vous, quels sont vos probl√©matiques et vos solutions ? ‚ö†Ô∏è

# Comment on fait du spark cluster avec R version courte ? ‚è≤Ô∏è

## O√π est Midas, 2√®me √©dition {.smaller}

Le cluster a son propre explorateur de fichiers √† mettre en favori dans son navigateur : https://midares-deb11-nn-01.midares.local:9870/

::: r-stack
![](/images/hdfs_browse.png){.fragment fig-align="center" width="900" height="500"}

![](/images/hdfs_midas.png){.fragment fig-align="center" width="900" height="500"}
:::

## Un cluster de calcul

![](/images/schema_cluster.drawio.png){fig-align="center"}

## Connexion

::: panel-tabset
## Traitement l√©ger

```{r}
#| eval: false
#| echo: true

conf <- spark_config()
conf["spark.driver.memory"] <- "40Go"
conf["spark.executor.memory"] <- "60Go"
conf["spark.executor.cores"] <- 4
conf["spark.executor.instances"] <- 2
cont["spark.yarn.queue"] <- "prod"
conf["spark.driver.maxResultSize"] <- 0
conf["spark.sql.shuffle.partitions"] <- 200

sc <- spark_connect(master = "yarn", config = conf)
```

## Traitement lourd

```{r}
#| eval: false
#| echo: true

library(sparklyr)
library(dplyr)
library(dbplyr)

conf <- spark_config()
conf["spark.driver.memory"] <- "40Go"
conf["spark.executor.memory"] <- "140Go"
conf["spark.executor.cores"] <- 8
conf["spark.executor.instances"] <- 2
cont["spark.yarn.queue"] <- "prod"
conf["spark.driver.maxResultSize"] <- 0
conf["spark.sql.shuffle.partitions"] <- 200

sc <- spark_connect(master = "yarn", config = conf)
```
:::

## Chargement des donn√©es en spark

<br>

```{r}
#| eval: false
#| echo: true

### Depuis HDFS
mmo_17_df_spark <- spark_read_parquet(sc,
                                  path = "hdfs:///dataset/MiDAS_v4/mmo/mmo_2017.parquet",
                                  memory = FALSE)

### Passer un dataframe R en spark
mon_data_frame <- data.frame(c("Anna", "Paul"), c(15, 20))
mon_data_frame_spark <- copy_to(sc, "mon_data_frame")
```

<br>

‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : par d√©faut, `memory = FALSE`

## Sparklyr, c'est comme dplyr

Ensuite, vous pouvez programmer avec `dplyr` !

```{r}
#| eval: false
#| echo: true

mmo_17_df_spark <- mmo_17_df_spark %>%
  rename(debut_contrat = DebutCTT) %>%
  filter(debut_contrat >= as.Date("2017-01-01") & debut_contrat < as.Date("2017-02-01")) %>%
  mutate(mois_debut_contrat = substr(debut_contrat,6,7))


```

## La lazy evaluation {.smaller}

Spark distingue deux types d'op√©rations :

-   **les transformations :** prennent en entr√©e un `spark_data_frame` et retournent un `spark_data_frame`, elles ne d√©clenchent aucun calcul

    Par exemple, le programme ci-dessous ne d√©clenche pas d'ex√©cution :

```{r}
#| eval: false
#| echo: true

mmo_17_df_spark_mois <- mmo_17_df_spark %>%
  rename(debut_contrat = DebutCTT) %>%
  filter(debut_contrat >= as.Date("2017-01-01") & debut_contrat < as.Date("2017-06-01")) %>%
  mutate(mois_debut_contrat = substr(debut_contrat,6,7))


```

-   **les actions :** forcent le calcul d'un r√©sultat pour le r√©cup√©rer et d√©clenchent l'ex√©cution de toutes les transformations compil√©es jusqu'√† l'appel de l'action.

    Par exemple, le programme ci-dessous d√©clenche le calcul de toute la cellule pr√©c√©dente :

```{r}
#| eval: false
#| echo: true

nb_debut_contrat_fev_17 <- mmo_17_df_spark_mois %>%
  group_by(mois_debut_contrat) %>%
  summarise(nb_contrats = n()) %>%
  print()

```

## R√©cup√©rer un r√©sultat

Les principales actions sont :

-   `print()`

-   `collect()`

-   `head()`

-   `tbl_cache()` (√©crire un `spark_data_frame` en m√©moire pour le r√©utiliser)

## ... presque tout comme dplyr {.smaller .scrollable}

::: panel-tabset
## Dates

Les fonctions de `lubridate()`ne sont pas adapt√©es au `spark_data_frames`.

-   Convertir une cha√Æne de caract√®re de la forme AAAA-MM-DD en Date

    ```{r}
    #| eval: false
    #| echo: true

    date_1 <- as.Date("2024-05-26")

    ```

-   Calculer une dur√©e entre deux dates

    ```{r}
    #| eval: false
    #| echo: true

    PJC_spark <- spark_read_parquet(sc,
                                    path = "hdfs:///dataset/MiDAS_v4/pjc.parquet",
                                    memory = FALSE)

    duree_pjc_df <- PJC_spark %>%
      rename(date_fin_pjc = as.Date(KDFPJ),
             date_deb_pjc = as.Date(KDDPJ)) %>%
      mutate(duree_pjc = datediff(date_fin_pjc, date_deb_pjc) + 1) %>%
      head(5)

    ```

-   Ajouter ou soustraire des jours ou des mois √† une date

    ```{r}
    #| eval: false
    #| echo: true


    duree_pjc_bis_df <- duree_pjc_df %>%
      mutate(duree_pjc_plus_5 = date_add(duree_pjc, int(5)),
             duree_pjc_moins_5 = date_sub(duree_pjc, int(5)),
             duree_pjc_plus_1_mois = add_months(duree_pjc, int(1))) %>%
      head(5)

    ```

::: callout-note
## Add_months

Si la date en entr√©e est le dernier jour d'un mois, la date retourn√©e avec `add_months(date_entree, int(1))` sera le dernier jour calendaire du mois suivant.
:::

::: callout-tip
## Format

Le `int()` est important car ces fonctions Hive n'accepte que les entiers pour l'ajout de jours : taper uniquement 5 est consid√©r√© comme un flottant dans R.
:::

## Tableau

-   Tri dans un groupe pour effectuer un calcul s√©quentiel

    ```{r}
    #| eval: false
    #| echo: true

    ODD_spark <- spark_read_parquet(sc,
                                    path = "hdfs:///dataset/MiDAS_v4/odd.parquet",
                                    memory = FALSE)

    ODD_premier <- ODD_spark %>%
      group_by(id_midas) %>%
      window_order(id_midas, KDPOD) %>%
      mutate(date_premier_droit = first(KDPOD)) %>%
      ungroup() %>%
      distinct(id_midas, KROD3, date_premier_droit) %>%
      head(5)
      
    ```

-   Tri pour une sortie : `sdf_sort()` , `arrange()` ne fonctionne pas

-   Concat√©ner les lignes (ou les colonnes `sdf_bind_cols()`)

    ```{r}
    #| eval: false
    #| echo: true

    ODD_1 <- ODD_spark %>%
      filter(KDPOD <= as.Date("2017-12-31")) %>%
      mutate(groupe = "temoins")

    ODD_2 <- ODD_spark %>%
      filter(KDPOD >= as.Date("2021-12-31")) %>%
      mutate(groupe = "traites")

    ODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)

    ```

-   D√©doublonner une table

    ```{r}
    #| eval: false
    #| echo: true

    droits_dans_PJC <- PJC_spark %>%
      sdf_distinct(id_midas, KROD3)

    print(head(droits_dans_PJC, 5))

    PJC_dedoublonnee <- PJC_spark %>%
      sdf_drop_duplicates()

    print(head(PJC_dedoublonnee, 5))

    ```

-   Pivot : les fonctions du packag `tidyr` ne fonctionnent pas sur donn√©es spark

    ```{r}
    #| eval: false
    #| echo: true

    ODD_sjr_moyen <- ODD_spark %>%
      mutate(groupe = ifelse(KDPOD <= as.Date("2020-12-31"), "controles", "traites")) %>%
      sdf_pivot(groupe ~ KCRGC,
        fun.aggregate = list(KQCSJP = "mean")
      )
    ```

## Statistiques

-   R√©sum√© statistique : `sdf_describe()` , `summary()`ne fonctionne pas.

-   Dimension : `sdf_dim`, la fonction `nrow()`ne fonctionne pas.

-   Quantiles approximatifs : le calcul des quantiles sur donn√©es distirbu√©es renvoie une approximation car toutes les donn√©es ne peuvent pas √™tre rappatri√©es sur la m√™me machine physique du fait de la volum√©trie, `sdf_quantile()`

-   Echantillonnage al√©atoire : `sdf_random_split`
:::

## Exporter des donn√©es {.smaller}

Export des spark data frames directement sous HDFS.

```{r}
#| eval: false
#| echo: true

ma_table <- data.frame(c("Anne", "Paul"), c(25,30))

ma_table_spark <- copy_to(sc, ma_table)

spark_write_parquet(ma_table_spark, "hdfs:///resultats/ma_table.parquet")

```

Possibilit√© de r√©cup√©rer ce fichier sur la bulle MiDARES = en local.

::: callout-warning
## Exports simultan√©s

HDFS supporte les exports simultan√©s, mais le temp d'export est plus long lorsque le NameNode est requ√™t√© par plusieurs personnes simultan√©ment : d'apr√®s les tests cluster

-   pour un petit export (5 minutes), le temps peut √™tre multipli√© par 4 ;

-   pour un gros export (15 minutes), le temps peut √™tre multipli√© par 2.
:::

## Si on souhaite la r√©cup√©rer en local

::: callout-caution
## Les exports sur HDFS

Lorsqu'on exporte une table depuis notre session R vers HDFS, celle-ci est **automatiquement partitionn√©e**, comme le reste des donn√©es.

Ainsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.

Il est possible de ma√Ætriser le nombre de partitions avec la commande `sdf_coalesce(partitions = 5)` du package `sparklyr`.

L'id√©al est d'**adapter le nombre de partitions √† la taille d'un bloc** : un bloc mesure 128 MB. Lorsqu'un bloc disque est utilis√©, m√™me √† 1%, il n'est pas utilisable pour un autre stockage.

Exporter un fichier de 1MB en 200 partitions r√©serve 200 blocs inutilement.
:::


## T√©l√©charger des donn√©es en local {.smaller}

::: r-stack
![](images/hdfs_browse.png){.fragment width="1000" height="700"}

![](/images/hdfs_dowload.PNG){.fragment}
:::

# Optimiser le code : non ! Mais optimiser la m√©moire...

## Pas besoin d'optimiser son code !

## La m√©moire du driver

## Programmer sans collecter

## Cacher une table


# Les bonnes pratiques

## Spark local : non

## Inutile de prendre toutes les ressources 

## Fermer sa session

## Mutualiser les exp√©riences


# Pour aller plus loin

## Partitionnement

Le format `.parquet` (avec `arrow`) et le framework `spark` permettent de g√©rer le partitionnement des donn√©es.

Si les op√©rations sont souvent effectu√©es par r√©gions par exemple, il est utile de forcer le stockage des donn√©es d'une m√™me r√©gion au m√™me endroit physique et acc√©l√®re drastiquement le temps de calcul :

```{r}
#| eval: false
#| echo: true

spark_write_parquet(ma_table, "hdfs:///resultats/ma_table.parquet", partition_by = c("region"))

```

## SparkUI

## Yarn

## Pyspark