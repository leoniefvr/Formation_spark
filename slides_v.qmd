---
title: "Initiation √† Spark avec R en mode cluster"
format: revealjs
---

## Au programme

1.  MiDAS : une base de donn√©es volumineuse

2.  Utiliser MiDAS avec R : un d√©fi

3.  Sparklyr : l'outil ergonomique de spark en R

4.  Optimiser la m√©moire : pourquoi et comment

5.  Les bonnes pratiques

6.  Pour aller plus loin

# Un rapide tour de table üí¨

# MiDAS : une base de donn√©es volumineuses

## Qu'est-ce que MiDAS ?

![](/images/midas_traj_1.PNG){fig-align="right" width="900"}

![](/images/midas_traj_2.PNG){fig-align="right" width="780"}

## Une des bases les plus volumineuses du SSP {.smaller}

![](/images/donnees_ssp.PNG){fig-align="center"}

Les administrations dont les donn√©es sont comparables √† MiDAS utilisent un cluster Spark : Insee, Drees, Acoss...

‚ñ∂Ô∏èLe cluster spark est une solution la tr√®s efficiente pour traiter des donn√©es de cette ampleur.

## Concr√®tement, qu'est-ce que MiDAS ? {.smaller}

![](/images/structure_midas.png){fig-align="center"}

::: callout-tip
## Pourquoi Spark ?

La manipulation des donn√©es MiDAS en l'√©tat implique de nombreuses op√©rations de jointures qui n√©cessitent une puissance de calcul et un temps certains.
:::

## O√π est MiDAS sur la bulle ? {.smaller}

Disponible dans l'espace commun (= Documents publics) : C:\\Users\\Public\\Documents\\MiDAS_parquet\\Vague X

<br>

Au format **parquet** :

-   **compression** efficace des donn√©es : taux de compression de 5 √† 10 par rapport au format csv

-   orient√© **colonnes**

-   chargement efficace **en m√©moire** des donn√©es

-   **stockage partitionn√©** des donn√©es avec `write_dataset()`

-   traiter des donn√©es **sur disque**

-   **ind√©pendant du logiciel** utilis√© : R, python, spark...

## La documentation en ligne {.smaller}

<br>

::: columns
::: {.column width="35%"}
[Documentation en ligne](https://documentationmidas.github.io/Documentation_MiDAS/Presentation/pr%C3%A9sentation.html)

-   Dictionnaire des donn√©es

-   Fiches pr√©sentant les concepts de l'indemnisation, du retour √† l'emploi

-   Exemples d'impl√©mentation en R

-   Conseils quallit√© des variables
:::

::: {.column width="65%"}
![](/images/documentation_midas.PNG){fig-align="center"}
:::
:::

# Et vous, quels sont vos usages de MiDAS ? üëÅÔ∏è‚Äçüó®Ô∏è

# Traiter MiDAS en R : un d√©fi üë®‚Äçüíª

## Une bulle CASD {.smaller}

Des ressources partag√©es entre tous les utilsateurs simultan√©s :

-   512 Go de m√©moire vive (ou RAM) : passage √† 256 Go
-   Un processeur (ou CPU) compos√© de 32 coeurs : passage √† 16 coeurs

![](/images/schema_ordinateur.png){fig-align="center"}

::: notes
Bulle CASD = un gros ordinateur partag√© par plusieurs utilisateurs, besoin du voc ordinateur pour comprendre spark
:::

## Une bulle CASD {.smaller}

::: panel-tabset
### La m√©moire vive

La m√©moire vive, aussi appel√©e **RAM**, se distingue de la m√©moire de stockage (disque) :

-   par sa **rapidit√©**, notamment pour fournir des donn√©es au processeur pour effectuer des calculs

-   par sa **volatilit√©** (toutes les donn√©es sont perdues si l'ordinateur n'est plus aliment√©)

-   par l'acc√®s direct aux informations qui y sont stock√©es, **quasi instantann√©**.

### Le processeur

Le processeur :

-   permet d'**ex√©cuter des t√¢ches et des programmes** : convertir un fichier, ex√©cuter un logiciel

-   est compos√© d'un ou de plusieurs **coeurs** : un coeur ne peut ex√©cuter qu'une seule t√¢che √† la fois. Si le processeur contient plusieurs coeurs, il peut ex√©cuter autant de t√¢ches en parall√®le qu'il a de coeurs

-   se caract√©rise aussi par sa **fr√©quence** : elle est globalement proportionnelle au nombre d'op√©rations qu'il est capable d'effetuer par seconde.
:::

## Traiter MiDAS en R : les limites

1.  Charger les donn√©es en m√©moire vive

```{r}
#| eval: false
#| echo: true
  
  path_fna <- "C:/Users/Public/Documents/MiDAS_parquet/Vague 4/FNA/"
  
  PJC <- read_parquet(paste0(path_fna, "pjc.parquet"), memory = TRUE)
  ODD <- read_parquet(paste0(path_fna, "odd.parquet"), memory = TRUE)


```

. . .

2.  R√©aliser des op√©rations co√ªteuses en ressources

```{r}
#| eval: false
#| echo: true
  
jointure <- PJC %>%
  rename(KROD1 = KROD3) %>%
  left_join(ODD, by = c("id_midas", "KROD1"))


```

. . .

3.  Le partage des ressources de la bulle

Chaque utilisateur peut mobiliser toutes les ressouces de la bulle.

::: notes
Donn√©es \> RAM et R fonctionne dans la m√©moire vive (pour √ßa que plus rapide que SAS) Jointures co√ªteux : on va voir pourquoi apr√®s tlm sur la m√™me bulle sans allocation des ressources = ralentissements
:::

## Traitement l√©ger versus co√ªteux {.smaller}

::: panel-tabset
## MAP = l√©ger {.smaller}

![](/images/formation%20sparklyr-Page-1.drawio.png){fig-align="center"}

::: notes
Ce traitement est peu co√ªteux :

-   chargement d'une seule colonne en RAM : format parquet orient√© colonnes

-   peu de m√©moire d'ex√©cution : R est un langage vectoris√©
:::

## REDUCE = co√ªteux {.smaller}

![](/images/formation%20sparklyr-Page-2.drawio.png){fig-align="center"}

::: notes
Ce traitement n√©cessite :

-   le chargement de davantage de colonnes en m√©moire vive ;

-   davantage de m√©moire d'ex√©cution pour effectuer l'intersection (`inner_join()`).
:::

## REDUCE en R

-   les jointures

-   les op√©rations en `group_by()`

-   les op√©rations de tri avec `arrange()`

-   `distinct()`

    ‚ñ∂Ô∏è Ex√©cution s√©quentielle sur un coeur du processeur + beaucoup de m√©moire vive (donn√©es temporaires)

    ‚ñ∂Ô∏è Erreur "out of memory".
:::

::: notes
Parquet orient√© colonne donc ne charge que les colonnes n√©cessaires en m√©moire R vectoris√© : op√©ration appliqu√©e √† tout le vecteur = traitement rapide

Jointure co√ªteuse parce que comparaison ligne √† ligne

window funcions
:::

## Pourquoi spark ? {.smaller}

+------------------------+------------------------+----------------------------------+
| Solution test√©e        | Avantage               | Limites rencontr√©e               |
+========================+========================+==================================+
| Package ¬´ data.table ¬ª | Calculs parall√©lis√©s   | pour bases \< RAM                |
|                        |                        |                                  |
|                        |                        | Syntaxe tr√®s diff√©rente de dplyr |
+------------------------+------------------------+----------------------------------+
| Format ¬´ parquet ¬ª +   | Stockage moins lourd   | Taille en m√©moire inchang√©e      |
|                        |                        |                                  |
| package ¬´ arrow ¬ª      | Chargement efficient   |                                  |
+------------------------+------------------------+----------------------------------+
| DuckDB                 | Gestionnaire de BDD    | Pour des bases \< 100 Go         |
|                        |                        |                                  |
|                        |                        | Fonctions et options non cod√©es  |
+------------------------+------------------------+----------------------------------+
| Spark en mode local    | Traitements distribu√©s | Consomme beaucoup de ressources  |
|                        |                        |                                  |
|                        |                        | Inadapt√© pour une unique bulle   |
|                        |                        |                                  |
|                        |                        | N√©cessite le ¬´ collect() ¬ª       |
+------------------------+------------------------+----------------------------------+

## Un gain de temps consid√©rable {.smaller}

<br>

+---------------------+-----------------------------------------------------------------------------+---------------------------------------------+
|                     | Calcul de la dur√©e moyenne du premier contrat pour tous les individus MiDAS | Retour √† l'emploi salari√© des indemnisables |
+=====================+=============================================================================+=============================================+
| Classique R         | 4 heures                                                                    | Crash                                       |
+---------------------+-----------------------------------------------------------------------------+---------------------------------------------+
| Arrow + duckdb      | 8 minutes                                                                   | 3 heures seul sur la bulle                  |
+---------------------+-----------------------------------------------------------------------------+---------------------------------------------+
| Arrow + spark local | 1 minute                                                                    | 2 minutes                                   |
+---------------------+-----------------------------------------------------------------------------+---------------------------------------------+

Mais alors, pourquoi le cluster ? ü§î

## Une bonne allocation des ressources entre utilisateurs

::: r-stack
![](/images/mode_local.PNG){.fragment fig-align="center" width="1000" height="450"}

![](/images/mode_cluster.PNG){.fragment fig-align="center" width="1000" height="450"}
:::

# Et vous, quels sont vos probl√©matiques et vos solutions ? ‚ö†Ô∏è

# Comment on fait du spark cluster avec R version courte ? ‚è≤Ô∏è

## O√π est Midas, 2√®me √©dition {.smaller}

Le cluster a son propre explorateur de fichiers √† mettre en favori dans son navigateur : https://midares-deb11-nn-01.midares.local:9870/

::: r-stack
![](/images/hdfs_browse.png){.fragment fig-align="center" width="900" height="500"}

![](/images/hdfs_midas.png){.fragment fig-align="center" width="900" height="500"}
:::

## Un cluster de calcul

![](/images/schema_cluster.drawio.png){fig-align="center"}

## Connexion

::: panel-tabset
## Traitement l√©ger

```{r}
#| eval: false
#| echo: true

library(sparklyr)
library(dplyr)
library(dbplyr)

conf <- spark_config()
conf["spark.driver.memory"] <- "20Go"
conf["spark.executor.memory"] <- "60Go"
conf["spark.executor.cores"] <- 4
conf["spark.executor.instances"] <- 2
cont["spark.yarn.queue"] <- "prod"
conf["spark.driver.maxResultSize"] <- 0
conf["spark.sql.shuffle.partitions"] <- 200

sc <- spark_connect(master = "yarn", config = conf)
```

## Traitement lourd

```{r}
#| eval: false
#| echo: true

library(sparklyr)
library(dplyr)
library(dbplyr)

conf <- spark_config()
conf["spark.driver.memory"] <- "20Go"
conf["spark.executor.memory"] <- "140Go"
conf["spark.executor.cores"] <- 8
conf["spark.executor.instances"] <- 2
cont["spark.yarn.queue"] <- "prod"
conf["spark.driver.maxResultSize"] <- 0
conf["spark.sql.shuffle.partitions"] <- 200

sc <- spark_connect(master = "yarn", config = conf)
```
:::

## Chargement des donn√©es en spark

<br>

```{r}
#| eval: false
#| echo: true

### Depuis HDFS
mmo_17_df_spark <- spark_read_parquet(sc,
                                  path = "hdfs:///dataset/MiDAS_v4/mmo/mmo_2017.parquet",
                                  memory = FALSE)

### Passer un dataframe R en spark
mon_data_frame <- data.frame(c("Anna", "Paul"), c(15, 20))
mon_data_frame_spark <- copy_to(sc, "mon_data_frame")
```

<br>

‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : par d√©faut, `memory = FALSE`

## Sparklyr, c'est comme dplyr

<br>

Ensuite, vous pouvez programmer avec `dplyr` !

```{r}
#| eval: false
#| echo: true

mmo_17_df_spark <- mmo_17_df_spark %>%
  rename(debut_contrat = DebutCTT) %>%
  filter(debut_contrat >= as.Date("2017-01-01") & debut_contrat < as.Date("2017-02-01")) %>%
  mutate(mois_debut_contrat = substr(debut_contrat,6,7))


```

## La lazy evaluation {.smaller}

Spark distingue deux types d'op√©rations :

-   **les transformations :** prennent en entr√©e un `spark_data_frame` et retournent un `spark_data_frame`, elles ne d√©clenchent aucun calcul

    Par exemple, le programme ci-dessous ne d√©clenche pas d'ex√©cution :

```{r}
#| eval: false
#| echo: true

mmo_17_df_spark_mois <- mmo_17_df_spark %>%
  rename(debut_contrat = DebutCTT) %>%
  filter(debut_contrat >= as.Date("2017-01-01") & debut_contrat < as.Date("2017-06-01")) %>%
  mutate(mois_debut_contrat = substr(debut_contrat,6,7))


```

-   **les actions :** forcent le calcul d'un r√©sultat pour le r√©cup√©rer et d√©clenchent l'ex√©cution de toutes les transformations compil√©es jusqu'√† l'appel de l'action.

    Par exemple, le programme ci-dessous d√©clenche le calcul de toute la cellule pr√©c√©dente :

```{r}
#| eval: false
#| echo: true

nb_debut_contrat_fev_17 <- mmo_17_df_spark_mois %>%
  group_by(mois_debut_contrat) %>%
  summarise(nb_contrats = n()) %>%
  print()

```

## La lazy evaluation : un gain de temps consid√©rable

<br>

::: callout-tip
## La gestion des erreurs

En r√©alit√©, lorsqu'on appuie ysur le bouton `run`, il ne se passe pas "rien". Le code est compil√© par spark : les erreurs sont rep√©r√©es avant m√™me que le code soit ex√©cut√© !
:::

INSERER EXEMPLE ERREUR REPEREE A LA COMPILATION

## R√©cup√©rer un r√©sultat

Les principales actions sont :

-   `print()`

-   `collect()`

-   `head()`

-   `tbl_cache()` (√©crire un `spark_data_frame` en m√©moire pour le r√©utiliser)

## ... presque tout comme dplyr {.smaller .scrollable}

La majorit√© des commandes `dplyr` fonctionnent sur un spark_data_frame avec le package `sparklyr`. Les divergences principales sont les suivantes :

+--------------------------------+----------------+----------------------------------+
| Fonctionnalit√©                 | tidyverse      | sparklyr                         |
+================================+================+==================================+
| import d'un fichier `.parquet` | `read_parquet` | `spark_read_parquet()`           |
+--------------------------------+----------------+----------------------------------+
| tri d'un tableau               | `arrange()`    | `window_order()` ou `sdf_sort()` |
+--------------------------------+----------------+----------------------------------+
| op√©rations sur les dates       | `lubridate`    | fonctions Hive                   |
+--------------------------------+----------------+----------------------------------+
| empiler des tableaux           | `bind_rows()`  | `sdf_bind_rows()`                |
+--------------------------------+----------------+----------------------------------+
| nombre de lignes d'un tableau  | `nrow()`       | `sdf_nrow()`                     |
+--------------------------------+----------------+----------------------------------+
| faire pivoter un tableau       | `tidyr`        | `sdf_pivot()`                    |
+--------------------------------+----------------+----------------------------------+
| export d'un `spark_data_frame` |                | `spark_write_parquet()`          |
+--------------------------------+----------------+----------------------------------+

## Quelques fonctions sp√©cifiques {.smaller .scrollable}

::: panel-tabset
## Dates

Les fonctions de `lubridate()`ne sont pas adapt√©es au `spark_data_frames`.

-   Convertir une cha√Æne de caract√®re de la forme AAAA-MM-DD en Date

    ```{r}
    #| eval: false
    #| echo: true

    date_1 <- as.Date("2024-05-26")

    ```

-   Calculer une dur√©e entre deux dates

    ```{r}
    #| eval: false
    #| echo: true

    PJC_spark <- spark_read_parquet(sc,
                                    path = "hdfs:///dataset/MiDAS_v4/pjc.parquet",
                                    memory = FALSE)

    duree_pjc_df <- PJC_spark %>%
      rename(date_fin_pjc = as.Date(KDFPJ),
             date_deb_pjc = as.Date(KDDPJ)) %>%
      mutate(duree_pjc = datediff(date_fin_pjc, date_deb_pjc) + 1) %>%
      head(5)

    ```

-   Ajouter ou soustraire des jours ou des mois √† une date

    ```{r}
    #| eval: false
    #| echo: true


    duree_pjc_bis_df <- duree_pjc_df %>%
      mutate(duree_pjc_plus_5 = date_add(duree_pjc, int(5)),
             duree_pjc_moins_5 = date_sub(duree_pjc, int(5)),
             duree_pjc_plus_1_mois = add_months(duree_pjc, int(1))) %>%
      head(5)

    ```

::: callout-note
## Add_months

Si la date en entr√©e est le dernier jour d'un mois, la date retourn√©e avec `add_months(date_entree, int(1))` sera le dernier jour calendaire du mois suivant.
:::

::: callout-tip
## Format

Le `int()` est important car ces fonctions Hive n'accepte que les entiers pour l'ajout de jours : taper uniquement 5 est consid√©r√© comme un flottant dans R.
:::

## Tableau

-   Tri dans un groupe pour effectuer un calcul s√©quentiel

    ```{r}
    #| eval: false
    #| echo: true

    ODD_spark <- spark_read_parquet(sc,
                                    path = "hdfs:///dataset/MiDAS_v4/odd.parquet",
                                    memory = FALSE)

    ODD_premier <- ODD_spark %>%
      group_by(id_midas) %>%
      window_order(id_midas, KDPOD) %>%
      mutate(date_premier_droit = first(KDPOD)) %>%
      ungroup() %>%
      distinct(id_midas, KROD3, date_premier_droit) %>%
      head(5)
      
    ```

-   Tri pour une sortie : `sdf_sort()` , `arrange()` ne fonctionne pas

-   Concat√©ner les lignes (ou les colonnes `sdf_bind_cols()`)

    ```{r}
    #| eval: false
    #| echo: true

    ODD_1 <- ODD_spark %>%
      filter(KDPOD <= as.Date("2017-12-31")) %>%
      mutate(groupe = "temoins")

    ODD_2 <- ODD_spark %>%
      filter(KDPOD >= as.Date("2021-12-31")) %>%
      mutate(groupe = "traites")

    ODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)

    ```

-   D√©doublonner une table

    ```{r}
    #| eval: false
    #| echo: true

    droits_dans_PJC <- PJC_spark %>%
      sdf_distinct(id_midas, KROD3)

    print(head(droits_dans_PJC, 5))

    PJC_dedoublonnee <- PJC_spark %>%
      sdf_drop_duplicates()

    print(head(PJC_dedoublonnee, 5))

    ```

-   Pivot : les fonctions du packag `tidyr` ne fonctionnent pas sur donn√©es spark

    ```{r}
    #| eval: false
    #| echo: true

    ODD_sjr_moyen <- ODD_spark %>%
      mutate(groupe = ifelse(KDPOD <= as.Date("2020-12-31"), "controles", "traites")) %>%
      sdf_pivot(groupe ~ KCRGC,
        fun.aggregate = list(KQCSJP = "mean")
      )
    ```

## Statistiques

-   R√©sum√© statistique : `sdf_describe()` , `summary()`ne fonctionne pas.

-   Dimension : `sdf_dim`, la fonction `nrow()`ne fonctionne pas.

-   Quantiles approximatifs : le calcul des quantiles sur donn√©es distirbu√©es renvoie une approximation car toutes les donn√©es ne peuvent pas √™tre rappatri√©es sur la m√™me machine physique du fait de la volum√©trie, `sdf_quantile()`

-   Echantillonnage al√©atoire : `sdf_random_split`
:::

## Exporter des donn√©es {.smaller}

Export des spark data frames directement sous HDFS : √† aucun moment on n'ouvre la table : on peut traiter des donn√©es beaucoup plus volumnieuses que la m√©moire RAM !

```{r}
#| eval: false
#| echo: true

ma_table <- data.frame(c("Anne", "Paul"), c(25,30))

ma_table_spark <- copy_to(sc, ma_table)

spark_write_parquet(ma_table_spark, "hdfs:///resultats/ma_table.parquet")

```

Possibilit√© de r√©cup√©rer ce fichier sur la bulle MiDARES = en local.

::: callout-warning
## Exports simultan√©s

HDFS supporte les exports simultan√©s, mais le temp d'export est plus long lorsque le NameNode est requ√™t√© par plusieurs personnes simultan√©ment : d'apr√®s les tests cluster

-   pour un petit export (5 minutes), le temps peut √™tre multipli√© par 4 ;

-   pour un gros export (15 minutes), le temps peut √™tre multipli√© par 2.
:::

## Si on souhaite la r√©cup√©rer en local {.smaller}

::: callout-caution
## Les exports sur HDFS

Lorsqu'on exporte une table depuis notre session R vers HDFS, celle-ci est **automatiquement partitionn√©e**, comme le reste des donn√©es.

Ainsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.

Il est possible de ma√Ætriser le nombre de partitions avec la commande `sdf_coalesce(partitions = 1)` du package `sparklyr`.

Avec `sdf_coalesce(partitions = 1)`, on n'aura qu'un seul fichier √† t√©l√©charger depuis HDFS.

Avec `sdf_coalesce(partitions = 200)`, on aura 200 morceaux de notre fichier √† t√©l√©charger √† la main (pas possible de faire tout s√©lectionner sous HDFS !).

L'id√©al est d'**adapter le nombre de partitions √† la taille d'un bloc** : un bloc mesure 128 MB.
:::

```{r}
#| eval: false
#| echo: true

ma_table <- data.frame(c("Anne", "Paul"), c(25,30))

ma_table_spark <- copy_to(sc, ma_table) %>%
  sdf_coalesce(partitions = 1)

spark_write_parquet(ma_table_spark, "hdfs:///resultats/ma_table.parquet")
```

## T√©l√©charger des donn√©es en local {.smaller}

::: r-stack
![](images/hdfs_browse.png){.fragment width="1000" height="700"}

![](/images/hdfs_dowload.PNG){.fragment}
:::

## Et ensuite ? {.smaller}

Spark est un outil de traitement de donn√©es volumineuses. Il n'est pas toujours adapt√© :

-   pour de toutes petites tables : il ne va pas engendrer de gain de temps

-   pour faire de l'√©conom√©trie pouss√©e : tous les packages R ne sont pas traduits en spark

-   pour ouvrir sa table : on perd les avantages de spark si on collecte toute la table en m√©moire RAM

Conseils :

1.  Cr√©er sa table d'√©tude en appariant les tables de MiDAS avec le cluster spark

2.  L'exporter sous HDFS

3.  La t√©l√©charger en local

4.  La charger en R classique pour faire de l'√©conom√©trie

# Optimiser le code : non ! Mais optimiser la m√©moire...

## Comment fonctionne spark ? {.smaller}

-   Apache Spark : **librairie open source** d√©velopp√©e dans le langage `scala`

    ```{r}
    #| eval: false
    #| echo: true

    val TopHorrorsIGN2022 = Seq(
      (9, "Pearl"),
      (6, "The Sadness"),
      (6, "Offseason"),
      (7, "Hatching"),
      (8, "x")
    ).toDF("IMDB Rating", "IGN Movie Picks")

    import org.apache.spark.sql.functions.col

    val cols = List(col("IGN Movie Picks"), col("AVC Movie Picks"))

    val query = TopHorrorsIGN2022(
      "IGN Movie Picks"
    ) === TopHorrorsTheAVClub2022("AVC Movie Picks")

    val outerJoin = TopHorrorsIGN2022
      .join(TopHorrorsTheAVClub2022, query, "outer")
      .select(cols: _*)

    outerJoin.show()
    ```

-   `scala` adapt√© pour ma√Ætriser toutes les fonctionnalit√©s de `spark` et optimiser au maximum les traitements en `spark`

-   `spark` est **compatible avec les langages** `scala`, `R`, `python`, `java`, et peut interpr√©ter des commandes **SQL.**

## Le driver en sparklyr {.smaller}

![](/images/schema_cluster.drawio.png){fig-align="center" width="400"}

-   Le programme R est traduit en scala gr√¢ce au package `sparklyr`

-   Le driver √©value le programme, il lit le code `scala` mais n'ex√©cute rien du tout

-   S'il remarque une erreur, l'erreur est envoy√©e directement √† l'utilisateur en session R avant l'ex√©cution du programme : c'est la force de la lazy evaluation.

## Pas besoin d'optimiser son code ! {.smaller}

![](images/catalyst.jpg)

source : documentation CASD disponible √† [Documentation Data Science](https://casd-eu.gitbook.io/data-science/)

## Catalyst optimise le code pour nous {.smaller}

Le driver contient un programme nomm√© Catalyst qui optimise le code `scala` automatiquement.

Spark optimise automatiquement les programmes soumis :

1.  Compilation des transformations pour soulever les √©ventuelles erreurs

2.  Int√©gration dans un **plan d'ex√©cution** contenant les √©tapes n√©cessaires pour parvenir au r√©sultat demand√© par le programme

3.  Optimisation du plan logique par le module **Catalyst** (driver Spark)

::: callout-warning
## Les erreurs en sparklyr

Petite pr√©cision sur les erreurs :

-   sparklyr traduit le code R en scala

-   mais √©galement les messages envoy√©s par spark en R

-   les erreurs affich√©es en R ne sont pas toujours bien interpr√©tables
:::

## Catalyst optimise le code pour nous {.smaller .scrollable}

![](images/dag.webp){fig-align="center"}

## Catalyst optimise le code pour nous

Par exemple si j'√©cris le programme :

```{r}
#| eval: false 
#| echo: true  

non_optimal <- table_1 %>%   
    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   
    filter(debut_contrat >= as.Date("2023-01-01"))
```

<br>

Catalyst r√©√©crit :

<br>

```{r}
#| eval: false 
#| echo: true  

optimal <- table_1 %>%   
    filter(debut_contrat >= as.Date("2023-01-01")) %>%   
    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))
```

Cette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu'une action d√©clenche l'ex√©cution.

## Catalyst optimise le code pour nous : laissons-le travailler ! {.smaller}

**D√©clencher le moins d'actions possibles** dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.

Pour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique. On √©vite quoi ?

. . .

On √©vite :

-   de mettre des `collect()`sur chaque table interm√©diaire

-   de `collect()` une table enti√®re

-   de `print()` √† chaque √©tape

. . .

Sinon Catalyst n'a pas assez de code pour optimiser !

## Catalyst optimise le code pour nous : laissons-le travailler !

```{r}
#| eval: false 
#| echo: true  

non_optimal <- table_1 %>% 
    collect() %>%
    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   
    filter(debut_contrat >= as.Date("2023-01-01"))

```

. . .

versus

```{r}
#| eval: false 
#| echo: true  

non_optimal <- table_1 %>% 
    collect() %>%
    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   
    filter(debut_contrat >= as.Date("2023-01-01")) 

```

## Jointures : un cas particulier

Pour effectuer ce type de jointure avec deux tables de volum√©tries diff√©rentes : A est petite, B est tr√®s volumineuse

![](images/join.png)

Solution rapide :

```{r}
#| eval: false
#| echo: true

table_finale <- table_volumineuse_comme_PJC %>%
  right_join(petite_table_mon_champ)
```

Solution lente :

```{r}
#| eval: false
#| echo: true

table_finale <- petite_table_mon_champ %>%
  left_join(table_volumineuse_comme_PJC)
```

## Calcul distribu√© et r√©cup√©ration des r√©sultats {.smaller}

![](images/schema_cluster.drawio.png){fig-align="center" width="400"}

::: callout-important
## Le r√©seau

-   Les workers communiquent avec le driver de la bulle MiDARES en r√©seau

-   Les workers communiquent entre eux en r√©seau pour s'√©changer des donn√©es

-   Le r√©seau est un mode de communication lent
:::

::: notes
Mtn un peu de th√©orie pour comprendre le calcul distribu√© et mieux l'utiliser
:::

## Le stockage distribu√© avec HDFS {.smaller}

![](images/stockage_distribue.drawio.png){fig-align="center"}

## Le stockage distribu√© avec HDFS {.smaller}

Hadoop Distributed File System (HDFS)

-   **stockage sur diff√©rentes machines :** les diff√©rents ordinateurs workers du cluster

-   donn√©es divis√©es **en blocs** plus petits de taille fixe et r√©partis sur les machines : aucune table de MiDAS n'existe en entier sur le cluster

-   chaque bloc est **r√©pliqu√© trois fois** : il existe trois fois les 10 premi√®res lignes de la table FNA sur trois ordinateurs diff√©rents du cluster (r√©silience)

-   un **NameNode** supervise les **m√©tadonn√©es** et g√®re la structure du syst√®me de fichiers : il sait o√π sont quels fichiers

-   les **DataNodes** stockent effectivement les blocs de donn√©es : les datanodes sont en fait les disques durs des workers du cluster, chaque ordinateur du cluster dispose d'un disque avec une partie des donn√©es MiDAS

-   le **syst√®me HDFS** est reli√© √† la bulle Midares : possible de charger des donn√©es en clique-bouton de la bulle vers HDFS de mani√®re tr√®s rapide et de t√©l√©charger des tables de HDFS pour les r√©cup√©rer en local

## Le r√¥le du cluster manager {.smaller}

![](images/calcul_distribue.drawio.png){fig-align="center"}

Le cluster manager distribue les traitements physiques aux ordinateurs du cluster :

-   il conna√Æt le meilleur plan physique fourni par Catalyst ;

-   il conna√Æt les ressources disponibles et occup√©es par toutes les machines du cluster ;

-   il affecte les ressources disponibles √† la session spark.

## Le r√¥le du worker {.smaller}

![](images/calcul_distribue.drawio.png){fig-align="center"}

Le worker effectue le morceau de programme qu'on lui affecte :

-   il ne conna√Æt que les t√¢ches qu'on lui a affect√©es ;

-   il peut communiquer avec le driver en r√©seau pour renvoyer un r√©sultat ;

-   il peut communiquer avec les autres workers en r√©seau pour partager des donn√©es ou des r√©sultats interm√©diaires : c'est un shuffle.

## La m√©moire du driver

![](images/collect.drawio.png){fig-align="center"}

## L'utilisation de la m√©moire du driver {.smaller .scrollable}

Lorsqu'il est n√©cessaire de collecter une table volumineuse, il faut donc pr√©voir assez de m√©moire RAM pour le driver : tous les r√©sultats sont rappatri√©s vers le driver.

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "2"

conf <- spark_config()
conf["spark.driver.memory"] <- "20Go"
conf["spark.executor.memory"] <- "80Go"
conf["spark.executor.cores"] <- 5
conf["spark.executor.instances"] <- 2
cont["spark.yarn.queue"] <- "prod"
conf["spark.driver.maxResultSize"] <- 0
conf["spark.sql.shuffle.partitions"] <- 200

sc <- spark_connect(master = "yarn", config = conf)
```

::: callout-caution
## Bonne pratique de partage des ressources

Le driver est dans la bulle Midares, qui a vocation √† √™tre r√©duite suite √† la g√©n√©ralisation du cluster.

-   La bulle Midares a besoin de RAM pour fonctionner, 100% des ressources ne sont donc pas disponibles pour `sparklyr`.

-   Pour permettre le **travail simultan√© fluide de 10 utilisateurs**, la m√©moire allou√©e au driver recommand√©e pour chaque utilisateur est de **20 Go**.

-   Il existe des alternatives pour ne pas collecter des r√©sultats trop volumineux dans le driver.
:::

## Programmer sans collecter {.smaller}

La programmation en spark doit √™tre adapt√©e aux contraintes de volum√©trie des donn√©es : test de chaque √©tape, puis ne forcer le calcul qu'√† la fin pour que Catalyst optimise l'ensemble du programme

La principale diff√©rence avec la programmation en R classique est que **la visualisation de tables compl√®tes volumineuses n'est pas toujours possible et n'est pas recommand√©e** :

-   **goulets d'√©tranglement** m√™me avec spark, car toutes les donn√©es sont rapatri√©es vers le driver puis vers la session R : erreurs Out of Memory

-   **longue :** √©change entre tous les noeuds impliqu√©s dans le calcul et le driver, puis un √©change driver-session R en r√©seau = lent ;

-   **beaucoup moins efficace que l'export direct en parquet** du r√©sultat (qui fonctionne toujours) : charger ensuite sa table finale en data frame R classique pour effectuer l'√©tude.

S'il est n√©cessaire de collecter, il faut pr√©voir **beaucoup de RAM pour le driver avec le param√®tre** `spark.driver.memory`, ce qui emp√™che les autres utilisateurs de travailler.

## Programmer sans collecter {.smaller}

Les r√©sultats qu'il est recommand√© de r√©cup√©rer en m√©moire vive en session R sont de la forme suivante :

-   **une table filtr√©e** avec les variables n√©cessaires √† l'√©tude uniquement : sous MiDAS, toutes les jointures, les calculs de variable et les filtres peuvent √™tre effectu√©s de mani√®re efficiente sous la forme de spark_data_frame, sans jamais collecter les donn√©es MiDAS ;

-   des **statistiques descriptives synth√©tiques ;**

-   les **premi√®res lignes** de la table pour v√©rifier que le programme retourne bien le r√©sultat attendu ;

-   une **table agr√©g√©e** pour un graphique par exemple, √† l'aide de la fonction `summarise()`.

## Programmer sans collecter {.smaller}

Je sais que la cr√©ation de ma table donne le r√©sultat souhait√©e (car j'ai regard√© ce dont elle a l'air avvec `head()`), maintenant je vais l'appeler une dizaine de fois pour collecter uniquement des statistiques descriptives.

Que se passe-t-il √† chaque fois que je collecte une statistique descriptive ?

. . .

La cr√©ation de la table va √™tre ex√©cut√©e √† nouveau : tr√®s long ?

Comment faire ?

::: panel-tabset
## Cache

La cr√©ation de la table est ex√©cut√©e une seule fois, le r√©sultat est conserv√© en m√©moire vive

```{r}
#| eval: false
#| echo: true

ma_table_spark <- MMO_2017 %>%
  filter(DebutCTT > as.Date("2017-06-01")) %>%
  mutate(duree_CTT = DATEDIFF(FinCTT,DebutCTT) + 1) %>%
  sdf_register(name = "ma_table_spark")

tbl_cache("ma_table_spark")
```

## Persist

La cr√©ation de la table est ex√©cut√©e une seule fois, le r√©sultat est conserv√© sur le disque

```{r}
#| eval: false
#| echo: true

ma_table_spark <- MMO_2017 %>%
  filter(DebutCTT > as.Date("2017-06-01")) %>%
  mutate(duree_CTT = DATEDIFF(FinCTT,DebutCTT) + 1) %>%
  sdf_persist(storage.level = "DISK_ONLY")

tbl_cache("ma_table_spark")
```
:::

::: notes
R√©ponse attendue : c'est une action donc ca d√©clenche la cr√©ation de la table Indice : cr√©ation de table contient uniquement des transformations
:::

## Optimiser la m√©moire : conclusion

Pour programmer en spark sans aucune erreur :

1.  D√©clencher une action avec plusieurs transformations pour laisser Catalyst optimiser

2.  Ne pas collecter tout une table

3.  Persister ou cacher une table qu'on va appeler plusieurs fois pour ne collecter que des statistiques descriptives

4.  Ne pas persister trop de tables : occupe de la m√©moire RAM

5.  Consulter le programme exemple sur la bulle CASD si besoin

# Les bonnes pratiques

## Mode local : sch√©ma {.smaller}

![](images/mode_local.PNG)

## Mode local : √† √©viter {.smaller}

En mode local :

-   les ressources utilis√©es sont celles de la bulle uniquement : bloque les autres utilisateurs

-   il faut allouer suffisamment de coeurs √† la JVM pour parall√©liser

-   m√™me si l'utilisateur choisit des ressources faibles, les ressources r√©elles utilis√©es dans une session spark peuvent √™tre plus √©lev√©es : mauvaise gestion de l'allocation des ressources entre utilisateurs

-   acc√©l√©ration sensible par rapport √† un mode de programmation classique s√©quentiel sur un unique coeur si beaucoup de ressources

-   Sur la bulle CASD, mauvaise gestion de la r√©partition des ressources en spark local : l'utilisation simultan√©e de spark par plusieurs membres de la bulle entra√Ænent des ralentissements consid√©rables

    ‚ñ∂Ô∏èmode local √† √©viter absolument

## Traitement MAP distribu√©

![](images/map_distribue.drawio.png){fig-align="center"}

## Traitement REDUCE distribu√©

![](images/reduce_distribue.drawio.png){fig-align="center"}

## Inutile de prendre toutes les ressources {.smaller}

![](images/reduce_distribue.drawio.png){fig-align="center"}

Comme nous l'avons vu, les traitements REDUCE ne se pr√™tent pas tr√®s bien au calcul distribu√© :

-   augmenter le nombre de workers augmente la probabilit√© de devoir effectuer des shuffles

-   il est recommand√© de se limiter √† deux workers comme dans la configuration propos√©e

-   r√©server d'autres ressources n'est souvent pas efficient et monopolise les ressources pour les autres utilisateurs.

## Fermer sa session {.smaller}

-   Une fois les ressources r√©serv√©es, tant que la session R est ouverte, les ressources restent r√©serv√©es √† l'utilisateur : personne ne peut les prendre

-   Si on ne ferme pas sa session, on bloque les autres

-   Si une session reste ouverte trop longtemps et bloque les autres, le CASD pourra la ferme √† distance : bien enregistrer ses r√©sultats avant de partir !

## Mutualiser les exp√©riences {.smaller}

-   Sessions de passage d'un code sur le cluster

-   Contributions √† la documentation MiDAS

-   Appeler un coll√®gue si erreur en sparklyr

# Pour aller plus loin

## Partitionnement

Le format `.parquet` (avec `arrow`) et le framework `spark` permettent de g√©rer le partitionnement des donn√©es.

Si les op√©rations sont souvent effectu√©es par r√©gions par exemple, il est utile de forcer le stockage des donn√©es
d'une m√™me r√©gion au m√™me endroit physique et acc√©l√®re drastiquement le temps de calcul :

```{r}
#| eval: false
#| echo: true

spark_write_parquet(ma_table, "hdfs:///resultats/ma_table.parquet", partition_by = c("region"))

```

## √âviter le probl√®me des ex√©cuteurs inactifs

Supposons que le jeu de donn√©es ait 8 partitions, un ex√©cuteur (avec seulement 1 core) ne peut ex√©cuter
qu'une t√¢che(task) √† la fois, et une partition = une t√¢che.

Cas 1 : 6 ex√©cuteurs, au dernier tour, il ne reste que 2 t√¢ches, 4 ex√©cuteurs seront inactifs.
Cas 2 : 4 ex√©cuteurs, 2*4, aucun ex√©cuteur inactif.

```{r}
#| eval: false
#| echo: true

# Get the number of partitions
num_partitions <- sdf_num_partitions(df)
print(num_partitions)

# Repartition the DataFrame to a specific number of partitions
df_repartitioned <- sdf_repartition(df, partitions = 10)
```

- Le nombre de partitions doit √™tre divisible par le nombre d'ex√©cuteurs.
- Le nombre de partitions doit √™tre sup√©rieur au nombre d'ex√©cuteurs.



## √âviter trop de partitions

La cr√©ation de t√¢ches entra√Æne des surcharges, qui doivent toujours √™tre inf√©rieures √† 50 % du temps total d'ex√©cution de la t√¢che.

![](images/stage_eventtimeline.png)

```{r}
#| eval: false
#| echo: true

# Repartition the DataFrame to a specific number of partitions
df_repartitioned <- sdf_repartition(df, partitions = 10)

# Repartition the DataFrame by a specific column, e.g., "commune_code".
# The partition number will be the distinct value number
df_repartitioned <- sdf_repartition(df, partition_by = "commune_code")
```

- La r√©partition est une op√©ration tr√®s co√ªteuse, utilisez-la judicieusement.
- En g√©n√©ral, la taille recommand√©e des partitions est d'environ 128 √† 512 Mo.

## Optimiser la configuration des ex√©cuteurs

Configuration recommand√©e :
- Un ex√©cuteur devrait avoir entre 3 et 5 cores.
- Pour chaque core, il faut r√©server entre 4 et 8 Go de m√©moire.

En mode cluster, chaque ex√©cuteur fonctionne dans une JVM (la JVM n√©cessite une m√©moire suppl√©mentaire et du CPU pour ex√©cuter le GC).

- √âvitez 1 core par ex√©cuteur.
- √âvitez trop de cores dans un seul ex√©cuteur, cela peut causer des probl√®mes de contention de threads ou la surcharge du garbage collector.

## T√¢ches Maximales en parall√®les

**Max_Parallel_Tasks=Number_of_Executors*Cores_per_Executor**

Par exemple, une session Spark dispose de la configuration suivante :

```{r}
conf["spark.executor.memory"] <- "32Go"
conf["spark.executor.cores"] <- 4
conf["spark.executor.instances"] <- 5
```

5 executor * 4 core = 20 t√¢ches en parall√®le. Pour un jeu de donn√©es de 200 partitions, il faut 10 tournes pour
terminer tous les calculs.

- Il n'existe pas de configuration universelle optimale pour tous, seulement la meilleure configuration pour vos t√¢ches.

## SparkUI  {.smaller .scrollable}

Spark UI permet de consulter le plan logique et physique du traitement demand√©. Trois outils permettent d'optimiser les traitements :

::: panel-tabset

## DAG

![](images/dag.webp)

## GC

V√©rifier que le `gc time` est inf√©rieur √† 10% du temps pour ex√©cuter la t√¢che ‚úÖ

![](images/gc.png)

## M√©moire

V√©rifier que la `storage memory` ne sature pas la m√©moire ‚úÖ

![](images/gc.png)
:::

## Yarn {.smaller .scrollable}

-   **yarn** : disponibilit√© des ressources

    ![](images/yarn_scheduler.PNG)

-   **Sparkhistory** pour des traitements de sessions ferm√©es

Le sparkhistory entra√Æne l'enregistrement de logs assez lourdes, il est donc d√©sactiv√© par d√©faut. Pour l'activer sur un programme :

```{r}
#| eval: false
#| echo: true

conf <- spark_config()
conf["spark.eventLog.enabled"] <- "true"
conf["spark.eventLog.dir"] <- "hdfs://midares-deb11-nn-01.midares.local:9000/spark-logs"
conf["appName"] <- "un_nom_de_traitement"

sc <- spark_connect(master = "yarn", config = conf)


```

## Pyspark

![](images/pyspark.drawio.png){fig-align="center"}
