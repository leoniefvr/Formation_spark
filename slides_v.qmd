---
title: "Initiation √† Spark avec R en mode cluster"
format: revealjs
---

## Au programme

1.  MiDAS : une base de donn√©es volumineuse üìö

2.  Utiliser MiDAS avec R : un d√©fi üí≠

3.  Sparklyr : l'outil ergonomique de spark en R üë®‚Äçüíª

4.  Les bonnes pratiques sur une infrastructure partag√©e üñ•Ô∏è

5.  Optimiser la m√©moire : pourquoi et comment ‚è≥

6.  Pour aller plus loin üí°

# Un rapide tour de table üí¨

::: notes
Poste, usages de R, connaissance spark
:::

# MiDAS : une base de donn√©es volumineuse üìö

## Qu'est-ce que MiDAS ?

![](/images/midas_traj_1.PNG){fig-align="right" width="900"}

![](/images/midas_traj_2.PNG){fig-align="right" width="780"}

## Une des bases les plus volumineuses du SSP {.smaller}

![](/images/donnees_ssp.PNG){fig-align="center"}

Les administrations dont les donn√©es sont comparables √† MiDAS utilisent un cluster Spark : Insee, Drees, Acoss, UNEDIC, Cnaf

‚ñ∂Ô∏èLe cluster spark est une solution tr√®s efficiente pour traiter des donn√©es de cette ampleur.

## Concr√®tement, qu'est-ce que MiDAS ? {.smaller}

![](/images/structure_midas.png){fig-align="center"}

::: callout-tip
## Pourquoi Spark ?

La manipulation des donn√©es MiDAS en l'√©tat implique de nombreuses op√©rations de jointures qui n√©cessitent une puissance de calcul et un temps certains.
:::

## O√π est MiDAS sur la bulle ? {.smaller}

Disponible dans l'espace commun (= Documents publics) : C:\\Users\\Public\\Documents\\MiDAS_parquet\\Vague X

<br>

Au format **parquet** :

-   **compression** efficace des donn√©es : taux de compression de 5 √† 10 par rapport au format csv

-   orient√© **colonnes**

-   chargement efficace **en m√©moire** des donn√©es

-   **stockage partitionn√©** des donn√©es avec `write_dataset()`

-   traiter des donn√©es **sur disque**

-   **ind√©pendant du logiciel** utilis√© : R, python, spark...

## La documentation en ligne {.smaller}

<br>

::::: columns
::: {.column width="35%"}
[Documentation en ligne](https://documentationmidas.github.io/Documentation_MiDAS/Presentation/pr%C3%A9sentation.html)

-   Dictionnaire des donn√©es

-   Fiches pr√©sentant les concepts de l'indemnisation, du retour √† l'emploi

-   Exemples d'impl√©mentation en R

-   Conseils qualit√© des variables
:::

::: {.column width="65%"}
![](/images/documentation_midas.PNG){fig-align="center"}
:::
:::::

::: notes
Contribuer avec github, montrer le github, dire que sur le read me conseils pour contribuer et mettre des codes, espace de partage de codes √† venir
:::

# Et vous, quels sont vos usages de MiDAS ? üëÅÔ∏è‚Äçüó®Ô∏è

::: notes
Utilisation midas, √©tudes
:::

# Traiter MiDAS en R : un d√©fi üë®‚Äçüíª

## Une bulle CASD {.smaller}

Des ressources partag√©es entre tous les utilsateurs simultan√©s :

-   256 Go de m√©moire vive (ou RAM)
-   Un processeur (ou CPU) compos√© de 16 coeurs

![](/images/schema_ordinateur.png){fig-align="center"}

::: notes
Bulle CASD = un gros ordinateur partag√© par plusieurs utilisateurs, besoin du voc ordinateur pour comprendre spark
:::

## Une bulle CASD {.smaller}

::: panel-tabset
### Le disque dur

Le disque dur, aussi appel√© **Hard Disk Drive (HDD)**, est une solution de **stockage permanente** :

-   les donn√©es sont conserv√©es m√™me **apr√®s l'arr√™t de l'appareil**

-   l'espace de stockage est **volumineux**

-   mais les op√©rations d'√©criture et de lecture ne sont pas du tout instantann√©es

### La m√©moire vive

La m√©moire vive, aussi appel√©e **RAM**, se distingue de la m√©moire de stockage (disque) :

-   par sa **rapidit√©**, notamment pour fournir des donn√©es au processeur pour effectuer des calculs

-   par sa **volatilit√©** (toutes les donn√©es sont perdues si l'ordinateur n'est plus aliment√©)

-   par l'acc√®s direct aux informations qui y sont stock√©es, **quasi instantann√©**.

### Le processeur

Le processeur :

-   permet d'**ex√©cuter des t√¢ches et des programmes** : convertir un fichier, ex√©cuter un logiciel

-   est compos√© d'un ou de plusieurs **coeurs** : un coeur ne peut ex√©cuter qu'une seule t√¢che √† la fois. Si le processeur contient plusieurs coeurs, il peut ex√©cuter autant de t√¢ches en parall√®le qu'il a de coeurs

-   se caract√©rise aussi par sa **fr√©quence** : elle est globalement proportionnelle au nombre d'op√©rations qu'il est capable d'effetuer par seconde.
:::

## Traiter MiDAS en R : les limites

1.  Charger les donn√©es en m√©moire vive

```{r}
#| eval: false
#| echo: true
  
  path_fna <- "C:/Users/Public/Documents/MiDAS_parquet/Vague 4/FNA/"
  
  PJC <- read_parquet(paste0(path_fna, "pjc.parquet"), memory = TRUE)
  ODD <- read_parquet(paste0(path_fna, "odd.parquet"), memory = TRUE)


```

. . .

2.  R√©aliser des op√©rations co√ªteuses en ressources

```{r}
#| eval: false
#| echo: true
  
jointure <- PJC %>%
  rename(KROD1 = KROD3) %>%
  left_join(ODD, by = c("id_midas", "KROD1"))


```

. . .

3.  Le partage des ressources de la bulle

Chaque utilisateur peut mobiliser toutes les ressouces de la bulle.

::: notes
Donn√©es \> RAM et R fonctionne dans la m√©moire vive (pour √ßa que plus rapide que SAS) Jointures co√ªteux : on va voir pourquoi apr√®s tlm sur la m√™me bulle sans allocation des ressources = ralentissements
:::

## Traitement l√©ger versus co√ªteux {.smaller}

::::: panel-tabset
## MAP = l√©ger {.smaller}

![](/images/formation%20sparklyr-Page-1.drawio.png){fig-align="center"}

::: notes
Ce traitement est peu co√ªteux :

-   chargement d'une seule colonne en RAM : format parquet orient√© colonnes

-   peu de m√©moire d'ex√©cution : R est un langage vectoris√©
:::

## REDUCE = co√ªteux {.smaller}

![](/images/formation%20sparklyr-Page-2.drawio.png){fig-align="center"}

::: notes
Ce traitement n√©cessite :

-   le chargement de davantage de colonnes en m√©moire vive ;

-   davantage de m√©moire d'ex√©cution pour effectuer l'intersection (`inner_join()`).
:::

## REDUCE en R

-   les jointures

-   les op√©rations en `group_by()`

-   les op√©rations de tri avec `arrange()`

-   `distinct()`

    ‚ñ∂Ô∏è Ex√©cution s√©quentielle sur un coeur du processeur + beaucoup de m√©moire vive (donn√©es temporaires)

    ‚ñ∂Ô∏è Erreur "out of memory".
:::::

::: notes
Parquet orient√© colonne donc ne charge que les colonnes n√©cessaires en m√©moire R vectoris√© : op√©ration appliqu√©e √† tout le vecteur = traitement rapide

Jointure co√ªteuse parce que comparaison ligne √† ligne

window funcions
:::

## Pourquoi spark ? {.smaller}

<br>

+------------------------+-------------------------------------+--------------------------+
| Solution test√©e        | Avantage                            | Destination d'usage      |
+========================+=====================================+==========================+
| Package ¬´ data.table ¬ª | Calculs parall√©lis√©s                | pour bases \< RAM        |
+------------------------+-------------------------------------+--------------------------+
| Format ¬´ parquet ¬ª +   | Stockage moins lourd                | pour bases \< RAM        |
|                        |                                     |                          |
| package ¬´ arrow ¬ª      | Chargement efficient                |                          |
+------------------------+-------------------------------------+--------------------------+
| DuckDB                 | Gestionnaire de BDD                 | Pour des bases \< 100 Go |
+------------------------+-------------------------------------+--------------------------+
| Spark                  | Traitements distribu√©s plus rapides | Pour des bases \> 100 Go |
|                        |                                     |                          |
|                        | Traitement de donn√©es volumineuses  |                          |
+------------------------+-------------------------------------+--------------------------+

## Un gain de temps consid√©rable {.smaller}

<br>

+-------------+-----------------------------------------------------------------------------+---------------------------------------------+
|             | Calcul de la dur√©e moyenne du premier contrat pour tous les individus MiDAS | Retour √† l'emploi salari√© des indemnisables |
+=============+=============================================================================+=============================================+
| Classique R | 4 heures                                                                    | Crash                                       |
+-------------+-----------------------------------------------------------------------------+---------------------------------------------+
| Duckdb      | 8 minutes                                                                   | 3 heures seul sur la bulle                  |
+-------------+-----------------------------------------------------------------------------+---------------------------------------------+
| Spark       | 1 minute                                                                    | 2 minutes                                   |
+-------------+-----------------------------------------------------------------------------+---------------------------------------------+

Mais alors, pourquoi le cluster ? ü§î

## Une bonne allocation des ressources entre utilisateurs

::: r-stack
![](/images/mode_local.PNG){.fragment fig-align="center" width="1000" height="450"}

![](/images/mode_cluster.PNG){.fragment fig-align="center" width="1000" height="450"}
:::

# Et vous, quels sont vos probl√©matiques et vos solutions ? ‚ö†Ô∏è

::: notes
op√©rations impossibles ? bugs erreurs insolubles ? D√©j√† utilis√© spark ?
:::

# Comment on fait du spark cluster avec R version courte ? ‚è≤Ô∏è

## O√π est Midas, 2√®me √©dition {.smaller}

Le cluster a son propre explorateur de fichiers √† mettre en favori dans son navigateur : https://midares-deb11-nn-01.midares.local:9870/

::: r-stack
![](/images/hdfs_browse.png){.fragment fig-align="center" width="900" height="500"}

![](/images/hdfs_midas.png){.fragment fig-align="center" width="900" height="500"}
:::

::: notes
Sorte de disque du cluster
:::

## Et mes bases sur la bulle ? {.smaller}

Il est possible de charger des bases enregistr√©es n'importe o√π sur la bulle sur HDFS : depuis vos documents personnels, depuis l'espace commun...

::: r-stack
![](/images/hdfs_upload_1.png){.fragment fig-align="center" width="1100" height="450"}

![](/images/hdfs_upload_2.png){.fragment fig-align="center" width="1100" height="450"}
:::

## Un cluster de calcul

![](/images/schema_cluster.drawio.png){fig-align="center"}

::: notes
Plusieurs ordinateurs, noter le voc au tableau noeud = worker = ordinateur = datanode = executeur = instance Session dans la bulle donc charger grosses donn√©es en session = limit√© par la taille de la bulle
:::

## Connexion {.smaller}

::: panel-tabset
## Traitement normal

```{r}
#| eval: false
#| echo: true

library(sparklyr)
library(dplyr)
library(dbplyr)

conf <- spark_config()
conf["spark.driver.memory"] <- "20Go"
conf["spark.executor.memory"] <- "60Go"
conf["spark.executor.cores"] <- 4
conf["spark.executor.instances"] <- 2
cont["spark.yarn.queue"] <- "prod"
conf["spark.driver.maxResultSize"] <- 0

sc <- spark_connect(master = "yarn", config = conf)
```

## Traitement tr√®s lourd

```{r}
#| eval: false
#| echo: true

library(sparklyr)
library(dplyr)
library(dbplyr)

conf <- spark_config()
conf["spark.driver.memory"] <- "20Go"
conf["spark.executor.memory"] <- "60Go"
conf["spark.executor.cores"] <- 4
conf["spark.executor.instances"] <- 3
cont["spark.yarn.queue"] <- "prod"
conf["spark.driver.maxResultSize"] <- 0

sc <- spark_connect(master = "yarn", config = conf)
```
:::

::: callout-important
## Temps de connexion

Pour se connecter au cluster, il faut environ 5 minutes, √† chaque connexion. Spark cluster n'est pas du tout adapt√© √† des traitements l√©gers (moins de 10 minutes).
:::

## Quizz : traitement nomal ou traitement tr√®s lourd {.smaller}

-   Appariement de 2 bases mensuelles de la CNAF entre elles (4 millions de lignes par base)

. . .

-   Rep√©rage de la situation en emploi (MMO) d'un champ de b√©n√©ficiaires RSA un mois donn√© (2 millions de lignes)

. . .

-   Calcul de la dur√©e d'inscription (FHS, table DE), de la dur√©e d'indemnisation (FNA, table PJC) et du retour √† l'emploi d'un champ de 2 millions de demandeurs d'emploi

. . .

-   Calcul de la dur√©e d'indemnisation (FNA, table PJC) d'un champ de 20 millions de demandeurs d'emploi

. . .

-   Calcul du retour √† l'emploi d'un champ de demandeur d'emploi en fin d'un mois donn√© (5 millions de DEFM)

## Chargement des donn√©es en spark {.smaller}

<br>

```{r}
#| eval: false
#| echo: true

### Depuis HDFS
mmo_17_df_spark <- spark_read_parquet(sc,
                                  path = "hdfs:///dataset/MiDAS_v4/mmo/mmo_2017.parquet",
                                  memory = FALSE)

### Passer un dataframe R en spark
mon_data_frame <- data.frame(c("Anna", "Paul"), c(15, 20))
mon_data_frame_spark <- copy_to(sc, "mon_data_frame")
```

‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : par d√©faut, `memory = FALSE`

::: callout-tip
## Spark data frames

`mmo_17_df_spark` est un spark data frame (sdf) : il ne peut pas √™tre ouvert comme un data frame R classique, il n'est pas dans la session R.
:::

::: notes
spark est lazy, paresseux, il ne fait rien tant qu'on ne le force pas
:::

## Comment voir ma table ?

R√©cup√©rer une partie de la table : pas plus de 500 lignes

```{r}
#| eval: false
#| echo: true

une_partie_de_ma_table <- ma_table %>% 
  head(100) %>%
  collect()


une_partie_de_ma_table <- ma_table %>% 
  filter(id_midas %in% ma_liste_id_midas) %>%
  collect()

# une_partie_de_ma_table est ici un data.frame R classique que vous pouvez ouvrir!
```

::: callout-tip
## Spark data frames

`une_partie_de_ma_table` est un data frame R : il peut pas √™tre ouvert, il est dans la session R. Cela signifie qu'il se situe sur la bulle
:::

## Un cluster de calcul

![](/images/schema_cluster.drawio.png){fig-align="center"}

## Sparklyr, c'est comme dplyr

<br>

Ensuite, vous pouvez programmer avec `dplyr` !

<br>

```{r}
#| eval: false
#| echo: true

mmo_17_df_spark <- mmo_17_df_spark %>%
  
  rename(debut_contrat = DebutCTT) %>%
  
  filter(debut_contrat >= as.Date("2017-01-01") & debut_contrat < as.Date("2017-02-01")) %>%
  
  mutate(mois_debut_contrat = substr(debut_contrat,6,7))


```

## La lazy evaluation {.smaller}

Spark distingue deux types d'op√©rations :

-   **les transformations :** prennent en entr√©e un `spark_data_frame` et retournent un `spark_data_frame`, elles ne d√©clenchent aucun calcul

    Par exemple, le programme ci-dessous ne d√©clenche pas d'ex√©cution :

```{r}
#| eval: false
#| echo: true

mmo_17_df_spark_mois <- mmo_17_df_spark %>%
  rename(debut_contrat = DebutCTT) %>%
  filter(debut_contrat >= as.Date("2017-01-01") & debut_contrat < as.Date("2017-06-01")) %>%
  mutate(mois_debut_contrat = substr(debut_contrat,6,7))


```

-   **les actions :** forcent le calcul d'un r√©sultat pour le r√©cup√©rer et d√©clenchent l'ex√©cution de toutes les transformations compil√©es jusqu'√† l'appel de l'action.

    Par exemple, le programme ci-dessous d√©clenche le calcul de toute la cellule pr√©c√©dente :

```{r}
#| eval: false
#| echo: true

nb_debut_contrat_fev_17 <- mmo_17_df_spark_mois %>%
  group_by(mois_debut_contrat) %>%
  summarise(nb_contrats = n()) %>%
  print()

```

## La lazy evaluation : un gain de temps consid√©rable

<br>

::: callout-tip
## La gestion des erreurs

En r√©alit√©, lorsqu'on appuie sur le bouton `run`, il ne se passe pas "rien". Le code est compil√© par spark : les erreurs sont rep√©r√©es avant m√™me que le code soit ex√©cut√© !
:::

![](images/erreur_variable_inexistante.PNG){width="300"}

## R√©cup√©rer un r√©sultat {.smaller}

Les principales actions sont :

-   `print()`

-   `head()` + `collect()`

-   ‚ö†Ô∏è `collect()` pour de petites tables : ne fonctionne pas sur des grosses tables

-   `tbl_cache()` (√©crire un `spark_data_frame` en m√©moire pour le r√©utiliser)

::: callout-warning
## Le bouton stop

Il est recommand√© de ne pas utiliser ce bouton en programmant en sparklyr : il rend la session spark inutilisable par la suite, il faut fermer RStudio et rouvrir ensuite.
:::

## Les erreurs spark {.smaller}

Les erreurs de **programmation** sont soulev√©es avant que les calculs commencent.

Des erreurs peuvent survenir pendant l'ex√©cution du code, quelques minutes apr√®s l'appel d'une action par exemple.

::: callout-warning
## Collecter des donn√©es trop volumineuses

Une source fr√©quente d'erreur pendant l'ex√©cution est l'appel d'un `collect()` sur des donn√©es trop volumineuses pour √™tre collect√©es. La premi√®re √©tape du d√©buggage consiste √† limiter les `collect()`.
:::

::: r-stack
![](images/erreur_1.png){.fragment width="1000" height="100"}

![](/images/erreur_2.PNG){.fragment width="1000" height="100"}

![](/images/erreur_2_bis.PNG){.fragment width="1000" height="120"}
:::

::: callout-caution
## Les erreurs sparklyr

Les erreurs envoy√©es par spark sont "traduites" par sparklyr pour √™tre affich√©es dans la console de R. Elles ne sont pas toujours tr√®s lisibles, ou tr√®s pr√©cises sur la nature de l'erreur/sa source.
:::

## ... presque tout comme dplyr {.smaller .scrollable}

La majorit√© des commandes `dplyr` fonctionnent sur un spark_data_frame avec le package `sparklyr`. Les divergences principales sont les suivantes :

+--------------------------------+----------------+----------------------------------+
| Fonctionnalit√©                 | tidyverse      | sparklyr                         |
+================================+================+==================================+
| import d'un fichier `.parquet` | `read_parquet` | `spark_read_parquet()`           |
+--------------------------------+----------------+----------------------------------+
| tri d'un tableau               | `arrange()`    | `window_order()` ou `sdf_sort()` |
+--------------------------------+----------------+----------------------------------+
| op√©rations sur les dates       | `lubridate`    | fonctions Hive                   |
+--------------------------------+----------------+----------------------------------+
| empiler des tableaux           | `bind_rows()`  | `sdf_bind_rows()`                |
+--------------------------------+----------------+----------------------------------+
| nombre de lignes d'un tableau  | `nrow()`       | `sdf_nrow()`                     |
+--------------------------------+----------------+----------------------------------+
| faire pivoter un tableau       | `tidyr`        | `sdf_pivot()`                    |
+--------------------------------+----------------+----------------------------------+
| export d'un `spark_data_frame` |                | `spark_write_parquet()`          |
+--------------------------------+----------------+----------------------------------+

## Quelques fonctions R pas encore traduites {.smaller .scrollable}

::::: panel-tabset
## Dates

Les fonctions de `lubridate()`ne sont pas adapt√©es au `spark_data_frames`.

-   Convertir une cha√Æne de caract√®re de la forme AAAA-MM-DD en Date

```{r}
#| eval: false
#| echo: true

    date_1 <- as.Date("2024-05-26")

```

-   Calculer une dur√©e entre deux dates

```{r}
#| eval: false
#| echo: true

    PJC_spark <- spark_read_parquet(sc,
                                    path = "hdfs:///dataset/MiDAS_v4/pjc.parquet",
                                    memory = FALSE)

    duree_pjc_df <- PJC_spark %>%
      rename(date_fin_pjc = as.Date(KDFPJ),
             date_deb_pjc = as.Date(KDDPJ)) %>%
      mutate(duree_pjc = datediff(date_fin_pjc, date_deb_pjc) + 1) %>%
      head(5)

```

-   Ajouter ou soustraire des jours ou des mois √† une date

```{r}
#| eval: false
#| echo: true


    duree_pjc_bis_df <- duree_pjc_df %>%
      mutate(duree_pjc_plus_5 = date_add(duree_pjc, int(5)),
             duree_pjc_moins_5 = date_sub(duree_pjc, int(5)),
             duree_pjc_plus_1_mois = add_months(duree_pjc, int(1))) %>%
      head(5)

```

::: callout-note
## Add_months

Si la date en entr√©e est le dernier jour d'un mois, la date retourn√©e avec `add_months(date_entree, int(1))` sera le dernier jour calendaire du mois suivant.
:::

::: callout-tip
## Format

Le `int()` est important car ces fonctions Hive n'accepte que les entiers pour l'ajout de jours : taper uniquement 5 est consid√©r√© comme un flottant dans R.
:::

## Tableau

-   Tri dans un groupe pour effectuer un calcul s√©quentiel

```{r}
#| eval: false
#| echo: true

    ODD_spark <- spark_read_parquet(sc,
                                    path = "hdfs:///dataset/MiDAS_v4/odd.parquet",
                                    memory = FALSE)

    ODD_premier <- ODD_spark %>%
      group_by(id_midas) %>%
      window_order(id_midas, KDPOD) %>%
      mutate(date_premier_droit = first(KDPOD)) %>%
      ungroup() %>%
      distinct(id_midas, KROD3, date_premier_droit) %>%
      head(5)
      
```

-   Tri pour une sortie : `sdf_sort()` , `arrange()` ne fonctionne pas

-   Concat√©ner les lignes (ou les colonnes `sdf_bind_cols()`)

    ```{r}
    #| eval: false
    #| echo: true

    ODD_1 <- ODD_spark %>%
      filter(KDPOD <= as.Date("2017-12-31")) %>%
      mutate(groupe = "temoins")

    ODD_2 <- ODD_spark %>%
      filter(KDPOD >= as.Date("2021-12-31")) %>%
      mutate(groupe = "traites")

    ODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)

    ```

-   D√©doublonner une table

```{r}
#| eval: false
#| echo: true

    droits_dans_PJC <- PJC_spark %>%
      sdf_distinct(id_midas, KROD3)

    print(head(droits_dans_PJC, 5))

    PJC_dedoublonnee <- PJC_spark %>%
      sdf_drop_duplicates()

    print(head(PJC_dedoublonnee, 5))

```

-   Pivot : les fonctions du packag `tidyr` ne fonctionnent pas sur donn√©es spark

```{r}
#| eval: false
#| echo: true

    ODD_sjr_moyen <- ODD_spark %>%
      mutate(groupe = ifelse(KDPOD <= as.Date("2020-12-31"), "controles", "traites")) %>%
      sdf_pivot(groupe ~ KCRGC,
        fun.aggregate = list(KQCSJP = "mean")
      )
```

## Statistiques

-   R√©sum√© statistique : `sdf_describe()` , `summary()`ne fonctionne pas.

-   Dimension : `sdf_dim`, la fonction `nrow()`ne fonctionne pas.

-   Quantiles approximatifs : le calcul des quantiles sur donn√©es distirbu√©es renvoie une approximation car toutes les donn√©es ne peuvent pas √™tre rappatri√©es sur la m√™me machine physique du fait de la volum√©trie, `sdf_quantile()`

-   Echantillonnage al√©atoire : `sdf_random_split`
:::::

## Je veux voir ma table {.smaller}

1.  V√©rifier le nombre de lignes sans collecter

```{r}
#| eval: false
#| echo: true

ma_table %>% 
  sdf_nrow()

```

. . .

2.  V√©rifier la pr√©sence de doublons

```{r}
#| eval: false
#| echo: true

nb_doublons <- ma_table %>% 
  group_by(id_midas) %>%
  summarise(nb_ligne_ind = n()) %>%
  ungroup() %>%
  filter(nb_ligne_ind > 1) %>%
  sdf_nrow()

```

. . .

3.  R√©cup√©rer une partie de la table : pas plus de 500 lignes

```{r}
#| eval: false
#| echo: true

une_partie_de_ma_table <- ma_table %>% 
  head(100) %>%
  collect()


une_partie_de_ma_table <- ma_table %>% 
  filter(id_midas %in% ma_liste_id_midas) %>%
  collect()

# une_partie_de_ma_table est ici un data.frame R classique que vous pouvez ouvrir!
```

## Exporter des donn√©es sur disque {.smaller}

Sur la pause d√©jeuner par exemple üòâ

Pourquoi ‚ùì Pour des donn√©es qui ne peuvent pas √™tre collect√©es en m√©moire vive

Export des spark data frames directement sous HDFS : √† aucun moment on n'ouvre la table : on peut traiter des donn√©es beaucoup plus volumnieuses que la m√©moire RAM !

```{r}
#| eval: false
#| echo: true

ma_table_spark <- MMO %>%
  
  right_join(mon_champ_individuel, by = c("id_midas")) %>%
  
  mutate(fin_ctt_bis = ifelse(is.na(FinCTT), as.Date("2023-12-31"), FinCTT)) %>%
  
  mutate(duree_ctt = DATEDIFF(FinCTT, DebutCTT) + 1)

spark_write_parquet(ma_table_spark, "hdfs:///resultats/ma_table.parquet")

```

Possibilit√© de r√©cup√©rer ce fichier sur la bulle MiDARES = en local.

::: callout-warning
## Exports simultan√©s

HDFS supporte les exports simultan√©s, mais le temp d'export est plus long lorsque le NameNode est requ√™t√© par plusieurs personnes simultan√©ment
:::

## Si on souhaite la r√©cup√©rer en local {.smaller}

::: callout-caution
## Les exports sur HDFS

Lorsqu'on exporte une table depuis notre session R vers HDFS, celle-ci est **automatiquement partitionn√©e**, comme le reste des donn√©es.

Ainsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.

Il est possible de ma√Ætriser le nombre de partitions avec la commande `sdf_coalesce(partitions = 1)` du package `sparklyr`.

Avec `sdf_coalesce(partitions = 1)`, on n'aura qu'un seul fichier √† t√©l√©charger depuis HDFS.

Avec `sdf_coalesce(partitions = 200)`, on aura 200 morceaux de notre fichier √† t√©l√©charger √† la main (pas possible de faire tout s√©lectionner sous HDFS !).

L'id√©al est d'**adapter le nombre de partitions √† la taille d'un bloc** : un bloc mesure 128 MB.
:::

```{r}
#| eval: false
#| echo: true

ma_table <- data.frame(c("Anne", "Paul"), c(25,30))

ma_table_spark <- copy_to(sc, ma_table) %>%
  sdf_coalesce(partitions = 1)

spark_write_parquet(ma_table_spark, "hdfs:///resultats/ma_table.parquet")
```

## Fermer sa session {.smaller}

Il faut imp√©rativement fermer sa session spark apr√®s une session de travail. Deux moyens pour √ßa :

-   fermer R Studio

-   si on ne ferme pas RStudio, utiliser la fonction `spark_disconnect_all()` dans son code

Si on souhaite lancer un code le soir en partant, on n'oublie pas le `spark_disconnect_all()` √† la fin du code.

::: callout-warning
## Partage des ressources

Les ressources r√©serv√©s par un utilisateur ne sont lib√©r√©es pour les autres que lorsqu'il se d√©connecte. Ne pas se d√©connecter, c'est bloquer les ressources. Si j'ai r√©serv√© deux ordinateurs du cluster sur 15, personne d'autres ne peut les r√©server tant que je n'ai pas d√©connecter ma session spark.

Nous fermerons les sessions ouvertes trop longtemps (d√©part de cong√©s sans d√©connexion) si des utilisateurs pr√©sents en ont besoin : risque de perte du travail non enregistr√©.
:::

## T√©l√©charger des donn√©es en local {.smaller}

::: r-stack
![](images/hdfs_browse.png){.fragment width="1000" height="700"}

![](/images/hdfs_dowload.PNG){.fragment}
:::

## Et ensuite ? {.smaller}

Spark est un outil de traitement de donn√©es volumineuses. Il n'est pas toujours adapt√© :

-   **pour de petites tables** : il ne va pas engendrer de gain de temps, voire augmenter le temps

-   **pour faire de l'√©conom√©trie pouss√©e** : tous les packages R ne sont pas traduits en spark

-   **pour ouvrir sa table** : on perd les avantages de spark si on collecte toute la table en m√©moire RAM

**Conseils :**

1.  Cr√©er sa table d'√©tude en appariant les tables de MiDAS avec le cluster spark

2.  L'exporter sous HDFS

3.  La t√©l√©charger en local

4.  La charger en R classique pour faire de l'√©conom√©trie

## Quizz : spark ou pas spark ? {.smaller}

-   faire des statistiques descriptives sur une unique table de 1 million d'individus et 30 variables d√©j√† cr√©√©e

. . .

-   cr√©er une table de 5 millions demandeurs d'emploi avec leur situation au regard de l'emploi (MMO), leur dur√©e d'inscription (DE du FHS)

. . .

-   apparier 4 tables mensuelles de la CNAF pour rep√©rer la liste des `id_midas` b√©n√©ficiaires de minima sociaux 4 mois donn√©s (4 millions chaque mois)

. . .

-   faire de l'√©conom√©trie sur une unique table d√©j√† cr√©√©e

. . .

::: callout-tip
## Econom√©trie et Machine Learning avec Spark

Il existe des outils pour faire de l'√©conom√©trie avec spark, la librairie Apache Spark **MLlib**. Elle rel√®ve d'une utilisation plus avanc√©e de spark que nous ne traitons pas ici. Elle ne contient pas autant de mod√®les que le CRAN R pour la recherche en √©conom√©trie.

Il vous est conseill√© de cr√©er une unique table d'√©tude puis de la traiter en R classique pour l'√©conom√©trie.
:::

# Les bonnes pratiques ü§ù

## Mode local : sch√©ma {.smaller}

![](images/mode_local.PNG)

## Mode local : inadapt√© et mauvaise pratique {.smaller}

<br>

Spark et le mode local :

-   un seul ordinateur alors que spark est fait pour **plusieurs ordinateurs** distincts

-   beaucoup **moins de ressources** disponibles sur la bulle que sur le cluster

-   mauvaise gestion de l'allocation des ressources entre utilisateurs : **pas faite pour plusieurs utilisateurs**

-   ralentissements consid√©rables et bugs : **bloque les autres utilisateurs**

    ‚ñ∂Ô∏èspark n'est adapt√© que pour le cluster de calcul, la bulle pour faire du R sans spark sur des donn√©es peu volumineuses

## Inefficient de prendre beaucoup de ressources {.smaller}

Les ordinateurs du cluster ont besoin de **s'envoyer des donn√©es par le r√©seau** : c'est la partie la plus lente d'un programme spark !

Si j'augmente les ressources : par exemple, je r√©serve 3 ordinateurs du cluster plut√¥t que 2

1.  **Effet puissance de calcul** : plus de ressources pour faire les calculs = r√©duction du temps de calcul

2.  **Effet augmentation des √©changes r√©seau (shuffles)** : augmentation du temps de calcul

3.  **G√™ne des autre utilisateurs**

## Ne pas collecter {.smaller}

::: callout-note
## Collecter, c'est quoi ?

Collecter c'est utiliser l'instruction `collect()`. Elle permet de rapatrier l'ensemble des r√©sultats du cluster vers la bulle et la session R de l'utilisateur en format R, par exemple des `data.frames`.

`Collect()` :

1.  est une **action** : elle d√©clencher tous les calculs

2.  implique des **√©changes r√©seau** tr√®s importants : entre ordinateurs du cluster et du cluster vers la bulle : c'est extr√™mement long, moins efficient que l'enregistrement sur disque directement depuis spark

3.  rappatrie les r√©sultats (une table) dans la m√©moire vive de R, qui est sur la bulle : si le r√©sultat est volumineux, cela **bloque les autres utilisateurs**
:::

Recommandations :

-   Ne pas collecter des tables de plus de 15 Go

-   Utiliser les autres m√©thodes propos√©es pour ne pas bloquer les utilisateurs qui ont besoin de R en mode classique

-   Ne pas changer les configurations

## Fermer sa session {.smaller}

<br>

<br>

<br>

Pour ne pas bloquer les coll√®gues üë®‚Äçüíª

## Yarn {.smaller}

Yarn permet de consulter la r√©servation des ressources par les utilisateurs.

On peut y acc√©der en copiant le lien suivant dans Google chrome sur la bulle (mettre en favori) : midares-deb11-nn-01.midares.local:8088/cluster

V√©rifier que notre session est ferm√©e et qu'on ne prend pas trop de ressources : **yarn**

![](images/yarn_scheduler.PNG)

## Mutualiser les exp√©riences {.smaller}

-   Aide au passage d'un code sur le cluster

-   Programmer entre coll√®gues

-   Contributions √† la documentation MiDAS : section fiches, √† l'aide de pull requests sur github

![](images/documentation_midas_fiches.PNG){fig-align="center"}

# Optimiser le code : non ! Mais optimiser la m√©moire...

## Comment fonctionne spark ? {.smaller}

-   Apache Spark : **librairie open source** d√©velopp√©e dans le langage `scala`

    ```{r}
    #| eval: false
    #| echo: true

    val TopHorrorsIGN2022 = Seq(
      (9, "Pearl"),
      (6, "The Sadness"),
      (6, "Offseason"),
      (7, "Hatching"),
      (8, "x")
    ).toDF("IMDB Rating", "IGN Movie Picks")

    import org.apache.spark.sql.functions.col

    val cols = List(col("IGN Movie Picks"), col("AVC Movie Picks"))

    val query = TopHorrorsIGN2022(
      "IGN Movie Picks"
    ) === TopHorrorsTheAVClub2022("AVC Movie Picks")

    val outerJoin = TopHorrorsIGN2022
      .join(TopHorrorsTheAVClub2022, query, "outer")
      .select(cols: _*)

    outerJoin.show()
    ```

-   `scala` adapt√© pour ma√Ætriser toutes les fonctionnalit√©s de `spark` et optimiser au maximum les traitements en `spark`

-   `spark` est **compatible avec les langages** `scala`, `R`, `python`, `java`, et peut interpr√©ter des commandes **SQL.**

## Le driver en sparklyr {.smaller}

![](/images/schema_cluster.drawio.png){fig-align="center" width="400"}

-   Le programme R est traduit en scala gr√¢ce au package `sparklyr`

-   Le driver √©value le programme, il lit le code `scala` mais n'ex√©cute rien du tout

-   S'il remarque une erreur, l'erreur est envoy√©e directement √† l'utilisateur en session R avant l'ex√©cution du programme : c'est la force de la lazy evaluation.

## Pas besoin d'optimiser son code ! {.smaller}

![](images/catalyst.jpg)

source : documentation CASD disponible √† [Documentation Data Science](https://casd-eu.gitbook.io/data-science/)

## Catalyst optimise le code pour nous {.smaller}

Le driver contient un programme nomm√© Catalyst qui optimise le code `scala` automatiquement.

Spark optimise automatiquement les programmes soumis :

1.  Compilation des transformations pour soulever les √©ventuelles erreurs

2.  Int√©gration dans un **plan d'ex√©cution** contenant les √©tapes n√©cessaires pour parvenir au r√©sultat demand√© par le programme

3.  Optimisation du plan logique par le module **Catalyst** (driver Spark)

## Catalyst optimise le code pour nous {.smaller .scrollable}

![](images/dag.webp){fig-align="center"}

## Catalyst optimise le code pour nous

Par exemple si j'√©cris le programme :

```{r}
#| eval: false 
#| echo: true  

non_optimal <- table_1 %>%   
    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   
    filter(debut_contrat >= as.Date("2023-01-01"))
```

<br>

Catalyst r√©√©crit :

<br>

```{r}
#| eval: false 
#| echo: true  

optimal <- table_1 %>%   
    filter(debut_contrat >= as.Date("2023-01-01")) %>%   
    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))
```

Cette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu'une action d√©clenche l'ex√©cution.

## Catalyst optimise le code pour nous : laissons-le travailler ! {.smaller}

**D√©clencher le moins d'actions possibles** dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.

Pour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique. On √©vite quoi ?

. . .

On √©vite :

-   de mettre des `collect()`sur chaque table interm√©diaire

-   de `collect()` une table enti√®re

-   de `print()` √† chaque √©tape

. . .

Sinon Catalyst n'a pas assez de code pour optimiser !

## Catalyst optimise le code pour nous : laissons-le travailler !

```{r}
#| eval: false 
#| echo: true  

non_optimal <- table_1 %>% 
    collect() %>%
    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   
    filter(debut_contrat >= as.Date("2023-01-01"))

```

. . .

versus

```{r}
#| eval: false 
#| echo: true  

optimal <- table_1 %>%
    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   
    filter(debut_contrat >= as.Date("2023-01-01")) %>%
    head(5) %>% 
    collect()

```

## La longueur du plan logique

Fournir un plan logique tr√®s long sans d√©clencher d'action peut cr√©er une erreur en spark : spark "refuse" d'optimiser un plan si long.

La bonne pratique consiste √† "cacher" des r√©sultats interm√©diaires, pour d√©clencher l'ex√©cution r√©guli√®rement et conserver les r√©sultats en m√©moire, tout en nettoyant la m√©moire des r√©sultat interm√©diaires pr√©c√©dents :

```{r}
#| eval: false
#| echo: true

table_1 <- mon_champ %>%
  left_join(table_2) %>%
  mutate(variable_1 = indicatrice_1 + indicatrice_2,
         regroupement_variable_2 = case_when(variable_2 %in% c(1,2,3) ~ "A",
                                             variable_2 %in% c(5,8,9) ~ "B",
                                             TRUE ~ "C")) %>%
  left_join(table_3) %>%
  sdf_register("table_1")

tbl_cache(sc, "table_1")

table_4 <- table_1 %>%
  left_join(table_5) %>%
  mutate(variable_y = ifelse(variable_x > 50, 1, 0)) %>%
  sdf_register("table_4")

tbl_cache(sc, "table_4")

tbl_uncache(sc, "table_1")
```

## Le r√¥le du cluster manager {.smaller}

![](images/calcul_distribue.drawio.png){fig-align="center"}

Le cluster manager distribue les traitements physiques aux ordinateurs du cluster :

-   il conna√Æt le meilleur plan physique fourni par Catalyst ;

-   il conna√Æt les ressources disponibles et occup√©es par toutes les machines du cluster ;

-   il affecte les ressources disponibles √† la session spark.

## Le r√¥le du worker {.smaller}

![](images/calcul_distribue.drawio.png){fig-align="center"}

Le worker effectue le morceau de programme qu'on lui affecte :

-   il ne conna√Æt que les t√¢ches qu'on lui a affect√©es ;

-   il peut communiquer avec le driver en r√©seau pour renvoyer un r√©sultat ;

-   il peut communiquer avec les autres workers en r√©seau pour partager des donn√©es ou des r√©sultats interm√©diaires : c'est un shuffle.

## Calcul distribu√© et r√©cup√©ration des r√©sultats {.smaller}

![](images/schema_cluster.drawio.png){fig-align="center" width="400"}

::: callout-important
## Le r√©seau

-   Les workers communiquent avec le driver de la bulle MiDARES en r√©seau

-   Les workers communiquent entre eux en r√©seau pour s'√©changer des donn√©es

-   Le r√©seau est un mode de communication lent
:::

::: notes
Mtn un peu de th√©orie pour comprendre le calcul distribu√© et mieux l'utiliser
:::

## Traitement MAP distribu√©

![](images/map_distribue.drawio.png){fig-align="center"}

## Traitement REDUCE distribu√©

![](images/reduce_distribue.drawio.png){fig-align="center"}

## Le stockage distribu√© avec HDFS {.smaller}

![](images/stockage_distribue.drawio.png){fig-align="center"}

## Calcul distribu√©, calcul vectoriel {.smaller}

<br>

Les op√©rations les plus co√ªteuses en spark sont :

-   les op√©rations par **groupe de lignes**, qui impliquent des **shuffles**, ou √©changes de donn√©es entre workers via le r√©seau

-   les op√©rations d'√©criture sur disque avec `spark_write_parquet()`

-   les op√©rations üõë**non vectoris√©es**üõë, qui entra√Ænent des shuffles lourds et inutiles : boucles for, jointures volumineuses...

<br>

Les donn√©es MiDAS sont structur√©es de mani√®re proche d'une **base de donn√©es relationnelles :** leur traitement n√©cessite des jointures. Une partie des donn√©es sont **mensuelles** : cette structure peut inciter √† programmer en boucle for sur le mois, ce qui est long et inefficient.

## Calcul distribu√©, calcul vectoriel : boucles for

<br>

Cas d'usage : je veux rep√©rer si un groupe d'individus est au RSA un mois, deux mois, trois mois etc. apr√®s la sortie de l'assurance-ch√¥mage

J'utilise :

-   le FNA, dont j'extraie une table individu avec le mois de sortie de l'assurance-ch√¥mage, table `sorties`

-   les tables mensuelles de la CNAF `cnaf_prestations_mois_m`

## Calcul distribu√©, calcul vectoriel : boucles for {.smaller .scrollable}

::: panel-tabset
### Solution 1

Lance 12 X tous les mois de sortie jobs spark, beaucoup de shuffles

```{r}
#| eval: false
#| echo: true

library(dplyr)
library(sparklyr)

res_all <- NULL

for (mois in mois_sortie_vec) { # 1√®re boucle sur les mois de sorties
  # Sous-ensemble des sortants de ce mois
  sorties_mois <- sorties %>%
    filter(mois_sortie == !!mois) %>%
    select(id, mois_sortie)

  for (h in 1:12) { # 2√®me boucle sur les 12 mois d'horizon
    
    mois_cible <- as.Date(mois) + months(h)
    nom_tbl <- paste0("cnaf_prestations_", format(mois_cible, "%Y_%m"))
    table_mois_cnaf <- spark_read_parquet(paste0(chemin_table, nom_tbl))

    perception_RSA_mois_h <- sorties_mois %>%
      mutate(mois_h = sql(paste0("add_months(mois_sortie, ", h, ")"))) %>%
      inner_join(table_mois_cnaf, by = c("id" = "id", "mois_h" = "mois")) %>%
      mutate(perception_RSA = ifelse(RSAVERS == "C" & MTRSAVER > 0, 1, 0)) %>%
      transmute(id, mois_sortie, h = !!h, perception_RSA)

    # empiler et mettre en cache le r√©sultat
    res_all <- if (is.null(res_all)) perception_RSA_mois_h else sdf_bind_rows(res_all, perception_RSA_mois_h) %>% sdf_register(paste0("temp", mois, h))
  tbl_cache(sc, paste0("temp", mois, h))
  }
}

```

### Solution 2

Lance 12 jobs et une action √† chaque tour

```{r}
#| eval: false
#| echo: true

for (mois in liste_mois) {
  
  nom_tbl <- paste0("cnaf_prestations_", format(mois, "%Y_%m"))
  table_mois_cnaf <- spark_read_parquet(paste0(chemin_table, nom_tbl))

  # Jointure globale, calcul de l'horizon h 
  perception_RSA_mois <- table_mois_cnaf %>%
    inner_join(sorties, by = "id") %>%
    mutate(h = sql("cast(months_between(mois, mois_sortie) as int)")) %>%
    filter(h >= 1, h <= 12) %>%
    select(id, mois_sortie, h, prest)

  # Cache pour enregistrer le r√©sultat en m√©moire
  perception_RSA_mois_cache <- perception_RSA_mois %>% sdf_register(paste0("temp", mois))
  tbl_cache(sc, paste0("temp", mois))

  res_stack <- if (is.null(res_stack)) joined_cached else sdf_bind_rows(res_stack, joined_cached)
}
```

### Solution 3

Meilleure solution : un seul plan logique que Catalyst peut enti√®rement optimsier, en limitant les shuffles, beaucoup plus rapide

```{r}
#| eval: false
#| echo: true


# Charger la premi√®re table CNAF
nom_1 <- paste0("cnaf_prestations_", format(as.Date("2023-01-01"), "%Y_%m"))
cnaf_total <- spark_read_parquet(paste0(chemin_table, nom_1))

# Empiler les autres
for (mois in liste_mois) {
  
  nom_tbl <- paste0("cnaf_prestations_", format(mois, "%Y_%m"))
  table_mois_cnaf <- spark_read_parquet(paste0(chemin_table, nom_tbl))
  
  cnaf_total <- sdf_bind_rows(cnaf_total, table_mois_cnaf) %>%
    sdf_register("cnaf_total")
  tbl_cache(sc, "cnaf_total")
}


# Joindre UNE fois avec la table des sorties (broadcast si petit)
sorties_b <- sdf_broadcast(sorties %>%
  select(id, mois_sortie)
)

perception_RSA_horizon <- cnaf_total %>%
  inner_join(sorties_b, by = "id") %>%
  mutate(
    h = sql("cast(months_between(mois, mois_sortie) as int)")
  ) %>%
  filter(h >= 1, h <= 12) %>%
  select(id, mois_sortie, h, prest)

```
:::

## Calcul distribu√©, calcul vectoriel : jointures {.smaller}

Une **jointure** implique pour spark de rappatrier les lignes avec les m√™mes valeurs de clef sur le m√™me worker : les jointures engendrent des **shuffles**.

<br>

Lorsque l‚Äôon joint une **grosse table** avec une **petite table**, Spark peut optimiser le calcul en utilisant un **broadcast join** : la petite table est **diffus√©e en entier** sur chaque worker, ce qui √©vite un shuffle massif.

```{r}
#| eval: false
#| echo: true

res <- grosse_table %>%
  inner_join(sdf_broadcast(petite_table), by = "clef")
```

<br>

üëâ Ici petite_table est diffus√©e (broadcast) sur tous les workers : chaque partition de grosse_table fait alors le join localement, sans transfert r√©seau co√ªteux.

## Calcul distribu√©, calcul vectoriel : jointures {.smaller}

**Broadcast automatique** : par d√©faut, Spark choisit automatiquement le broadcast join si la table √† diffuser fait moins de 10 MB (param√®tre configurable).

Au-del√†, il utilise un **shuffle join** classique (plus lent).

**Astuce right_join** : dans sparklyr, la position de la table peut influencer le plan choisi par Spark :

`petite_table %>% left_join(grosse_table)` ‚Üí Spark n‚Äôessaie pas forc√©ment de diffuser la petite.

`grosse_table %>% right_join(petite_table)` ‚Üí Spark choisit plus volontiers un broadcast join.

üëâ Bonne pratique : forcer avec `sdf_broadcast()` quand on sait que la table est petite, plut√¥t que de compter sur ce comportement implicite.

## Calcule distribu√©, calcul vectoriel {.smaller}

+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+
| **Op√©ration logique**                  | **Solution non vectorielle**                         | **Solution vectorielle**                                           |
+========================================+======================================================+====================================================================+
| situation √† m + 1, 2...                | Boucle for sur les mois                              | utilisation de `lag()` et `lead()`, ou auto jointure sur les dates |
+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+
| R√©p√©ter une fonction                   | user defined functions (UDF)                         | √©viter les UDF                                                     |
+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+
| op√©ration groupe de lignes             | `group_by %>% mutate %>% distinct`                   | `group_by %>% summarise`                                           |
+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+
| joindre petite table avec grosse table | `petite_table %>% left_join(grosse_table)`           | broadcast join                                                     |
+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+
| joindre deux grosses tables            | boucle for en divisant les tables en petits morceaux | unique jointure et partition par la clef de jointure               |
+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+
| construire un panel cylindr√©           | boucle for                                           | `cross_join()` de deux tables                                      |
+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+

## La m√©moire du driver

![](images/collect.drawio.png){fig-align="center"}

## L'utilisation de la m√©moire du driver {.smaller .scrollable}

Cette configuration permet de collecter des statistiques descriptives et de petites tables sans g√™ner les autres utilisateurs.

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "2"

conf <- spark_config()
conf["spark.driver.memory"] <- "20Go"
conf["spark.executor.memory"] <- "80Go"
conf["spark.executor.cores"] <- 5
conf["spark.executor.instances"] <- 2
cont["spark.yarn.queue"] <- "prod"
conf["spark.driver.maxResultSize"] <- 0

sc <- spark_connect(master = "yarn", config = conf)
```

::: callout-caution
## Bonne pratique de partage des ressources

Le driver est dans la bulle Midares, qui a vocation √† √™tre r√©duite suite √† la g√©n√©ralisation du cluster.

-   La bulle Midares a besoin de RAM pour fonctionner, 100% des ressources ne sont donc pas disponibles pour `sparklyr`.

-   Pour permettre le **travail simultan√© fluide de 10 utilisateurs**, la m√©moire allou√©e au driver recommand√©e pour chaque utilisateur est de **maximum 20 Go**.

-   Il existe des alternatives pour ne pas collecter des r√©sultats trop volumineux dans le driver.
:::

## Programmer sans collecter {.smaller}

La programmation en spark doit √™tre adapt√©e aux contraintes de volum√©trie des donn√©es : test de chaque √©tape, puis ne forcer le calcul qu'√† la fin pour que Catalyst optimise l'ensemble du programme

La principale diff√©rence avec la programmation en R classique est que **la visualisation de tables compl√®tes volumineuses n'est pas toujours possible et n'est pas recommand√©e** :

-   **goulets d'√©tranglement** m√™me avec spark, car toutes les donn√©es sont rapatri√©es vers le driver puis vers la session R : erreurs Out of Memory

-   **longue :** √©change entre tous les noeuds impliqu√©s dans le calcul et le driver, puis un √©change driver-session R en r√©seau = lent ;

-   **beaucoup moins efficace que l'export direct en parquet** du r√©sultat (qui fonctionne toujours) : charger ensuite sa table finale en data frame R classique pour effectuer l'√©tude.

S'il est n√©cessaire de collecter, il faut pr√©voir **beaucoup de RAM pour le driver avec le param√®tre** `spark.driver.memory`, ce qui emp√™che les autres utilisateurs de travailler.

## Programmer sans collecter {.smaller}

Les r√©sultats qu'il est recommand√© de r√©cup√©rer en m√©moire vive en session R sont de la forme suivante :

-   **une table filtr√©e** avec les variables n√©cessaires √† l'√©tude uniquement : sous MiDAS, toutes les jointures, les calculs de variable et les filtres peuvent √™tre effectu√©s de mani√®re efficiente sous la forme de spark_data_frame, sans jamais collecter les donn√©es MiDAS ;

-   des **statistiques descriptives synth√©tiques ;**

-   les **premi√®res lignes** de la table pour v√©rifier que le programme retourne bien le r√©sultat attendu ;

-   une **table agr√©g√©e** pour un graphique par exemple, √† l'aide de la fonction `summarise()`.

## Programmer sans collecter {.smaller}

Je sais que la cr√©ation de ma table donne le r√©sultat souhait√©e (car j'ai regard√© ce dont elle a l'air avvec `head()`), maintenant je vais l'appeler une dizaine de fois pour collecter uniquement des statistiques descriptives.

Que se passe-t-il √† chaque fois que je collecte une statistique descriptive ?

. . .

La cr√©ation de la table va √™tre ex√©cut√©e √† nouveau : tr√®s long ?

Comment faire ?

::: panel-tabset
## Cache

La cr√©ation de la table est ex√©cut√©e une seule fois, le r√©sultat est conserv√© en m√©moire vive

```{r}
#| eval: false
#| echo: true

ma_table_spark <- MMO_2017 %>%
  filter(DebutCTT > as.Date("2017-06-01")) %>%
  mutate(duree_CTT = DATEDIFF(FinCTT,DebutCTT) + 1) %>%
  sdf_register(name = "ma_table_spark")

tbl_cache("ma_table_spark")
```
:::

::: notes
R√©ponse attendue : c'est une action donc ca d√©clenche la cr√©ation de la table Indice : cr√©ation de table contient uniquement des transformations
:::

## Optimiser la m√©moire : conclusion

Pour programmer en spark sans aucune erreur :

1.  D√©clencher une action avec plusieurs transformations pour laisser Catalyst optimiser

2.  Ne pas collecter tout une table

3.  Persister ou cacher une table qu'on va appeler plusieurs fois pour ne collecter que des statistiques descriptives

4.  Ne pas persister trop de tables : occupe de la m√©moire RAM

5.  Consulter le programme exemple sur la bulle CASD si besoin

# Pour aller plus loin

## Partitionnement {.smaller}

Le format `.parquet` (avec `arrow`) et le framework `spark` permettent de g√©rer le partitionnement des donn√©es.

Le partitionnement a un impact sur la mani√®re dont les donn√©es sont organis√©es physiquement sur le syst√®me de fichiers.

![](images/partitioned_parquet_file_archi.png){fig-align="center" width="1000"}

## Partitionnement {.smaller}

<br>

+----------------------------------------+-----------+-----------+-----------+
| Partitions                             | 2         | 5         | 1000      |
+========================================+===========+===========+===========+
| Colonne qui a servi au partitionnement | 74,50%    | 46,30%    | 16,66%    |
+----------------------------------------+-----------+-----------+-----------+
| Vers une autre colonne                 | 89,51%    | 191,01%   | 556,99%   |
+----------------------------------------+-----------+-----------+-----------+
| Select distinct(\*)                    | 136,79%   | 163,68%   | 1194,88%  |
+----------------------------------------+-----------+-----------+-----------+

<br>

```{r}
#| eval: false
#| echo: true

spark_write_parquet(ma_table, "hdfs:///resultats/ma_table.parquet", partition_by = c("age","sex"))

```

## √âviter le probl√®me des ex√©cuteurs inactifs {.smaller}

Supposons que le jeu de donn√©es ait 8 partitions, un ex√©cuteur (avec seulement 1 core) ne peut ex√©cuter qu'une t√¢che(task) √† la fois, et une partition = une t√¢che.

Cas 1 : 6 ex√©cuteurs, au dernier tour, il ne reste que 2 t√¢ches, 4 ex√©cuteurs seront inactifs. Cas 2 : 4 ex√©cuteurs, 2\*4, aucun ex√©cuteur inactif.

```{r}
#| eval: false
#| echo: true

# Get the number of partitions
num_partitions <- sdf_num_partitions(df)
print(num_partitions)

# Repartition the DataFrame to a specific number of partitions
df_repartitioned <- sdf_repartition(df, partitions = 10)
```

-   Le nombre de partitions doit √™tre divisible par le nombre d'ex√©cuteurs.
-   Le nombre de partitions doit √™tre sup√©rieur au nombre d'ex√©cuteurs.

## √âviter trop de partitions {.smaller}

La cr√©ation de t√¢ches entra√Æne des surcharges, qui doivent toujours √™tre inf√©rieures √† 50 % du temps total d'ex√©cution de la t√¢che.

![](images/stage_eventtimeline.png)

-   <div>

    ```{r}
    #| eval: false
    #| echo: true

    # Repartition the DataFrame to a specific number of partitions
    df_repartitioned <- sdf_repartition(df, partitions = 10)

    # Repartition the DataFrame by a specific column, e.g., "commune_code".
    # The partition number will be the distinct value number
    df_repartitioned <- sdf_repartition(df, partition_by = "commune_code")
    ```

    </div>

-   La r√©partition est une op√©ration tr√®s co√ªteuse, utilisez-la judicieusement.

-   En g√©n√©ral, la taille recommand√©e des partitions est d'environ 128 √† 512 Mo.

## Optimiser la configuration des ex√©cuteurs {.smaller}

Configuration recommand√©e :

-   Un ex√©cuteur devrait avoir entre 3 et 5 cores.
-   Pour chaque core, il faut r√©server entre 4 et 8 Go de m√©moire.

En mode cluster, chaque ex√©cuteur fonctionne dans une JVM (la JVM n√©cessite une m√©moire suppl√©mentaire et du CPU pour ex√©cuter le GC).

-   √âvitez 1 core par ex√©cuteur.
-   √âvitez trop de cores dans un seul ex√©cuteur, cela peut causer des probl√®mes de contention de threads ou la surcharge du garbage collector.

## T√¢ches Maximales en parall√®les {.smaller}

<br>

::: callout-tip
## Parall√©lisation

**Max_Parallel_Tasks = Number_of_Executors \* Cores_per_Executor**
:::

<br>

Par exemple, une session Spark dispose de la configuration suivante :

```{r}
#| eval: false
#| echo: true
#| 
conf["spark.executor.memory"] <- "32Go"
conf["spark.executor.cores"] <- 4
conf["spark.executor.instances"] <- 5
```

5 executor \* 4 core = 20 t√¢ches en parall√®le. Pour un jeu de donn√©es de 200 partitions, il faut 10 tours pour terminer tous les calculs.

<br>

‚ñ∂Ô∏èIl n'existe pas de configuration universelle optimale pour tous, seulement la meilleure configuration pour vos t√¢ches.

## SparkUI {.smaller .scrollable}

Spark UI permet de consulter le plan logique et physique du traitement demand√©. Trois outils permettent d'optimiser les traitements :

::: panel-tabset
## DAG

![](images/dag.webp)

## GC

V√©rifier que le `gc time` est inf√©rieur √† 10% du temps pour ex√©cuter la t√¢che ‚úÖ

![](images/gc.png)

## M√©moire

V√©rifier que la `storage memory` ne sature pas la m√©moire ‚úÖ

![](images/gc.png)
:::

## Sparkhistory {.smaller .scrollable}

-   **Sparkhistory** pour des traitements de sessions ferm√©es

Le sparkhistory entra√Æne l'enregistrement de logs assez lourdes, il est donc d√©sactiv√© par d√©faut. Pour l'activer sur un programme :

```{r}
#| eval: false
#| echo: true

conf <- spark_config()
conf["spark.eventLog.enabled"] <- "true"
conf["spark.eventLog.dir"] <- "hdfs://midares-deb11-nn-01.midares.local:9000/spark-logs"
conf["appName"] <- "un_nom_de_traitement"

sc <- spark_connect(master = "yarn", config = conf)


```

## Pyspark

<br>

![](images/pyspark.drawio.png){fig-align="center"}

# Annexe

## Le stockage distribu√© avec HDFS {.smaller}

Hadoop Distributed File System (HDFS)

-   **stockage sur diff√©rentes machines :** les diff√©rents ordinateurs workers du cluster

-   donn√©es divis√©es **en blocs** plus petits de taille fixe et r√©partis sur les machines : aucune table de MiDAS n'existe en entier sur le cluster

-   chaque bloc est **r√©pliqu√© trois fois** : il existe trois fois les 10 premi√®res lignes de la table FNA sur trois ordinateurs diff√©rents du cluster (r√©silience)

-   un **NameNode** supervise les **m√©tadonn√©es** et g√®re la structure du syst√®me de fichiers : il sait o√π sont quels fichiers

-   les **DataNodes** stockent effectivement les blocs de donn√©es : les datanodes sont en fait les disques durs des workers du cluster, chaque ordinateur du cluster dispose d'un disque avec une partie des donn√©es MiDAS

-   le **syst√®me HDFS** est reli√© √† la bulle Midares : possible de charger des donn√©es en clique-bouton de la bulle vers HDFS de mani√®re tr√®s rapide et de t√©l√©charger des tables de HDFS pour les r√©cup√©rer en local
