{
  "hash": "2a5d3e3b63c9e2dbf2faa92ebe403687",
  "result": {
    "markdown": "---\ntitle: \"Initiation √† Spark avec R en mode cluster\"\nformat: revealjs\n---\n\n\n## Au programme\n\n1.  MiDAS : une base de donn√©es volumineuse\n\n2.  Utiliser MiDAS avec R : un d√©fi\n\n3.  Sparklyr : l'outil ergonomique de spark en R\n\n4.  Optimiser la m√©moire : pourquoi et comment\n\n5.  Les bonnes pratiques\n\n6.  Pour aller plus loin\n\n# Un rapide tour de table üí¨\n\n# MiDAS : une base de donn√©es volumineuses\n\n## Qu'est-ce que MiDAS ?\n\n![](/images/midas_traj_1.PNG){fig-align=\"right\" width=\"900\"}\n\n![](/images/midas_traj_2.PNG){fig-align=\"right\" width=\"780\"}\n\n## Une des bases les plus volumineuses du SSP {.smaller}\n\n![](/images/donnees_ssp.PNG){fig-align=\"center\"}\n\nLes administrations dont les donn√©es sont comparables √† MiDAS utilisent un cluster Spark : Insee, Drees, Acoss...\n\n‚ñ∂Ô∏èLe cluster spark est une solution la tr√®s efficiente pour traiter des donn√©es de cette ampleur.\n\n## Concr√®tement, qu'est-ce que MiDAS ? {.smaller}\n\n![](/images/structure_midas.png){fig-align=\"center\"}\n\n::: callout-tip\n## Pourquoi Spark ?\n\nLa manipulation des donn√©es MiDAS en l'√©tat implique de nombreuses op√©rations de jointures qui n√©cessitent une puissance de calcul et un temps certains.\n:::\n\n## O√π est MiDAS sur la bulle ? {.smaller}\n\nDisponible dans l'espace commun (= Documents publics) : C:\\\\Users\\\\Public\\\\Documents\\\\MiDAS_parquet\\\\Vague X\n\n<br>\n\nAu format **parquet** :\n\n-   **compression** efficace des donn√©es : taux de compression de 5 √† 10 par rapport au format csv\n\n-   orient√© **colonnes**\n\n-   chargement efficace **en m√©moire** des donn√©es\n\n-   **stockage partitionn√©** des donn√©es avec `write_dataset()`\n\n-   traiter des donn√©es **sur disque**\n\n-   **ind√©pendant du logiciel** utilis√© : R, python, spark...\n\n## La documentation en ligne {.smaller}\n\n<br>\n\n::: columns\n::: {.column width=\"35%\"}\n[Documentation en ligne](https://documentationmidas.github.io/Documentation_MiDAS/Presentation/pr%C3%A9sentation.html)\n\n-   Dictionnaire des donn√©es\n\n-   Fiches pr√©sentant les concepts de l'indemnisation, du retour √† l'emploi\n\n-   Exemples d'impl√©mentation en R\n\n-   Conseils quallit√© des variables\n:::\n\n::: {.column width=\"65%\"}\n![](/images/documentation_midas.PNG){fig-align=\"center\"}\n:::\n:::\n\n# Et vous, quels sont vos usages de MiDAS ? üëÅÔ∏è‚Äçüó®Ô∏è\n\n# Traiter MiDAS en R : un d√©fi üë®‚Äçüíª\n\n## Une bulle CASD {.smaller}\n\nDes ressources partag√©es entre tous les utilsateurs simultan√©s :\n\n-   512 Go de m√©moire vive (ou RAM) : passage √† 256 Go\n-   Un processeur (ou CPU) compos√© de 32 coeurs : passage √† 16 coeurs\n\n![](/images/schema_ordinateur.png){fig-align=\"center\"}\n\n## Une bulle CASD {.smaller}\n\n::: panel-tabset\n### La m√©moire vive\n\nLa m√©moire vive, aussi appel√©e **RAM**, se distingue de la m√©moire de stockage (disque) :\n\n-   par sa **rapidit√©**, notamment pour fournir des donn√©es au processeur pour effectuer des calculs\n\n-   par sa **volatilit√©** (toutes les donn√©es sont perdues si l'ordinateur n'est plus aliment√©)\n\n-   par l'acc√®s direct aux informations qui y sont stock√©es, **quasi instantann√©**.\n\n### Le processeur\n\nLe processeur :\n\n-   permet d'**ex√©cuter des t√¢ches et des programmes** : convertir un fichier, ex√©cuter un logiciel\n\n-   est compos√© d'un ou de plusieurs **coeurs** : un coeur ne peut ex√©cuter qu'une seule t√¢che √† la fois. Si le processeur contient plusieurs coeurs, il peut ex√©cuter autant de t√¢ches en parall√®le qu'il a de coeurs\n\n-   se caract√©rise aussi par sa **fr√©quence** : elle est globalement proportionnelle au nombre d'op√©rations qu'il est capable d'effetuer par seconde.\n:::\n\n## Traiter MiDAS en R : les limites\n\n1.  Charger les donn√©es en m√©moire vive\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  path_fna <- \"C:/Users/Public/Documents/MiDAS_parquet/Vague 4/FNA/\"\n  \n  PJC <- read_parquet(paste0(path_fna, \"pjc.parquet\"), memory = TRUE)\n  ODD <- read_parquet(paste0(path_fna, \"odd.parquet\"), memory = TRUE)\n```\n:::\n\n\n. . .\n\n2.  R√©aliser des op√©rations co√ªteuses en ressources\n\n\n::: {.cell}\n\n```{.r .cell-code}\njointure <- PJC %>%\n  rename(KROD1 = KROD3) %>%\n  left_join(ODD, by = c(\"id_midas\", \"KROD1\"))\n```\n:::\n\n\n. . .\n\n3.  Le partage des ressources de la bulle\n\nChaque utilisateur peut mobiliser toutes les ressouces de la bulle.\n\n## Traitement l√©ger versus co√ªteux {.smaller}\n\n::: panel-tabset\n## MAP = l√©ger {.smaller}\n\n![](/images/formation%20sparklyr-Page-1.drawio.png){fig-align=\"center\"}\n\n::: notes\nCe traitement est peu co√ªteux :\n\n-   chargement d'une seule colonne en RAM : format parquet orient√© colonnes\n\n-   peu de m√©moire d'ex√©cution : R est un langage vectoris√©\n:::\n\n## REDUCE = co√ªteux {.smaller}\n\n![](/images/formation%20sparklyr-Page-2.drawio.png){fig-align=\"center\"}\n\n::: notes\nCe traitement n√©cessite :\n\n-   le chargement de davantage de colonnes en m√©moire vive ;\n\n-   davantage de m√©moire d'ex√©cution pour effectuer l'intersection (`inner_join()`).\n:::\n\n## REDUCE en R\n\n-   les jointures\n\n-   les op√©rations en `group_by()`\n\n-   `distinct()`\n\n    ‚ñ∂Ô∏è Ex√©cution s√©quentielle sur un coeur du processeur + beaucoup de m√©moire vive (donn√©es temporaires)\n\n    ‚ñ∂Ô∏è Erreur \"out of memory\".\n:::\n\n## Pourquoi spark ? {.smaller}\n\n+------------------------+------------------------+----------------------------------+\n| Solution test√©e        | Avantage               | Limites rencontr√©e               |\n+========================+========================+==================================+\n| Package ¬´ data.table ¬ª | Calculs parall√©lis√©s   | pour bases \\< RAM                |\n|                        |                        |                                  |\n|                        |                        | Syntaxe tr√®s diff√©rente de dplyr |\n+------------------------+------------------------+----------------------------------+\n| Format ¬´ parquet ¬ª +   | Stockage moins lourd   | Taille en m√©moire inchang√©e      |\n|                        |                        |                                  |\n| package ¬´ arrow ¬ª      | Chargement efficient   |                                  |\n+------------------------+------------------------+----------------------------------+\n| DuckDB                 | Gestionnaire de BDD    | Pour des bases \\< 100 Go         |\n|                        |                        |                                  |\n|                        |                        | Fonctions et options non cod√©es  |\n+------------------------+------------------------+----------------------------------+\n| Spark en mode local    | Traitements distribu√©s | Consomme beaucoup de ressources  |\n|                        |                        |                                  |\n|                        |                        | Inadapt√© pour une unique bulle   |\n|                        |                        |                                  |\n|                        |                        | N√©cessite le ¬´ collect() ¬ª       |\n+------------------------+------------------------+----------------------------------+\n\n## Un gain de temps consid√©rable {.smaller}\n\n<br>\n\n+---------------------+-----------------------------------------+---------------------------------------------+\n|                     | Calcul de la dur√©e moyenne d'un contrat | Retour √† l'emploi salari√© des indemnisables |\n+=====================+=========================================+=============================================+\n| Classique R         | 4 heures                                | Crash                                       |\n+---------------------+-----------------------------------------+---------------------------------------------+\n| Arrow + duckdb      | 8 minutes                               | 3 heures seul sur la bulle                  |\n+---------------------+-----------------------------------------+---------------------------------------------+\n| Arrow + spark local | 1 minute                                | 2 minutes                                   |\n+---------------------+-----------------------------------------+---------------------------------------------+\n\nMais alors, pourquoi le cluster ? ü§î\n\n# Et vous, quels sont vos probl√©matiques et vos solutions ? ‚ö†Ô∏è\n\n# Comment on fait du spark cluster avec R version courte ? ‚è≤Ô∏è\n\n## O√π est Midas, 2√®me √©dition {.smaller}\n\nLe cluster a son propre explorateur de fichiers √† mettre en favori dans son navigateur : https://midares-deb11-nn-01.midares.local:9870/\n\n::: r-stack\n![](/images/hdfs_browse.png){.fragment fig-align=\"center\" width=\"900\" height=\"500\"}\n\n![](/images/hdfs_midas.png){.fragment fig-align=\"center\" width=\"900\" height=\"500\"}\n:::\n\n## Un cluster de calcul\n\n![](/images/schema_cluster.drawio.png){fig-align=\"center\"}\n\n## Connexion\n\n::: panel-tabset\n## Traitement l√©ger\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"60Go\"\nconf[\"spark.executor.cores\"] <- 4\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n## Traitement lourd\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(dbplyr)\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"140Go\"\nconf[\"spark.executor.cores\"] <- 8\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n:::\n\n## Chargement des donn√©es en spark\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Depuis HDFS\nmmo_17_df_spark <- spark_read_parquet(sc,\n                                  path = \"hdfs:///dataset/MiDAS_v4/mmo/mmo_2017.parquet\",\n                                  memory = FALSE)\n\n### Passer un dataframe R en spark\nmon_data_frame <- data.frame(c(\"Anna\", \"Paul\"), c(15, 20))\nmon_data_frame_spark <- copy_to(sc, \"mon_data_frame\")\n```\n:::\n\n\n<br>\n\n‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : par d√©faut, `memory = FALSE`\n\n## Sparklyr, c'est comme dplyr\n\nEnsuite, vous pouvez programmer avec `dplyr` !\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmmo_17_df_spark <- mmo_17_df_spark %>%\n  rename(debut_contrat = DebutCTT) %>%\n  filter(debut_contrat >= as.Date(\"2017-01-01\") & debut_contrat < as.Date(\"2017-02-01\")) %>%\n  mutate(mois_debut_contrat = substr(debut_contrat,6,7))\n```\n:::\n\n\n## La lazy evaluation {.smaller}\n\nSpark distingue deux types d'op√©rations :\n\n-   **les transformations :** prennent en entr√©e un `spark_data_frame` et retournent un `spark_data_frame`, elles ne d√©clenchent aucun calcul\n\n    Par exemple, le programme ci-dessous ne d√©clenche pas d'ex√©cution :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmmo_17_df_spark_mois <- mmo_17_df_spark %>%\n  rename(debut_contrat = DebutCTT) %>%\n  filter(debut_contrat >= as.Date(\"2017-01-01\") & debut_contrat < as.Date(\"2017-06-01\")) %>%\n  mutate(mois_debut_contrat = substr(debut_contrat,6,7))\n```\n:::\n\n\n-   **les actions :** forcent le calcul d'un r√©sultat pour le r√©cup√©rer et d√©clenchent l'ex√©cution de toutes les transformations compil√©es jusqu'√† l'appel de l'action.\n\n    Par exemple, le programme ci-dessous d√©clenche le calcul de toute la cellule pr√©c√©dente :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_debut_contrat_fev_17 <- mmo_17_df_spark_mois %>%\n  group_by(mois_debut_contrat) %>%\n  summarise(nb_contrats = n()) %>%\n  print()\n```\n:::\n\n\n## R√©cup√©rer un r√©sultat\n\nLes principales actions sont :\n\n-   `print()`\n\n-   `collect()`\n\n-   `head()`\n\n-   `tbl_cache()` (√©crire un `spark_data_frame` en m√©moire pour le r√©utiliser)\n\n## ... presque tout comme dplyr {.smaller .scrollable}\n\n::: panel-tabset\n## Dates\n\nLes fonctions de `lubridate()`ne sont pas adapt√©es au `spark_data_frames`.\n\n-   Convertir une cha√Æne de caract√®re de la forme AAAA-MM-DD en Date\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    date_1 <- as.Date(\"2024-05-26\")\n    ```\n    :::\n\n\n-   Calculer une dur√©e entre deux dates\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    PJC_spark <- spark_read_parquet(sc,\n                                    path = \"hdfs:///dataset/MiDAS_v4/pjc.parquet\",\n                                    memory = FALSE)\n    \n    duree_pjc_df <- PJC_spark %>%\n      rename(date_fin_pjc = as.Date(KDFPJ),\n             date_deb_pjc = as.Date(KDDPJ)) %>%\n      mutate(duree_pjc = datediff(date_fin_pjc, date_deb_pjc) + 1) %>%\n      head(5)\n    ```\n    :::\n\n\n-   Ajouter ou soustraire des jours ou des mois √† une date\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    duree_pjc_bis_df <- duree_pjc_df %>%\n      mutate(duree_pjc_plus_5 = date_add(duree_pjc, int(5)),\n             duree_pjc_moins_5 = date_sub(duree_pjc, int(5)),\n             duree_pjc_plus_1_mois = add_months(duree_pjc, int(1))) %>%\n      head(5)\n    ```\n    :::\n\n\n::: callout-note\n## Add_months\n\nSi la date en entr√©e est le dernier jour d'un mois, la date retourn√©e avec `add_months(date_entree, int(1))` sera le dernier jour calendaire du mois suivant.\n:::\n\n::: callout-tip\n## Format\n\nLe `int()` est important car ces fonctions Hive n'accepte que les entiers pour l'ajout de jours : taper uniquement 5 est consid√©r√© comme un flottant dans R.\n:::\n\n## Tableau\n\n-   Tri dans un groupe pour effectuer un calcul s√©quentiel\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_spark <- spark_read_parquet(sc,\n                                    path = \"hdfs:///dataset/MiDAS_v4/odd.parquet\",\n                                    memory = FALSE)\n    \n    ODD_premier <- ODD_spark %>%\n      group_by(id_midas) %>%\n      window_order(id_midas, KDPOD) %>%\n      mutate(date_premier_droit = first(KDPOD)) %>%\n      ungroup() %>%\n      distinct(id_midas, KROD3, date_premier_droit) %>%\n      head(5)\n    ```\n    :::\n\n\n-   Tri pour une sortie : `sdf_sort()` , `arrange()` ne fonctionne pas\n\n-   Concat√©ner les lignes (ou les colonnes `sdf_bind_cols()`)\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_1 <- ODD_spark %>%\n      filter(KDPOD <= as.Date(\"2017-12-31\")) %>%\n      mutate(groupe = \"temoins\")\n    \n    ODD_2 <- ODD_spark %>%\n      filter(KDPOD >= as.Date(\"2021-12-31\")) %>%\n      mutate(groupe = \"traites\")\n    \n    ODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)\n    ```\n    :::\n\n\n-   D√©doublonner une table\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    droits_dans_PJC <- PJC_spark %>%\n      sdf_distinct(id_midas, KROD3)\n    \n    print(head(droits_dans_PJC, 5))\n    \n    PJC_dedoublonnee <- PJC_spark %>%\n      sdf_drop_duplicates()\n    \n    print(head(PJC_dedoublonnee, 5))\n    ```\n    :::\n\n\n-   Pivot : les fonctions du packag `tidyr` ne fonctionnent pas sur donn√©es spark\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_sjr_moyen <- ODD_spark %>%\n      mutate(groupe = ifelse(KDPOD <= as.Date(\"2020-12-31\"), \"controles\", \"traites\")) %>%\n      sdf_pivot(groupe ~ KCRGC,\n        fun.aggregate = list(KQCSJP = \"mean\")\n      )\n    ```\n    :::\n\n\n## Statistiques\n\n-   R√©sum√© statistique : `sdf_describe()` , `summary()`ne fonctionne pas.\n\n-   Dimension : `sdf_dim`, la fonction `nrow()`ne fonctionne pas.\n\n-   Quantiles approximatifs : le calcul des quantiles sur donn√©es distirbu√©es renvoie une approximation car toutes les donn√©es ne peuvent pas √™tre rappatri√©es sur la m√™me machine physique du fait de la volum√©trie, `sdf_quantile()`\n\n-   Echantillonnage al√©atoire : `sdf_random_split`\n:::\n\n## Exporter des donn√©es {.smaller}\n\nExport des spark data frames directement sous HDFS.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma_table <- data.frame(c(\"Anne\", \"Paul\"), c(25,30))\n\nma_table_spark <- copy_to(sc, ma_table)\n\nspark_write_parquet(ma_table_spark, \"hdfs:///resultats/ma_table.parquet\")\n```\n:::\n\n\nPossibilit√© de r√©cup√©rer ce fichier sur la bulle MiDARES = en local.\n\n::: callout-warning\n## Exports simultan√©s\n\nHDFS supporte les exports simultan√©s, mais le temp d'export est plus long lorsque le NameNode est requ√™t√© par plusieurs personnes simultan√©ment : d'apr√®s les tests cluster\n\n-   pour un petit export (5 minutes), le temps peut √™tre multipli√© par 4 ;\n\n-   pour un gros export (15 minutes), le temps peut √™tre multipli√© par 2.\n:::\n\n## Si on souhaite la r√©cup√©rer en local\n\n::: callout-caution\n## Les exports sur HDFS\n\nLorsqu'on exporte une table depuis notre session R vers HDFS, celle-ci est **automatiquement partitionn√©e**, comme le reste des donn√©es.\n\nAinsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.\n\nIl est possible de ma√Ætriser le nombre de partitions avec la commande `sdf_coalesce(partitions = 5)` du package `sparklyr`.\n\nL'id√©al est d'**adapter le nombre de partitions √† la taille d'un bloc** : un bloc mesure 128 MB. Lorsqu'un bloc disque est utilis√©, m√™me √† 1%, il n'est pas utilisable pour un autre stockage.\n\nExporter un fichier de 1MB en 200 partitions r√©serve 200 blocs inutilement.\n:::\n\n\n## T√©l√©charger des donn√©es en local {.smaller}\n\n::: r-stack\n![](images/hdfs_browse.png){.fragment width=\"1000\" height=\"700\"}\n\n![](/images/hdfs_dowload.PNG){.fragment}\n:::\n\n# Optimiser le code : non ! Mais optimiser la m√©moire...\n\n## Pas besoin d'optimiser son code !\n\n## La m√©moire du driver\n\n## Programmer sans collecter\n\n## Cacher une table\n\n\n# Les bonnes pratiques\n\n## Spark local : non\n\n## Inutile de prendre toutes les ressources \n\n## Fermer sa session\n\n## Mutualiser les exp√©riences\n\n\n# Pour aller plus loin\n\n## Partitionnement\n\nLe format `.parquet` (avec `arrow`) et le framework `spark` permettent de g√©rer le partitionnement des donn√©es.\n\nSi les op√©rations sont souvent effectu√©es par r√©gions par exemple, il est utile de forcer le stockage des donn√©es d'une m√™me r√©gion au m√™me endroit physique et acc√©l√®re drastiquement le temps de calcul :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_write_parquet(ma_table, \"hdfs:///resultats/ma_table.parquet\", partition_by = c(\"region\"))\n```\n:::\n\n\n## SparkUI\n\n## Yarn\n\n## Pyspark",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}