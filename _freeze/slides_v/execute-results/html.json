{
  "hash": "299f75e4e32ca55534becf90e9853156",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Initiation √† Spark avec R en mode cluster\"\nformat: revealjs\n---\n\n\n\n\n## Au programme\n\n1.  MiDAS : une base de donn√©es volumineuse üìö\n\n2.  Utiliser MiDAS avec R : un d√©fi üí≠\n\n3.  Sparklyr : l'outil ergonomique de spark en R üë®‚Äçüíª\n\n4.  Les bonnes pratiques sur une infrastructure partag√©e üñ•Ô∏è\n\n5.  Optimiser la m√©moire : pourquoi et comment ‚è≥\n\n6.  Pour aller plus loin üí°\n\n# Un rapide tour de table üí¨\n\n::: notes\nPoste, usages de R, connaissance spark\n:::\n\n# MiDAS : une base de donn√©es volumineuse üìö\n\n## Qu'est-ce que MiDAS ?\n\n![](/images/midas_traj_1.PNG){fig-align=\"right\" width=\"900\"}\n\n![](/images/midas_traj_2.PNG){fig-align=\"right\" width=\"780\"}\n\n## Une des bases les plus volumineuses du SSP {.smaller}\n\n![](/images/donnees_ssp.PNG){fig-align=\"center\"}\n\nLes administrations dont les donn√©es sont comparables √† MiDAS utilisent un cluster Spark : Insee, Drees, Acoss, UNEDIC, Cnaf\n\n‚ñ∂Ô∏èLe cluster spark est une solution tr√®s efficiente pour traiter des donn√©es de cette ampleur.\n\n## Concr√®tement, qu'est-ce que MiDAS ? {.smaller}\n\n![](/images/structure_midas.png){fig-align=\"center\"}\n\n::: callout-tip\n## Pourquoi Spark ?\n\nLa manipulation des donn√©es MiDAS en l'√©tat implique de nombreuses op√©rations de jointures qui n√©cessitent une puissance de calcul et un temps certains.\n:::\n\n## O√π est MiDAS sur la bulle ? {.smaller}\n\nDisponible dans l'espace commun (= Documents publics) : C:\\\\Users\\\\Public\\\\Documents\\\\MiDAS_parquet\\\\Vague X\n\n<br>\n\nAu format **parquet** :\n\n-   **compression** efficace des donn√©es : taux de compression de 5 √† 10 par rapport au format csv\n\n-   orient√© **colonnes**\n\n-   chargement efficace **en m√©moire** des donn√©es\n\n-   **stockage partitionn√©** des donn√©es avec `write_dataset()`\n\n-   traiter des donn√©es **sur disque**\n\n-   **ind√©pendant du logiciel** utilis√© : R, python, spark...\n\n## La documentation en ligne {.smaller}\n\n<br>\n\n::::: columns\n::: {.column width=\"35%\"}\n[Documentation en ligne](https://documentationmidas.github.io/Documentation_MiDAS/Presentation/pr%C3%A9sentation.html)\n\n-   Dictionnaire des donn√©es\n\n-   Fiches pr√©sentant les concepts de l'indemnisation, du retour √† l'emploi\n\n-   Exemples d'impl√©mentation en R\n\n-   Conseils qualit√© des variables\n:::\n\n::: {.column width=\"65%\"}\n![](/images/documentation_midas.PNG){fig-align=\"center\"}\n:::\n:::::\n\n::: notes\nContribuer avec github, montrer le github, dire que sur le read me conseils pour contribuer et mettre des codes, espace de partage de codes √† venir\n:::\n\n# Et vous, quels sont vos usages de MiDAS ? üëÅÔ∏è‚Äçüó®Ô∏è\n\n::: notes\nUtilisation midas, √©tudes\n:::\n\n# Traiter MiDAS en R : un d√©fi üë®‚Äçüíª\n\n## Une bulle CASD {.smaller}\n\nDes ressources partag√©es entre tous les utilsateurs simultan√©s :\n\n-   256 Go de m√©moire vive (ou RAM)\n-   Un processeur (ou CPU) compos√© de 16 coeurs\n\n![](/images/schema_ordinateur.png){fig-align=\"center\"}\n\n::: notes\nBulle CASD = un gros ordinateur partag√© par plusieurs utilisateurs, besoin du voc ordinateur pour comprendre spark\n:::\n\n## Une bulle CASD {.smaller}\n\n::: panel-tabset\n### Le disque dur\n\nLe disque dur, aussi appel√© **Hard Disk Drive (HDD)**, est une solution de **stockage permanente** :\n\n-   les donn√©es sont conserv√©es m√™me **apr√®s l'arr√™t de l'appareil**\n\n-   l'espace de stockage est **volumineux**\n\n-   mais les op√©rations d'√©criture et de lecture ne sont pas du tout instantann√©es\n\n### La m√©moire vive\n\nLa m√©moire vive, aussi appel√©e **RAM**, se distingue de la m√©moire de stockage (disque) :\n\n-   par sa **rapidit√©**, notamment pour fournir des donn√©es au processeur pour effectuer des calculs\n\n-   par sa **volatilit√©** (toutes les donn√©es sont perdues si l'ordinateur n'est plus aliment√©)\n\n-   par l'acc√®s direct aux informations qui y sont stock√©es, **quasi instantann√©**.\n\n### Le processeur\n\nLe processeur :\n\n-   permet d'**ex√©cuter des t√¢ches et des programmes** : convertir un fichier, ex√©cuter un logiciel\n\n-   est compos√© d'un ou de plusieurs **coeurs** : un coeur ne peut ex√©cuter qu'une seule t√¢che √† la fois. Si le processeur contient plusieurs coeurs, il peut ex√©cuter autant de t√¢ches en parall√®le qu'il a de coeurs\n\n-   se caract√©rise aussi par sa **fr√©quence** : elle est globalement proportionnelle au nombre d'op√©rations qu'il est capable d'effetuer par seconde.\n:::\n\n## Traiter MiDAS en R : les limites\n\n1.  Charger les donn√©es en m√©moire vive\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  path_fna <- \"C:/Users/Public/Documents/MiDAS_parquet/Vague 4/FNA/\"\n  \n  PJC <- read_parquet(paste0(path_fna, \"pjc.parquet\"), memory = TRUE)\n  ODD <- read_parquet(paste0(path_fna, \"odd.parquet\"), memory = TRUE)\n```\n:::\n\n\n\n\n. . .\n\n2.  R√©aliser des op√©rations co√ªteuses en ressources\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njointure <- PJC %>%\n  rename(KROD1 = KROD3) %>%\n  left_join(ODD, by = c(\"id_midas\", \"KROD1\"))\n```\n:::\n\n\n\n\n. . .\n\n3.  Le partage des ressources de la bulle\n\nChaque utilisateur peut mobiliser toutes les ressouces de la bulle.\n\n::: notes\nDonn√©es \\> RAM et R fonctionne dans la m√©moire vive (pour √ßa que plus rapide que SAS) Jointures co√ªteux : on va voir pourquoi apr√®s tlm sur la m√™me bulle sans allocation des ressources = ralentissements\n:::\n\n## Traitement l√©ger versus co√ªteux {.smaller}\n\n::::: panel-tabset\n## MAP = l√©ger {.smaller}\n\n![](/images/formation%20sparklyr-Page-1.drawio.png){fig-align=\"center\"}\n\n::: notes\nCe traitement est peu co√ªteux :\n\n-   chargement d'une seule colonne en RAM : format parquet orient√© colonnes\n\n-   peu de m√©moire d'ex√©cution : R est un langage vectoris√©\n:::\n\n## REDUCE = co√ªteux {.smaller}\n\n![](/images/formation%20sparklyr-Page-2.drawio.png){fig-align=\"center\"}\n\n::: notes\nCe traitement n√©cessite :\n\n-   le chargement de davantage de colonnes en m√©moire vive ;\n\n-   davantage de m√©moire d'ex√©cution pour effectuer l'intersection (`inner_join()`).\n:::\n\n## REDUCE en R\n\n-   les jointures\n\n-   les op√©rations en `group_by()`\n\n-   les op√©rations de tri avec `arrange()`\n\n-   `distinct()`\n\n    ‚ñ∂Ô∏è Ex√©cution s√©quentielle sur un coeur du processeur + beaucoup de m√©moire vive (donn√©es temporaires)\n\n    ‚ñ∂Ô∏è Erreur \"out of memory\".\n:::::\n\n::: notes\nParquet orient√© colonne donc ne charge que les colonnes n√©cessaires en m√©moire R vectoris√© : op√©ration appliqu√©e √† tout le vecteur = traitement rapide\n\nJointure co√ªteuse parce que comparaison ligne √† ligne\n\nwindow funcions\n:::\n\n## Pourquoi spark ? {.smaller}\n\n<br>\n\n+------------------------+-------------------------------------+--------------------------+\n| Solution test√©e        | Avantage                            | Destination d'usage      |\n+========================+=====================================+==========================+\n| Package ¬´ data.table ¬ª | Calculs parall√©lis√©s                | pour bases \\< RAM        |\n+------------------------+-------------------------------------+--------------------------+\n| Format ¬´ parquet ¬ª +   | Stockage moins lourd                | pour bases \\< RAM        |\n|                        |                                     |                          |\n| package ¬´ arrow ¬ª      | Chargement efficient                |                          |\n+------------------------+-------------------------------------+--------------------------+\n| DuckDB                 | Gestionnaire de BDD                 | Pour des bases \\< 100 Go |\n+------------------------+-------------------------------------+--------------------------+\n| Spark                  | Traitements distribu√©s plus rapides | Pour des bases \\> 100 Go |\n|                        |                                     |                          |\n|                        | Traitement de donn√©es volumineuses  |                          |\n+------------------------+-------------------------------------+--------------------------+\n\n## Un gain de temps consid√©rable {.smaller}\n\n<br>\n\n+-------------+-----------------------------------------------------------------------------+---------------------------------------------+\n|             | Calcul de la dur√©e moyenne du premier contrat pour tous les individus MiDAS | Retour √† l'emploi salari√© des indemnisables |\n+=============+=============================================================================+=============================================+\n| Classique R | 4 heures                                                                    | Crash                                       |\n+-------------+-----------------------------------------------------------------------------+---------------------------------------------+\n| Duckdb      | 8 minutes                                                                   | 3 heures seul sur la bulle                  |\n+-------------+-----------------------------------------------------------------------------+---------------------------------------------+\n| Spark       | 1 minute                                                                    | 2 minutes                                   |\n+-------------+-----------------------------------------------------------------------------+---------------------------------------------+\n\nMais alors, pourquoi le cluster ? ü§î\n\n## Une bonne allocation des ressources entre utilisateurs\n\n::: r-stack\n![](/images/mode_local.PNG){.fragment fig-align=\"center\" width=\"1000\" height=\"450\"}\n\n![](/images/mode_cluster.PNG){.fragment fig-align=\"center\" width=\"1000\" height=\"450\"}\n:::\n\n# Et vous, quels sont vos probl√©matiques et vos solutions ? ‚ö†Ô∏è\n\n::: notes\nop√©rations impossibles ? bugs erreurs insolubles ? D√©j√† utilis√© spark ?\n:::\n\n# Comment on fait du spark cluster avec R version courte ? ‚è≤Ô∏è\n\n## O√π est Midas, 2√®me √©dition {.smaller}\n\nLe cluster a son propre explorateur de fichiers √† mettre en favori dans son navigateur : https://midares-deb11-nn-01.midares.local:9870/\n\n::: r-stack\n![](/images/hdfs_browse.png){.fragment fig-align=\"center\" width=\"900\" height=\"500\"}\n\n![](/images/hdfs_midas.png){.fragment fig-align=\"center\" width=\"900\" height=\"500\"}\n:::\n\n::: notes\nSorte de disque du cluster\n:::\n\n## Et mes bases sur la bulle ? {.smaller}\n\nIl est possible de charger des bases enregistr√©es n'importe o√π sur la bulle sur HDFS : depuis vos documents personnels, depuis l'espace commun...\n\n::: r-stack\n![](/images/hdfs_upload_1.png){.fragment fig-align=\"center\" width=\"1100\" height=\"450\"}\n\n![](/images/hdfs_upload_2.png){.fragment fig-align=\"center\" width=\"1100\" height=\"450\"}\n:::\n\n## Un cluster de calcul\n\n![](/images/schema_cluster.drawio.png){fig-align=\"center\"}\n\n::: notes\nPlusieurs ordinateurs, noter le voc au tableau noeud = worker = ordinateur = datanode = executeur = instance Session dans la bulle donc charger grosses donn√©es en session = limit√© par la taille de la bulle\n:::\n\n## Connexion {.smaller}\n\n::: panel-tabset\n## Traitement normal\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(dbplyr)\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"20Go\"\nconf[\"spark.executor.memory\"] <- \"60Go\"\nconf[\"spark.executor.cores\"] <- 4\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n\n\n## Traitement tr√®s lourd\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(dbplyr)\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"20Go\"\nconf[\"spark.executor.memory\"] <- \"60Go\"\nconf[\"spark.executor.cores\"] <- 4\nconf[\"spark.executor.instances\"] <- 3\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n\n:::\n\n::: callout-important\n## Temps de connexion\n\nPour se connecter au cluster, il faut environ 5 minutes, √† chaque connexion. Spark cluster n'est pas du tout adapt√© √† des traitements l√©gers (moins de 10 minutes).\n:::\n\n## Quizz : traitement nomal ou traitement tr√®s lourd {.smaller}\n\n-   Appariement de 2 bases mensuelles de la CNAF entre elles (4 millions de lignes par base)\n\n. . .\n\n-   Rep√©rage de la situation en emploi (MMO) d'un champ de b√©n√©ficiaires RSA un mois donn√© (2 millions de lignes)\n\n. . .\n\n-   Calcul de la dur√©e d'inscription (FHS, table DE), de la dur√©e d'indemnisation (FNA, table PJC) et du retour √† l'emploi d'un champ de 2 millions de demandeurs d'emploi\n\n. . .\n\n-   Calcul de la dur√©e d'indemnisation (FNA, table PJC) d'un champ de 20 millions de demandeurs d'emploi\n\n. . .\n\n-   Calcul du retour √† l'emploi d'un champ de demandeur d'emploi en fin d'un mois donn√© (5 millions de DEFM)\n\n## Chargement des donn√©es en spark {.smaller}\n\n<br>\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Depuis HDFS\nmmo_17_df_spark <- spark_read_parquet(sc,\n                                  path = \"hdfs:///dataset/MiDAS_v4/mmo/mmo_2017.parquet\",\n                                  memory = FALSE)\n\n### Passer un dataframe R en spark\nmon_data_frame <- data.frame(c(\"Anna\", \"Paul\"), c(15, 20))\nmon_data_frame_spark <- copy_to(sc, \"mon_data_frame\")\n```\n:::\n\n\n\n\n‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : par d√©faut, `memory = FALSE`\n\n::: callout-tip\n## Spark data frames\n\n`mmo_17_df_spark` est un spark data frame (sdf) : il ne peut pas √™tre ouvert comme un data frame R classique, il n'est pas dans la session R.\n:::\n\n::: notes\nspark est lazy, paresseux, il ne fait rien tant qu'on ne le force pas\n:::\n\n## Comment voir ma table ?\n\nR√©cup√©rer une partie de la table : pas plus de 500 lignes\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nune_partie_de_ma_table <- ma_table %>% \n  head(100) %>%\n  collect()\n\n\nune_partie_de_ma_table <- ma_table %>% \n  filter(id_midas %in% ma_liste_id_midas) %>%\n  collect()\n\n# une_partie_de_ma_table est ici un data.frame R classique que vous pouvez ouvrir!\n```\n:::\n\n\n\n\n::: callout-tip\n## Spark data frames\n\n`une_partie_de_ma_table` est un data frame R : il peut pas √™tre ouvert, il est dans la session R. Cela signifie qu'il se situe sur la bulle\n:::\n\n## Un cluster de calcul\n\n![](/images/schema_cluster.drawio.png){fig-align=\"center\"}\n\n## Sparklyr, c'est comme dplyr\n\n<br>\n\nEnsuite, vous pouvez programmer avec `dplyr` !\n\n<br>\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmmo_17_df_spark <- mmo_17_df_spark %>%\n  \n  rename(debut_contrat = DebutCTT) %>%\n  \n  filter(debut_contrat >= as.Date(\"2017-01-01\") & debut_contrat < as.Date(\"2017-02-01\")) %>%\n  \n  mutate(mois_debut_contrat = substr(debut_contrat,6,7))\n```\n:::\n\n\n\n\n## La lazy evaluation {.smaller}\n\nSpark distingue deux types d'op√©rations :\n\n-   **les transformations :** prennent en entr√©e un `spark_data_frame` et retournent un `spark_data_frame`, elles ne d√©clenchent aucun calcul\n\n    Par exemple, le programme ci-dessous ne d√©clenche pas d'ex√©cution :\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmmo_17_df_spark_mois <- mmo_17_df_spark %>%\n  rename(debut_contrat = DebutCTT) %>%\n  filter(debut_contrat >= as.Date(\"2017-01-01\") & debut_contrat < as.Date(\"2017-06-01\")) %>%\n  mutate(mois_debut_contrat = substr(debut_contrat,6,7))\n```\n:::\n\n\n\n\n-   **les actions :** forcent le calcul d'un r√©sultat pour le r√©cup√©rer et d√©clenchent l'ex√©cution de toutes les transformations compil√©es jusqu'√† l'appel de l'action.\n\n    Par exemple, le programme ci-dessous d√©clenche le calcul de toute la cellule pr√©c√©dente :\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_debut_contrat_fev_17 <- mmo_17_df_spark_mois %>%\n  group_by(mois_debut_contrat) %>%\n  summarise(nb_contrats = n()) %>%\n  print()\n```\n:::\n\n\n\n\n## La lazy evaluation : un gain de temps consid√©rable\n\n<br>\n\n::: callout-tip\n## La gestion des erreurs\n\nEn r√©alit√©, lorsqu'on appuie sur le bouton `run`, il ne se passe pas \"rien\". Le code est compil√© par spark : les erreurs sont rep√©r√©es avant m√™me que le code soit ex√©cut√© !\n:::\n\n![](images/erreur_variable_inexistante.PNG){width=\"300\"}\n\n## R√©cup√©rer un r√©sultat {.smaller}\n\nLes principales actions sont :\n\n-   `print()`\n\n-   `head()` + `collect()`\n\n-   ‚ö†Ô∏è `collect()` pour de petites tables : ne fonctionne pas sur des grosses tables\n\n-   `tbl_cache()` (√©crire un `spark_data_frame` en m√©moire pour le r√©utiliser)\n\n::: callout-warning\n## Le bouton stop\n\nIl est recommand√© de ne pas utiliser ce bouton en programmant en sparklyr : il rend la session spark inutilisable par la suite, il faut fermer RStudio et rouvrir ensuite.\n:::\n\n## Les erreurs spark {.smaller}\n\nLes erreurs de **programmation** sont soulev√©es avant que les calculs commencent.\n\nDes erreurs peuvent survenir pendant l'ex√©cution du code, quelques minutes apr√®s l'appel d'une action par exemple.\n\n::: callout-warning\n## Collecter des donn√©es trop volumineuses\n\nUne source fr√©quente d'erreur pendant l'ex√©cution est l'appel d'un `collect()` sur des donn√©es trop volumineuses pour √™tre collect√©es. La premi√®re √©tape du d√©buggage consiste √† limiter les `collect()`.\n:::\n\n::: r-stack\n![](images/erreur_1.png){.fragment width=\"1000\" height=\"100\"}\n\n![](/images/erreur_2.PNG){.fragment width=\"1000\" height=\"100\"}\n\n![](/images/erreur_2_bis.PNG){.fragment width=\"1000\" height=\"120\"}\n:::\n\n::: callout-caution\n## Les erreurs sparklyr\n\nLes erreurs envoy√©es par spark sont \"traduites\" par sparklyr pour √™tre affich√©es dans la console de R. Elles ne sont pas toujours tr√®s lisibles, ou tr√®s pr√©cises sur la nature de l'erreur/sa source.\n:::\n\n## ... presque tout comme dplyr {.smaller .scrollable}\n\nLa majorit√© des commandes `dplyr` fonctionnent sur un spark_data_frame avec le package `sparklyr`. Les divergences principales sont les suivantes :\n\n+--------------------------------+----------------+----------------------------------+\n| Fonctionnalit√©                 | tidyverse      | sparklyr                         |\n+================================+================+==================================+\n| import d'un fichier `.parquet` | `read_parquet` | `spark_read_parquet()`           |\n+--------------------------------+----------------+----------------------------------+\n| tri d'un tableau               | `arrange()`    | `window_order()` ou `sdf_sort()` |\n+--------------------------------+----------------+----------------------------------+\n| op√©rations sur les dates       | `lubridate`    | fonctions Hive                   |\n+--------------------------------+----------------+----------------------------------+\n| empiler des tableaux           | `bind_rows()`  | `sdf_bind_rows()`                |\n+--------------------------------+----------------+----------------------------------+\n| nombre de lignes d'un tableau  | `nrow()`       | `sdf_nrow()`                     |\n+--------------------------------+----------------+----------------------------------+\n| faire pivoter un tableau       | `tidyr`        | `sdf_pivot()`                    |\n+--------------------------------+----------------+----------------------------------+\n| export d'un `spark_data_frame` |                | `spark_write_parquet()`          |\n+--------------------------------+----------------+----------------------------------+\n\n## Quelques fonctions R pas encore traduites {.smaller .scrollable}\n\n::::: panel-tabset\n## Dates\n\nLes fonctions de `lubridate()`ne sont pas adapt√©es au `spark_data_frames`.\n\n-   Convertir une cha√Æne de caract√®re de la forme AAAA-MM-DD en Date\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    date_1 <- as.Date(\"2024-05-26\")\n```\n:::\n\n\n\n\n-   Calculer une dur√©e entre deux dates\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    PJC_spark <- spark_read_parquet(sc,\n                                    path = \"hdfs:///dataset/MiDAS_v4/pjc.parquet\",\n                                    memory = FALSE)\n\n    duree_pjc_df <- PJC_spark %>%\n      rename(date_fin_pjc = as.Date(KDFPJ),\n             date_deb_pjc = as.Date(KDDPJ)) %>%\n      mutate(duree_pjc = datediff(date_fin_pjc, date_deb_pjc) + 1) %>%\n      head(5)\n```\n:::\n\n\n\n\n-   Ajouter ou soustraire des jours ou des mois √† une date\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    duree_pjc_bis_df <- duree_pjc_df %>%\n      mutate(duree_pjc_plus_5 = date_add(duree_pjc, int(5)),\n             duree_pjc_moins_5 = date_sub(duree_pjc, int(5)),\n             duree_pjc_plus_1_mois = add_months(duree_pjc, int(1))) %>%\n      head(5)\n```\n:::\n\n\n\n\n::: callout-note\n## Add_months\n\nSi la date en entr√©e est le dernier jour d'un mois, la date retourn√©e avec `add_months(date_entree, int(1))` sera le dernier jour calendaire du mois suivant.\n:::\n\n::: callout-tip\n## Format\n\nLe `int()` est important car ces fonctions Hive n'accepte que les entiers pour l'ajout de jours : taper uniquement 5 est consid√©r√© comme un flottant dans R.\n:::\n\n## Tableau\n\n-   Tri dans un groupe pour effectuer un calcul s√©quentiel\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    ODD_spark <- spark_read_parquet(sc,\n                                    path = \"hdfs:///dataset/MiDAS_v4/odd.parquet\",\n                                    memory = FALSE)\n\n    ODD_premier <- ODD_spark %>%\n      group_by(id_midas) %>%\n      window_order(id_midas, KDPOD) %>%\n      mutate(date_premier_droit = first(KDPOD)) %>%\n      ungroup() %>%\n      distinct(id_midas, KROD3, date_premier_droit) %>%\n      head(5)\n```\n:::\n\n\n\n\n-   Tri pour une sortie : `sdf_sort()` , `arrange()` ne fonctionne pas\n\n-   Concat√©ner les lignes (ou les colonnes `sdf_bind_cols()`)\n\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_1 <- ODD_spark %>%\n      filter(KDPOD <= as.Date(\"2017-12-31\")) %>%\n      mutate(groupe = \"temoins\")\n    \n    ODD_2 <- ODD_spark %>%\n      filter(KDPOD >= as.Date(\"2021-12-31\")) %>%\n      mutate(groupe = \"traites\")\n    \n    ODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)\n    ```\n    :::\n\n\n\n\n-   D√©doublonner une table\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    droits_dans_PJC <- PJC_spark %>%\n      sdf_distinct(id_midas, KROD3)\n\n    print(head(droits_dans_PJC, 5))\n\n    PJC_dedoublonnee <- PJC_spark %>%\n      sdf_drop_duplicates()\n\n    print(head(PJC_dedoublonnee, 5))\n```\n:::\n\n\n\n\n-   Pivot : les fonctions du packag `tidyr` ne fonctionnent pas sur donn√©es spark\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    ODD_sjr_moyen <- ODD_spark %>%\n      mutate(groupe = ifelse(KDPOD <= as.Date(\"2020-12-31\"), \"controles\", \"traites\")) %>%\n      sdf_pivot(groupe ~ KCRGC,\n        fun.aggregate = list(KQCSJP = \"mean\")\n      )\n```\n:::\n\n\n\n\n## Statistiques\n\n-   R√©sum√© statistique : `sdf_describe()` , `summary()`ne fonctionne pas.\n\n-   Dimension : `sdf_dim`, la fonction `nrow()`ne fonctionne pas.\n\n-   Quantiles approximatifs : le calcul des quantiles sur donn√©es distirbu√©es renvoie une approximation car toutes les donn√©es ne peuvent pas √™tre rappatri√©es sur la m√™me machine physique du fait de la volum√©trie, `sdf_quantile()`\n\n-   Echantillonnage al√©atoire : `sdf_random_split`\n:::::\n\n## Je veux voir ma table {.smaller}\n\n1.  V√©rifier le nombre de lignes sans collecter\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma_table %>% \n  sdf_nrow()\n```\n:::\n\n\n\n\n. . .\n\n2.  V√©rifier la pr√©sence de doublons\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_doublons <- ma_table %>% \n  group_by(id_midas) %>%\n  summarise(nb_ligne_ind = n()) %>%\n  ungroup() %>%\n  filter(nb_ligne_ind > 1) %>%\n  sdf_nrow()\n```\n:::\n\n\n\n\n. . .\n\n3.  R√©cup√©rer une partie de la table : pas plus de 500 lignes\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nune_partie_de_ma_table <- ma_table %>% \n  head(100) %>%\n  collect()\n\n\nune_partie_de_ma_table <- ma_table %>% \n  filter(id_midas %in% ma_liste_id_midas) %>%\n  collect()\n\n# une_partie_de_ma_table est ici un data.frame R classique que vous pouvez ouvrir!\n```\n:::\n\n\n\n\n## Exporter des donn√©es sur disque {.smaller}\n\nSur la pause d√©jeuner par exemple üòâ\n\nPourquoi ‚ùì Pour des donn√©es qui ne peuvent pas √™tre collect√©es en m√©moire vive\n\nExport des spark data frames directement sous HDFS : √† aucun moment on n'ouvre la table : on peut traiter des donn√©es beaucoup plus volumnieuses que la m√©moire RAM !\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma_table_spark <- MMO %>%\n  \n  right_join(mon_champ_individuel, by = c(\"id_midas\")) %>%\n  \n  mutate(fin_ctt_bis = ifelse(is.na(FinCTT), as.Date(\"2023-12-31\"), FinCTT)) %>%\n  \n  mutate(duree_ctt = DATEDIFF(FinCTT, DebutCTT) + 1)\n\nspark_write_parquet(ma_table_spark, \"hdfs:///resultats/ma_table.parquet\")\n```\n:::\n\n\n\n\nPossibilit√© de r√©cup√©rer ce fichier sur la bulle MiDARES = en local.\n\n::: callout-warning\n## Exports simultan√©s\n\nHDFS supporte les exports simultan√©s, mais le temp d'export est plus long lorsque le NameNode est requ√™t√© par plusieurs personnes simultan√©ment\n:::\n\n## Si on souhaite la r√©cup√©rer en local {.smaller}\n\n::: callout-caution\n## Les exports sur HDFS\n\nLorsqu'on exporte une table depuis notre session R vers HDFS, celle-ci est **automatiquement partitionn√©e**, comme le reste des donn√©es.\n\nAinsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.\n\nIl est possible de ma√Ætriser le nombre de partitions avec la commande `sdf_coalesce(partitions = 1)` du package `sparklyr`.\n\nAvec `sdf_coalesce(partitions = 1)`, on n'aura qu'un seul fichier √† t√©l√©charger depuis HDFS.\n\nAvec `sdf_coalesce(partitions = 200)`, on aura 200 morceaux de notre fichier √† t√©l√©charger √† la main (pas possible de faire tout s√©lectionner sous HDFS !).\n\nL'id√©al est d'**adapter le nombre de partitions √† la taille d'un bloc** : un bloc mesure 128 MB.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma_table <- data.frame(c(\"Anne\", \"Paul\"), c(25,30))\n\nma_table_spark <- copy_to(sc, ma_table) %>%\n  sdf_coalesce(partitions = 1)\n\nspark_write_parquet(ma_table_spark, \"hdfs:///resultats/ma_table.parquet\")\n```\n:::\n\n\n\n\n## Fermer sa session {.smaller}\n\nIl faut imp√©rativement fermer sa session spark apr√®s une session de travail. Deux moyens pour √ßa :\n\n-   fermer R Studio\n\n-   si on ne ferme pas RStudio, utiliser la fonction `spark_disconnect_all()` dans son code\n\nSi on souhaite lancer un code le soir en partant, on n'oublie pas le `spark_disconnect_all()` √† la fin du code.\n\n::: callout-warning\n## Partage des ressources\n\nLes ressources r√©serv√©s par un utilisateur ne sont lib√©r√©es pour les autres que lorsqu'il se d√©connecte. Ne pas se d√©connecter, c'est bloquer les ressources. Si j'ai r√©serv√© deux ordinateurs du cluster sur 15, personne d'autres ne peut les r√©server tant que je n'ai pas d√©connecter ma session spark.\n\nNous fermerons les sessions ouvertes trop longtemps (d√©part de cong√©s sans d√©connexion) si des utilisateurs pr√©sents en ont besoin : risque de perte du travail non enregistr√©.\n:::\n\n## T√©l√©charger des donn√©es en local {.smaller}\n\n::: r-stack\n![](images/hdfs_browse.png){.fragment width=\"1000\" height=\"700\"}\n\n![](/images/hdfs_dowload.PNG){.fragment}\n:::\n\n## Et ensuite ? {.smaller}\n\nSpark est un outil de traitement de donn√©es volumineuses. Il n'est pas toujours adapt√© :\n\n-   **pour de petites tables** : il ne va pas engendrer de gain de temps, voire augmenter le temps\n\n-   **pour faire de l'√©conom√©trie pouss√©e** : tous les packages R ne sont pas traduits en spark\n\n-   **pour ouvrir sa table** : on perd les avantages de spark si on collecte toute la table en m√©moire RAM\n\n**Conseils :**\n\n1.  Cr√©er sa table d'√©tude en appariant les tables de MiDAS avec le cluster spark\n\n2.  L'exporter sous HDFS\n\n3.  La t√©l√©charger en local\n\n4.  La charger en R classique pour faire de l'√©conom√©trie\n\n## Quizz : spark ou pas spark ? {.smaller}\n\n-   faire des statistiques descriptives sur une unique table de 1 million d'individus et 30 variables d√©j√† cr√©√©e\n\n. . .\n\n-   cr√©er une table de 5 millions demandeurs d'emploi avec leur situation au regard de l'emploi (MMO), leur dur√©e d'inscription (DE du FHS)\n\n. . .\n\n-   apparier 4 tables mensuelles de la CNAF pour rep√©rer la liste des `id_midas` b√©n√©ficiaires de minima sociaux 4 mois donn√©s (4 millions chaque mois)\n\n. . .\n\n-   faire de l'√©conom√©trie sur une unique table d√©j√† cr√©√©e\n\n. . .\n\n::: callout-tip\n## Econom√©trie et Machine Learning avec Spark\n\nIl existe des outils pour faire de l'√©conom√©trie avec spark, la librairie Apache Spark **MLlib**. Elle rel√®ve d'une utilisation plus avanc√©e de spark que nous ne traitons pas ici. Elle ne contient pas autant de mod√®les que le CRAN R pour la recherche en √©conom√©trie.\n\nIl vous est conseill√© de cr√©er une unique table d'√©tude puis de la traiter en R classique pour l'√©conom√©trie.\n:::\n\n# Les bonnes pratiques ü§ù\n\n## Mode local : sch√©ma {.smaller}\n\n![](images/mode_local.PNG)\n\n## Mode local : inadapt√© et mauvaise pratique {.smaller}\n\n<br>\n\nSpark et le mode local :\n\n-   un seul ordinateur alors que spark est fait pour **plusieurs ordinateurs** distincts\n\n-   beaucoup **moins de ressources** disponibles sur la bulle que sur le cluster\n\n-   mauvaise gestion de l'allocation des ressources entre utilisateurs : **pas faite pour plusieurs utilisateurs**\n\n-   ralentissements consid√©rables et bugs : **bloque les autres utilisateurs**\n\n    ‚ñ∂Ô∏èspark n'est adapt√© que pour le cluster de calcul, la bulle pour faire du R sans spark sur des donn√©es peu volumineuses\n\n## Inefficient de prendre beaucoup de ressources {.smaller}\n\nLes ordinateurs du cluster ont besoin de **s'envoyer des donn√©es par le r√©seau** : c'est la partie la plus lente d'un programme spark !\n\nSi j'augmente les ressources : par exemple, je r√©serve 3 ordinateurs du cluster plut√¥t que 2\n\n1.  **Effet puissance de calcul** : plus de ressources pour faire les calculs = r√©duction du temps de calcul\n\n2.  **Effet augmentation des √©changes r√©seau (shuffles)** : augmentation du temps de calcul\n\n3.  **G√™ne des autre utilisateurs**\n\n## Ne pas collecter {.smaller}\n\n::: callout-note\n## Collecter, c'est quoi ?\n\nCollecter c'est utiliser l'instruction `collect()`. Elle permet de rapatrier l'ensemble des r√©sultats du cluster vers la bulle et la session R de l'utilisateur en format R, par exemple des `data.frames`.\n\n`Collect()` :\n\n1.  est une **action** : elle d√©clencher tous les calculs\n\n2.  implique des **√©changes r√©seau** tr√®s importants : entre ordinateurs du cluster et du cluster vers la bulle : c'est extr√™mement long, moins efficient que l'enregistrement sur disque directement depuis spark\n\n3.  rappatrie les r√©sultats (une table) dans la m√©moire vive de R, qui est sur la bulle : si le r√©sultat est volumineux, cela **bloque les autres utilisateurs**\n:::\n\nRecommandations :\n\n-   Ne pas collecter des tables de plus de 15 Go\n\n-   Utiliser les autres m√©thodes propos√©es pour ne pas bloquer les utilisateurs qui ont besoin de R en mode classique\n\n-   Ne pas changer les configurations\n\n## Fermer sa session {.smaller}\n\n<br>\n\n<br>\n\n<br>\n\nPour ne pas bloquer les coll√®gues üë®‚Äçüíª\n\n## Yarn {.smaller}\n\nYarn permet de consulter la r√©servation des ressources par les utilisateurs.\n\nOn peut y acc√©der en copiant le lien suivant dans Google chrome sur la bulle (mettre en favori) : midares-deb11-nn-01.midares.local:8088/cluster\n\nV√©rifier que notre session est ferm√©e et qu'on ne prend pas trop de ressources : **yarn**\n\n![](images/yarn_scheduler.PNG)\n\n## Mutualiser les exp√©riences {.smaller}\n\n-   Aide au passage d'un code sur le cluster\n\n-   Programmer entre coll√®gues\n\n-   Contributions √† la documentation MiDAS : section fiches, √† l'aide de pull requests sur github\n\n![](images/documentation_midas_fiches.PNG){fig-align=\"center\"}\n\n# Optimiser le code : non ! Mais optimiser la m√©moire...\n\n## Comment fonctionne spark ? {.smaller}\n\n-   Apache Spark : **librairie open source** d√©velopp√©e dans le langage `scala`\n\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    val TopHorrorsIGN2022 = Seq(\n      (9, \"Pearl\"),\n      (6, \"The Sadness\"),\n      (6, \"Offseason\"),\n      (7, \"Hatching\"),\n      (8, \"x\")\n    ).toDF(\"IMDB Rating\", \"IGN Movie Picks\")\n    \n    import org.apache.spark.sql.functions.col\n    \n    val cols = List(col(\"IGN Movie Picks\"), col(\"AVC Movie Picks\"))\n    \n    val query = TopHorrorsIGN2022(\n      \"IGN Movie Picks\"\n    ) === TopHorrorsTheAVClub2022(\"AVC Movie Picks\")\n    \n    val outerJoin = TopHorrorsIGN2022\n      .join(TopHorrorsTheAVClub2022, query, \"outer\")\n      .select(cols: _*)\n    \n    outerJoin.show()\n    ```\n    :::\n\n\n\n\n-   `scala` adapt√© pour ma√Ætriser toutes les fonctionnalit√©s de `spark` et optimiser au maximum les traitements en `spark`\n\n-   `spark` est **compatible avec les langages** `scala`, `R`, `python`, `java`, et peut interpr√©ter des commandes **SQL.**\n\n## Le driver en sparklyr {.smaller}\n\n![](/images/schema_cluster.drawio.png){fig-align=\"center\" width=\"400\"}\n\n-   Le programme R est traduit en scala gr√¢ce au package `sparklyr`\n\n-   Le driver √©value le programme, il lit le code `scala` mais n'ex√©cute rien du tout\n\n-   S'il remarque une erreur, l'erreur est envoy√©e directement √† l'utilisateur en session R avant l'ex√©cution du programme : c'est la force de la lazy evaluation.\n\n## Pas besoin d'optimiser son code ! {.smaller}\n\n![](images/catalyst.jpg)\n\nsource : documentation CASD disponible √† [Documentation Data Science](https://casd-eu.gitbook.io/data-science/)\n\n## Catalyst optimise le code pour nous {.smaller}\n\nLe driver contient un programme nomm√© Catalyst qui optimise le code `scala` automatiquement.\n\nSpark optimise automatiquement les programmes soumis :\n\n1.  Compilation des transformations pour soulever les √©ventuelles erreurs\n\n2.  Int√©gration dans un **plan d'ex√©cution** contenant les √©tapes n√©cessaires pour parvenir au r√©sultat demand√© par le programme\n\n3.  Optimisation du plan logique par le module **Catalyst** (driver Spark)\n\n## Catalyst optimise le code pour nous {.smaller .scrollable}\n\n![](images/dag.webp){fig-align=\"center\"}\n\n## Catalyst optimise le code pour nous\n\nPar exemple si j'√©cris le programme :\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnon_optimal <- table_1 %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))\n```\n:::\n\n\n\n\n<br>\n\nCatalyst r√©√©crit :\n\n<br>\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptimal <- table_1 %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\")) %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))\n```\n:::\n\n\n\n\nCette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu'une action d√©clenche l'ex√©cution.\n\n## Catalyst optimise le code pour nous : laissons-le travailler ! {.smaller}\n\n**D√©clencher le moins d'actions possibles** dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.\n\nPour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique. On √©vite quoi ?\n\n. . .\n\nOn √©vite :\n\n-   de mettre des `collect()`sur chaque table interm√©diaire\n\n-   de `collect()` une table enti√®re\n\n-   de `print()` √† chaque √©tape\n\n. . .\n\nSinon Catalyst n'a pas assez de code pour optimiser !\n\n## Catalyst optimise le code pour nous : laissons-le travailler !\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnon_optimal <- table_1 %>% \n    collect() %>%\n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))\n```\n:::\n\n\n\n\n. . .\n\nversus\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptimal <- table_1 %>%\n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\")) %>%\n    head(5) %>% \n    collect()\n```\n:::\n\n\n\n\n## La longueur du plan logique\n\nFournir un plan logique tr√®s long sans d√©clencher d'action peut cr√©er une erreur en spark : spark \"refuse\" d'optimiser un plan si long.\n\nLa bonne pratique consiste √† \"cacher\" des r√©sultats interm√©diaires, pour d√©clencher l'ex√©cution r√©guli√®rement et conserver les r√©sultats en m√©moire, tout en nettoyant la m√©moire des r√©sultat interm√©diaires pr√©c√©dents :\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable_1 <- mon_champ %>%\n  left_join(table_2) %>%\n  mutate(variable_1 = indicatrice_1 + indicatrice_2,\n         regroupement_variable_2 = case_when(variable_2 %in% c(1,2,3) ~ \"A\",\n                                             variable_2 %in% c(5,8,9) ~ \"B\",\n                                             TRUE ~ \"C\")) %>%\n  left_join(table_3) %>%\n  sdf_register(\"table_1\")\n\ntbl_cache(sc, \"table_1\")\n\ntable_4 <- table_1 %>%\n  left_join(table_5) %>%\n  mutate(variable_y = ifelse(variable_x > 50, 1, 0)) %>%\n  sdf_register(\"table_4\")\n\ntbl_cache(sc, \"table_4\")\n\ntbl_uncache(sc, \"table_1\")\n```\n:::\n\n\n\n\n## Le r√¥le du cluster manager {.smaller}\n\n![](images/calcul_distribue.drawio.png){fig-align=\"center\"}\n\nLe cluster manager distribue les traitements physiques aux ordinateurs du cluster :\n\n-   il conna√Æt le meilleur plan physique fourni par Catalyst ;\n\n-   il conna√Æt les ressources disponibles et occup√©es par toutes les machines du cluster ;\n\n-   il affecte les ressources disponibles √† la session spark.\n\n## Le r√¥le du worker {.smaller}\n\n![](images/calcul_distribue.drawio.png){fig-align=\"center\"}\n\nLe worker effectue le morceau de programme qu'on lui affecte :\n\n-   il ne conna√Æt que les t√¢ches qu'on lui a affect√©es ;\n\n-   il peut communiquer avec le driver en r√©seau pour renvoyer un r√©sultat ;\n\n-   il peut communiquer avec les autres workers en r√©seau pour partager des donn√©es ou des r√©sultats interm√©diaires : c'est un shuffle.\n\n## Calcul distribu√© et r√©cup√©ration des r√©sultats {.smaller}\n\n![](images/schema_cluster.drawio.png){fig-align=\"center\" width=\"400\"}\n\n::: callout-important\n## Le r√©seau\n\n-   Les workers communiquent avec le driver de la bulle MiDARES en r√©seau\n\n-   Les workers communiquent entre eux en r√©seau pour s'√©changer des donn√©es\n\n-   Le r√©seau est un mode de communication lent\n:::\n\n::: notes\nMtn un peu de th√©orie pour comprendre le calcul distribu√© et mieux l'utiliser\n:::\n\n## Traitement MAP distribu√©\n\n![](images/map_distribue.drawio.png){fig-align=\"center\"}\n\n## Traitement REDUCE distribu√©\n\n![](images/reduce_distribue.drawio.png){fig-align=\"center\"}\n\n## Le stockage distribu√© avec HDFS {.smaller}\n\n![](images/stockage_distribue.drawio.png){fig-align=\"center\"}\n\n## Calcul distribu√©, calcul vectoriel {.smaller}\n\n<br>\n\nLes op√©rations les plus co√ªteuses en spark sont :\n\n-   les op√©rations par **groupe de lignes**, qui impliquent des **shuffles**, ou √©changes de donn√©es entre workers via le r√©seau\n\n-   les op√©rations d'√©criture sur disque avec `spark_write_parquet()`\n\n-   les op√©rations üõë**non vectoris√©es**üõë, qui entra√Ænent des shuffles lourds et inutiles : boucles for, jointures volumineuses...\n\n<br>\n\nLes donn√©es MiDAS sont structur√©es de mani√®re proche d'une **base de donn√©es relationnelles :** leur traitement n√©cessite des jointures. Une partie des donn√©es sont **mensuelles** : cette structure peut inciter √† programmer en boucle for sur le mois, ce qui est long et inefficient.\n\n## Calcul distribu√©, calcul vectoriel : boucles for\n\n<br>\n\nCas d'usage : je veux rep√©rer si un groupe d'individus est au RSA un mois, deux mois, trois mois etc. apr√®s la sortie de l'assurance-ch√¥mage\n\nJ'utilise :\n\n-   le FNA, dont j'extraie une table individu avec le mois de sortie de l'assurance-ch√¥mage, table `sorties`\n\n-   les tables mensuelles de la CNAF `cnaf_prestations_mois_m`\n\n## Calcul distribu√©, calcul vectoriel : boucles for {.smaller .scrollable}\n\n::: panel-tabset\n### Solution 1\n\nLance 12 X tous les mois de sortie jobs spark, beaucoup de shuffles\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(sparklyr)\n\nres_all <- NULL\n\nfor (mois in mois_sortie_vec) { # 1√®re boucle sur les mois de sorties\n  # Sous-ensemble des sortants de ce mois\n  sorties_mois <- sorties %>%\n    filter(mois_sortie == !!mois) %>%\n    select(id, mois_sortie)\n\n  for (h in 1:12) { # 2√®me boucle sur les 12 mois d'horizon\n    \n    mois_cible <- as.Date(mois) + months(h)\n    nom_tbl <- paste0(\"cnaf_prestations_\", format(mois_cible, \"%Y_%m\"))\n    table_mois_cnaf <- spark_read_parquet(paste0(chemin_table, nom_tbl))\n\n    perception_RSA_mois_h <- sorties_mois %>%\n      mutate(mois_h = sql(paste0(\"add_months(mois_sortie, \", h, \")\"))) %>%\n      inner_join(table_mois_cnaf, by = c(\"id\" = \"id\", \"mois_h\" = \"mois\")) %>%\n      mutate(perception_RSA = ifelse(RSAVERS == \"C\" & MTRSAVER > 0, 1, 0)) %>%\n      transmute(id, mois_sortie, h = !!h, perception_RSA)\n\n    # empiler et mettre en cache le r√©sultat\n    res_all <- if (is.null(res_all)) perception_RSA_mois_h else sdf_bind_rows(res_all, perception_RSA_mois_h) %>% sdf_register(paste0(\"temp\", mois, h))\n  tbl_cache(sc, paste0(\"temp\", mois, h))\n  }\n}\n```\n:::\n\n\n\n\n### Solution 2\n\nLance 12 jobs et une action √† chaque tour\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (mois in liste_mois) {\n  \n  nom_tbl <- paste0(\"cnaf_prestations_\", format(mois, \"%Y_%m\"))\n  table_mois_cnaf <- spark_read_parquet(paste0(chemin_table, nom_tbl))\n\n  # Jointure globale, calcul de l'horizon h \n  perception_RSA_mois <- table_mois_cnaf %>%\n    inner_join(sorties, by = \"id\") %>%\n    mutate(h = sql(\"cast(months_between(mois, mois_sortie) as int)\")) %>%\n    filter(h >= 1, h <= 12) %>%\n    select(id, mois_sortie, h, prest)\n\n  # Cache pour enregistrer le r√©sultat en m√©moire\n  perception_RSA_mois_cache <- perception_RSA_mois %>% sdf_register(paste0(\"temp\", mois))\n  tbl_cache(sc, paste0(\"temp\", mois))\n\n  res_stack <- if (is.null(res_stack)) joined_cached else sdf_bind_rows(res_stack, joined_cached)\n}\n```\n:::\n\n\n\n\n### Solution 3\n\nMeilleure solution : un seul plan logique que Catalyst peut enti√®rement optimsier, en limitant les shuffles, beaucoup plus rapide\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Charger la premi√®re table CNAF\nnom_1 <- paste0(\"cnaf_prestations_\", format(as.Date(\"2023-01-01\"), \"%Y_%m\"))\ncnaf_total <- spark_read_parquet(paste0(chemin_table, nom_1))\n\n# Empiler les autres\nfor (mois in liste_mois) {\n  \n  nom_tbl <- paste0(\"cnaf_prestations_\", format(mois, \"%Y_%m\"))\n  table_mois_cnaf <- spark_read_parquet(paste0(chemin_table, nom_tbl))\n  \n  cnaf_total <- sdf_bind_rows(cnaf_total, table_mois_cnaf) %>%\n    sdf_register(\"cnaf_total\")\n  tbl_cache(sc, \"cnaf_total\")\n}\n\n\n# Joindre UNE fois avec la table des sorties (broadcast si petit)\nsorties_b <- sdf_broadcast(sorties %>%\n  select(id, mois_sortie)\n)\n\nperception_RSA_horizon <- cnaf_total %>%\n  inner_join(sorties_b, by = \"id\") %>%\n  mutate(\n    h = sql(\"cast(months_between(mois, mois_sortie) as int)\")\n  ) %>%\n  filter(h >= 1, h <= 12) %>%\n  select(id, mois_sortie, h, prest)\n```\n:::\n\n\n\n:::\n\n## Calcul distribu√©, calcul vectoriel : jointures {.smaller}\n\nUne **jointure** implique pour spark de rappatrier les lignes avec les m√™mes valeurs de clef sur le m√™me worker : les jointures engendrent des **shuffles**.\n\n<br>\n\nLorsque l‚Äôon joint une **grosse table** avec une **petite table**, Spark peut optimiser le calcul en utilisant un **broadcast join** : la petite table est **diffus√©e en entier** sur chaque worker, ce qui √©vite un shuffle massif.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- grosse_table %>%\n  inner_join(sdf_broadcast(petite_table), by = \"clef\")\n```\n:::\n\n\n\n\n<br>\n\nüëâ Ici petite_table est diffus√©e (broadcast) sur tous les workers : chaque partition de grosse_table fait alors le join localement, sans transfert r√©seau co√ªteux.\n\n## Calcul distribu√©, calcul vectoriel : jointures {.smaller}\n\n**Broadcast automatique** : par d√©faut, Spark choisit automatiquement le broadcast join si la table √† diffuser fait moins de 10 MB (param√®tre configurable).\n\nAu-del√†, il utilise un **shuffle join** classique (plus lent).\n\n**Astuce right_join** : dans sparklyr, la position de la table peut influencer le plan choisi par Spark :\n\n`petite_table %>% left_join(grosse_table)` ‚Üí Spark n‚Äôessaie pas forc√©ment de diffuser la petite.\n\n`grosse_table %>% right_join(petite_table)` ‚Üí Spark choisit plus volontiers un broadcast join.\n\nüëâ Bonne pratique : forcer avec `sdf_broadcast()` quand on sait que la table est petite, plut√¥t que de compter sur ce comportement implicite.\n\n## Calcule distribu√©, calcul vectoriel {.smaller}\n\n+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+\n| **Op√©ration logique**                  | **Solution non vectorielle**                         | **Solution vectorielle**                                           |\n+========================================+======================================================+====================================================================+\n| situation √† m + 1, 2...                | Boucle for sur les mois                              | utilisation de `lag()` et `lead()`, ou auto jointure sur les dates |\n+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+\n| R√©p√©ter une fonction                   | user defined functions (UDF)                         | √©viter les UDF                                                     |\n+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+\n| op√©ration groupe de lignes             | `group_by %>% mutate %>% distinct`                   | `group_by %>% summarise`                                           |\n+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+\n| joindre petite table avec grosse table | `petite_table %>% left_join(grosse_table)`           | broadcast join                                                     |\n+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+\n| joindre deux grosses tables            | boucle for en divisant les tables en petits morceaux | unique jointure et partition par la clef de jointure               |\n+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+\n| construire un panel cylindr√©           | boucle for                                           | `cross_join()` de deux tables                                      |\n+----------------------------------------+------------------------------------------------------+--------------------------------------------------------------------+\n\n## La m√©moire du driver\n\n![](images/collect.drawio.png){fig-align=\"center\"}\n\n## L'utilisation de la m√©moire du driver {.smaller .scrollable}\n\nCette configuration permet de collecter des statistiques descriptives et de petites tables sans g√™ner les autres utilisateurs.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2\"}\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"20Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n\n\n::: callout-caution\n## Bonne pratique de partage des ressources\n\nLe driver est dans la bulle Midares, qui a vocation √† √™tre r√©duite suite √† la g√©n√©ralisation du cluster.\n\n-   La bulle Midares a besoin de RAM pour fonctionner, 100% des ressources ne sont donc pas disponibles pour `sparklyr`.\n\n-   Pour permettre le **travail simultan√© fluide de 10 utilisateurs**, la m√©moire allou√©e au driver recommand√©e pour chaque utilisateur est de **maximum 20 Go**.\n\n-   Il existe des alternatives pour ne pas collecter des r√©sultats trop volumineux dans le driver.\n:::\n\n## Programmer sans collecter {.smaller}\n\nLa programmation en spark doit √™tre adapt√©e aux contraintes de volum√©trie des donn√©es : test de chaque √©tape, puis ne forcer le calcul qu'√† la fin pour que Catalyst optimise l'ensemble du programme\n\nLa principale diff√©rence avec la programmation en R classique est que **la visualisation de tables compl√®tes volumineuses n'est pas toujours possible et n'est pas recommand√©e** :\n\n-   **goulets d'√©tranglement** m√™me avec spark, car toutes les donn√©es sont rapatri√©es vers le driver puis vers la session R : erreurs Out of Memory\n\n-   **longue :** √©change entre tous les noeuds impliqu√©s dans le calcul et le driver, puis un √©change driver-session R en r√©seau = lent ;\n\n-   **beaucoup moins efficace que l'export direct en parquet** du r√©sultat (qui fonctionne toujours) : charger ensuite sa table finale en data frame R classique pour effectuer l'√©tude.\n\nS'il est n√©cessaire de collecter, il faut pr√©voir **beaucoup de RAM pour le driver avec le param√®tre** `spark.driver.memory`, ce qui emp√™che les autres utilisateurs de travailler.\n\n## Programmer sans collecter {.smaller}\n\nLes r√©sultats qu'il est recommand√© de r√©cup√©rer en m√©moire vive en session R sont de la forme suivante :\n\n-   **une table filtr√©e** avec les variables n√©cessaires √† l'√©tude uniquement : sous MiDAS, toutes les jointures, les calculs de variable et les filtres peuvent √™tre effectu√©s de mani√®re efficiente sous la forme de spark_data_frame, sans jamais collecter les donn√©es MiDAS ;\n\n-   des **statistiques descriptives synth√©tiques ;**\n\n-   les **premi√®res lignes** de la table pour v√©rifier que le programme retourne bien le r√©sultat attendu ;\n\n-   une **table agr√©g√©e** pour un graphique par exemple, √† l'aide de la fonction `summarise()`.\n\n## Programmer sans collecter {.smaller}\n\nJe sais que la cr√©ation de ma table donne le r√©sultat souhait√©e (car j'ai regard√© ce dont elle a l'air avvec `head()`), maintenant je vais l'appeler une dizaine de fois pour collecter uniquement des statistiques descriptives.\n\nQue se passe-t-il √† chaque fois que je collecte une statistique descriptive ?\n\n. . .\n\nLa cr√©ation de la table va √™tre ex√©cut√©e √† nouveau : tr√®s long ?\n\nComment faire ?\n\n::: panel-tabset\n## Cache\n\nLa cr√©ation de la table est ex√©cut√©e une seule fois, le r√©sultat est conserv√© en m√©moire vive\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma_table_spark <- MMO_2017 %>%\n  filter(DebutCTT > as.Date(\"2017-06-01\")) %>%\n  mutate(duree_CTT = DATEDIFF(FinCTT,DebutCTT) + 1) %>%\n  sdf_register(name = \"ma_table_spark\")\n\ntbl_cache(\"ma_table_spark\")\n```\n:::\n\n\n\n:::\n\n::: notes\nR√©ponse attendue : c'est une action donc ca d√©clenche la cr√©ation de la table Indice : cr√©ation de table contient uniquement des transformations\n:::\n\n## Optimiser la m√©moire : conclusion\n\nPour programmer en spark sans aucune erreur :\n\n1.  D√©clencher une action avec plusieurs transformations pour laisser Catalyst optimiser\n\n2.  Ne pas collecter tout une table\n\n3.  Persister ou cacher une table qu'on va appeler plusieurs fois pour ne collecter que des statistiques descriptives\n\n4.  Ne pas persister trop de tables : occupe de la m√©moire RAM\n\n5.  Consulter le programme exemple sur la bulle CASD si besoin\n\n# Pour aller plus loin\n\n## Partitionnement {.smaller}\n\nLe format `.parquet` (avec `arrow`) et le framework `spark` permettent de g√©rer le partitionnement des donn√©es.\n\nLe partitionnement a un impact sur la mani√®re dont les donn√©es sont organis√©es physiquement sur le syst√®me de fichiers.\n\n![](images/partitioned_parquet_file_archi.png){fig-align=\"center\" width=\"1000\"}\n\n## Partitionnement {.smaller}\n\n<br>\n\n+----------------------------------------+-----------+-----------+-----------+\n| Partitions                             | 2         | 5         | 1000      |\n+========================================+===========+===========+===========+\n| Colonne qui a servi au partitionnement | 74,50%    | 46,30%    | 16,66%    |\n+----------------------------------------+-----------+-----------+-----------+\n| Vers une autre colonne                 | 89,51%    | 191,01%   | 556,99%   |\n+----------------------------------------+-----------+-----------+-----------+\n| Select distinct(\\*)                    | 136,79%   | 163,68%   | 1194,88%  |\n+----------------------------------------+-----------+-----------+-----------+\n\n<br>\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_write_parquet(ma_table, \"hdfs:///resultats/ma_table.parquet\", partition_by = c(\"age\",\"sex\"))\n```\n:::\n\n\n\n\n## √âviter le probl√®me des ex√©cuteurs inactifs {.smaller}\n\nSupposons que le jeu de donn√©es ait 8 partitions, un ex√©cuteur (avec seulement 1 core) ne peut ex√©cuter qu'une t√¢che(task) √† la fois, et une partition = une t√¢che.\n\nCas 1 : 6 ex√©cuteurs, au dernier tour, il ne reste que 2 t√¢ches, 4 ex√©cuteurs seront inactifs. Cas 2 : 4 ex√©cuteurs, 2\\*4, aucun ex√©cuteur inactif.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the number of partitions\nnum_partitions <- sdf_num_partitions(df)\nprint(num_partitions)\n\n# Repartition the DataFrame to a specific number of partitions\ndf_repartitioned <- sdf_repartition(df, partitions = 10)\n```\n:::\n\n\n\n\n-   Le nombre de partitions doit √™tre divisible par le nombre d'ex√©cuteurs.\n-   Le nombre de partitions doit √™tre sup√©rieur au nombre d'ex√©cuteurs.\n\n## √âviter trop de partitions {.smaller}\n\nLa cr√©ation de t√¢ches entra√Æne des surcharges, qui doivent toujours √™tre inf√©rieures √† 50 % du temps total d'ex√©cution de la t√¢che.\n\n![](images/stage_eventtimeline.png)\n\n-   <div>\n\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    # Repartition the DataFrame to a specific number of partitions\n    df_repartitioned <- sdf_repartition(df, partitions = 10)\n    \n    # Repartition the DataFrame by a specific column, e.g., \"commune_code\".\n    # The partition number will be the distinct value number\n    df_repartitioned <- sdf_repartition(df, partition_by = \"commune_code\")\n    ```\n    :::\n\n\n\n\n    </div>\n\n-   La r√©partition est une op√©ration tr√®s co√ªteuse, utilisez-la judicieusement.\n\n-   En g√©n√©ral, la taille recommand√©e des partitions est d'environ 128 √† 512 Mo.\n\n## Optimiser la configuration des ex√©cuteurs {.smaller}\n\nConfiguration recommand√©e :\n\n-   Un ex√©cuteur devrait avoir entre 3 et 5 cores.\n-   Pour chaque core, il faut r√©server entre 4 et 8 Go de m√©moire.\n\nEn mode cluster, chaque ex√©cuteur fonctionne dans une JVM (la JVM n√©cessite une m√©moire suppl√©mentaire et du CPU pour ex√©cuter le GC).\n\n-   √âvitez 1 core par ex√©cuteur.\n-   √âvitez trop de cores dans un seul ex√©cuteur, cela peut causer des probl√®mes de contention de threads ou la surcharge du garbage collector.\n\n## T√¢ches Maximales en parall√®les {.smaller}\n\n<br>\n\n::: callout-tip\n## Parall√©lisation\n\n**Max_Parallel_Tasks = Number_of_Executors \\* Cores_per_Executor**\n:::\n\n<br>\n\nPar exemple, une session Spark dispose de la configuration suivante :\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf[\"spark.executor.memory\"] <- \"32Go\"\nconf[\"spark.executor.cores\"] <- 4\nconf[\"spark.executor.instances\"] <- 5\n```\n:::\n\n\n\n\n5 executor \\* 4 core = 20 t√¢ches en parall√®le. Pour un jeu de donn√©es de 200 partitions, il faut 10 tours pour terminer tous les calculs.\n\n<br>\n\n‚ñ∂Ô∏èIl n'existe pas de configuration universelle optimale pour tous, seulement la meilleure configuration pour vos t√¢ches.\n\n## SparkUI {.smaller .scrollable}\n\nSpark UI permet de consulter le plan logique et physique du traitement demand√©. Trois outils permettent d'optimiser les traitements :\n\n::: panel-tabset\n## DAG\n\n![](images/dag.webp)\n\n## GC\n\nV√©rifier que le `gc time` est inf√©rieur √† 10% du temps pour ex√©cuter la t√¢che ‚úÖ\n\n![](images/gc.png)\n\n## M√©moire\n\nV√©rifier que la `storage memory` ne sature pas la m√©moire ‚úÖ\n\n![](images/gc.png)\n:::\n\n## Sparkhistory {.smaller .scrollable}\n\n-   **Sparkhistory** pour des traitements de sessions ferm√©es\n\nLe sparkhistory entra√Æne l'enregistrement de logs assez lourdes, il est donc d√©sactiv√© par d√©faut. Pour l'activer sur un programme :\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf <- spark_config()\nconf[\"spark.eventLog.enabled\"] <- \"true\"\nconf[\"spark.eventLog.dir\"] <- \"hdfs://midares-deb11-nn-01.midares.local:9000/spark-logs\"\nconf[\"appName\"] <- \"un_nom_de_traitement\"\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n\n\n## Pyspark\n\n<br>\n\n![](images/pyspark.drawio.png){fig-align=\"center\"}\n\n# Annexe\n\n## Le stockage distribu√© avec HDFS {.smaller}\n\nHadoop Distributed File System (HDFS)\n\n-   **stockage sur diff√©rentes machines :** les diff√©rents ordinateurs workers du cluster\n\n-   donn√©es divis√©es **en blocs** plus petits de taille fixe et r√©partis sur les machines : aucune table de MiDAS n'existe en entier sur le cluster\n\n-   chaque bloc est **r√©pliqu√© trois fois** : il existe trois fois les 10 premi√®res lignes de la table FNA sur trois ordinateurs diff√©rents du cluster (r√©silience)\n\n-   un **NameNode** supervise les **m√©tadonn√©es** et g√®re la structure du syst√®me de fichiers : il sait o√π sont quels fichiers\n\n-   les **DataNodes** stockent effectivement les blocs de donn√©es : les datanodes sont en fait les disques durs des workers du cluster, chaque ordinateur du cluster dispose d'un disque avec une partie des donn√©es MiDAS\n\n-   le **syst√®me HDFS** est reli√© √† la bulle Midares : possible de charger des donn√©es en clique-bouton de la bulle vers HDFS de mani√®re tr√®s rapide et de t√©l√©charger des tables de HDFS pour les r√©cup√©rer en local\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}