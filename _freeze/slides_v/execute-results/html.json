{
  "hash": "10f0b9bc8d7cdac79c741d126e8f9db0",
  "result": {
    "markdown": "---\ntitle: \"Initiation √† Spark avec R en mode cluster\"\nformat: revealjs\n---\n\n\n## Au programme\n\n1.  MiDAS : une base de donn√©es volumineuse\n\n2.  Utiliser MiDAS avec R : un d√©fi\n\n3.  Sparklyr : l'outil ergonomique de spark en R\n\n4.  Optimiser la m√©moire : pourquoi et comment\n\n5.  Les bonnes pratiques\n\n6.  Pour aller plus loin\n\n# Un rapide tour de table üí¨\n\n# MiDAS : une base de donn√©es volumineuses\n\n## Qu'est-ce que MiDAS ?\n\n![](/images/midas_traj_1.PNG){fig-align=\"right\" width=\"900\"}\n\n![](/images/midas_traj_2.PNG){fig-align=\"right\" width=\"780\"}\n\n## Une des bases les plus volumineuses du SSP {.smaller}\n\n![](/images/donnees_ssp.PNG){fig-align=\"center\"}\n\nLes administrations dont les donn√©es sont comparables √† MiDAS utilisent un cluster Spark : Insee, Drees, Acoss...\n\n‚ñ∂Ô∏èLe cluster spark est une solution la tr√®s efficiente pour traiter des donn√©es de cette ampleur.\n\n## Concr√®tement, qu'est-ce que MiDAS ? {.smaller}\n\n![](/images/structure_midas.png){fig-align=\"center\"}\n\n::: callout-tip\n## Pourquoi Spark ?\n\nLa manipulation des donn√©es MiDAS en l'√©tat implique de nombreuses op√©rations de jointures qui n√©cessitent une puissance de calcul et un temps certains.\n:::\n\n## O√π est MiDAS sur la bulle ? {.smaller}\n\nDisponible dans l'espace commun (= Documents publics) : C:\\\\Users\\\\Public\\\\Documents\\\\MiDAS_parquet\\\\Vague X\n\n<br>\n\nAu format **parquet** :\n\n-   **compression** efficace des donn√©es : taux de compression de 5 √† 10 par rapport au format csv\n\n-   orient√© **colonnes**\n\n-   chargement efficace **en m√©moire** des donn√©es\n\n-   **stockage partitionn√©** des donn√©es avec `write_dataset()`\n\n-   traiter des donn√©es **sur disque**\n\n-   **ind√©pendant du logiciel** utilis√© : R, python, spark...\n\n## La documentation en ligne {.smaller}\n\n<br>\n\n::: columns\n::: {.column width=\"35%\"}\n[Documentation en ligne](https://documentationmidas.github.io/Documentation_MiDAS/Presentation/pr%C3%A9sentation.html)\n\n-   Dictionnaire des donn√©es\n\n-   Fiches pr√©sentant les concepts de l'indemnisation, du retour √† l'emploi\n\n-   Exemples d'impl√©mentation en R\n\n-   Conseils quallit√© des variables\n:::\n\n::: {.column width=\"65%\"}\n![](/images/documentation_midas.PNG){fig-align=\"center\"}\n:::\n:::\n\n# Et vous, quels sont vos usages de MiDAS ? üëÅÔ∏è‚Äçüó®Ô∏è\n\n# Traiter MiDAS en R : un d√©fi üë®‚Äçüíª\n\n## Une bulle CASD {.smaller}\n\nDes ressources partag√©es entre tous les utilsateurs simultan√©s :\n\n-   512 Go de m√©moire vive (ou RAM) : passage √† 256 Go\n-   Un processeur (ou CPU) compos√© de 32 coeurs : passage √† 16 coeurs\n\n![](/images/schema_ordinateur.png){fig-align=\"center\"}\n\n::: notes\nBulle CASD = un gros ordinateur partag√© par plusieurs utilisateurs, besoin du voc ordinateur pour comprendre spark\n:::\n\n## Une bulle CASD {.smaller}\n\n::: panel-tabset\n### La m√©moire vive\n\nLa m√©moire vive, aussi appel√©e **RAM**, se distingue de la m√©moire de stockage (disque) :\n\n-   par sa **rapidit√©**, notamment pour fournir des donn√©es au processeur pour effectuer des calculs\n\n-   par sa **volatilit√©** (toutes les donn√©es sont perdues si l'ordinateur n'est plus aliment√©)\n\n-   par l'acc√®s direct aux informations qui y sont stock√©es, **quasi instantann√©**.\n\n### Le processeur\n\nLe processeur :\n\n-   permet d'**ex√©cuter des t√¢ches et des programmes** : convertir un fichier, ex√©cuter un logiciel\n\n-   est compos√© d'un ou de plusieurs **coeurs** : un coeur ne peut ex√©cuter qu'une seule t√¢che √† la fois. Si le processeur contient plusieurs coeurs, il peut ex√©cuter autant de t√¢ches en parall√®le qu'il a de coeurs\n\n-   se caract√©rise aussi par sa **fr√©quence** : elle est globalement proportionnelle au nombre d'op√©rations qu'il est capable d'effetuer par seconde.\n:::\n\n## Traiter MiDAS en R : les limites\n\n1.  Charger les donn√©es en m√©moire vive\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  path_fna <- \"C:/Users/Public/Documents/MiDAS_parquet/Vague 4/FNA/\"\n  \n  PJC <- read_parquet(paste0(path_fna, \"pjc.parquet\"), memory = TRUE)\n  ODD <- read_parquet(paste0(path_fna, \"odd.parquet\"), memory = TRUE)\n```\n:::\n\n\n. . .\n\n2.  R√©aliser des op√©rations co√ªteuses en ressources\n\n\n::: {.cell}\n\n```{.r .cell-code}\njointure <- PJC %>%\n  rename(KROD1 = KROD3) %>%\n  left_join(ODD, by = c(\"id_midas\", \"KROD1\"))\n```\n:::\n\n\n. . .\n\n3.  Le partage des ressources de la bulle\n\nChaque utilisateur peut mobiliser toutes les ressouces de la bulle.\n\n::: notes\nDonn√©es \\> RAM et R fonctionne dans la m√©moire vive (pour √ßa que plus rapide que SAS) Jointures co√ªteux : on va voir pourquoi apr√®s tlm sur la m√™me bulle sans allocation des ressources = ralentissements\n:::\n\n## Traitement l√©ger versus co√ªteux {.smaller}\n\n::: panel-tabset\n## MAP = l√©ger {.smaller}\n\n![](/images/formation%20sparklyr-Page-1.drawio.png){fig-align=\"center\"}\n\n::: notes\nCe traitement est peu co√ªteux :\n\n-   chargement d'une seule colonne en RAM : format parquet orient√© colonnes\n\n-   peu de m√©moire d'ex√©cution : R est un langage vectoris√©\n:::\n\n## REDUCE = co√ªteux {.smaller}\n\n![](/images/formation%20sparklyr-Page-2.drawio.png){fig-align=\"center\"}\n\n::: notes\nCe traitement n√©cessite :\n\n-   le chargement de davantage de colonnes en m√©moire vive ;\n\n-   davantage de m√©moire d'ex√©cution pour effectuer l'intersection (`inner_join()`).\n:::\n\n## REDUCE en R\n\n-   les jointures\n\n-   les op√©rations en `group_by()`\n\n-   les op√©rations de tri avec `arrange()`\n\n-   `distinct()`\n\n    ‚ñ∂Ô∏è Ex√©cution s√©quentielle sur un coeur du processeur + beaucoup de m√©moire vive (donn√©es temporaires)\n\n    ‚ñ∂Ô∏è Erreur \"out of memory\".\n:::\n\n::: notes\nParquet orient√© colonne donc ne charge que les colonnes n√©cessaires en m√©moire R vectoris√© : op√©ration appliqu√©e √† tout le vecteur = traitement rapide\n\nJointure co√ªteuse parce que comparaison ligne √† ligne\n\nwindow funcions\n:::\n\n## Pourquoi spark ? {.smaller}\n\n+------------------------+------------------------+----------------------------------+\n| Solution test√©e        | Avantage               | Limites rencontr√©e               |\n+========================+========================+==================================+\n| Package ¬´ data.table ¬ª | Calculs parall√©lis√©s   | pour bases \\< RAM                |\n|                        |                        |                                  |\n|                        |                        | Syntaxe tr√®s diff√©rente de dplyr |\n+------------------------+------------------------+----------------------------------+\n| Format ¬´ parquet ¬ª +   | Stockage moins lourd   | Taille en m√©moire inchang√©e      |\n|                        |                        |                                  |\n| package ¬´ arrow ¬ª      | Chargement efficient   |                                  |\n+------------------------+------------------------+----------------------------------+\n| DuckDB                 | Gestionnaire de BDD    | Pour des bases \\< 100 Go         |\n|                        |                        |                                  |\n|                        |                        | Fonctions et options non cod√©es  |\n+------------------------+------------------------+----------------------------------+\n| Spark en mode local    | Traitements distribu√©s | Consomme beaucoup de ressources  |\n|                        |                        |                                  |\n|                        |                        | Inadapt√© pour une unique bulle   |\n|                        |                        |                                  |\n|                        |                        | N√©cessite le ¬´ collect() ¬ª       |\n+------------------------+------------------------+----------------------------------+\n\n## Un gain de temps consid√©rable {.smaller}\n\n<br>\n\n+---------------------+-----------------------------------------------------------------------------+---------------------------------------------+\n|                     | Calcul de la dur√©e moyenne du premier contrat pour tous les individus MiDAS | Retour √† l'emploi salari√© des indemnisables |\n+=====================+=============================================================================+=============================================+\n| Classique R         | 4 heures                                                                    | Crash                                       |\n+---------------------+-----------------------------------------------------------------------------+---------------------------------------------+\n| Arrow + duckdb      | 8 minutes                                                                   | 3 heures seul sur la bulle                  |\n+---------------------+-----------------------------------------------------------------------------+---------------------------------------------+\n| Arrow + spark local | 1 minute                                                                    | 2 minutes                                   |\n+---------------------+-----------------------------------------------------------------------------+---------------------------------------------+\n\nMais alors, pourquoi le cluster ? ü§î\n\n## Une bonne allocation des ressources entre utilisateurs\n\n::: r-stack\n![](/images/mode_local.PNG){.fragment fig-align=\"center\" width=\"1000\" height=\"450\"}\n\n![](/images/mode_cluster.PNG){.fragment fig-align=\"center\" width=\"1000\" height=\"450\"}\n:::\n\n# Et vous, quels sont vos probl√©matiques et vos solutions ? ‚ö†Ô∏è\n\n# Comment on fait du spark cluster avec R version courte ? ‚è≤Ô∏è\n\n## O√π est Midas, 2√®me √©dition {.smaller}\n\nLe cluster a son propre explorateur de fichiers √† mettre en favori dans son navigateur : https://midares-deb11-nn-01.midares.local:9870/\n\n::: r-stack\n![](/images/hdfs_browse.png){.fragment fig-align=\"center\" width=\"900\" height=\"500\"}\n\n![](/images/hdfs_midas.png){.fragment fig-align=\"center\" width=\"900\" height=\"500\"}\n:::\n\n## Un cluster de calcul\n\n![](/images/schema_cluster.drawio.png){fig-align=\"center\"}\n\n## Connexion\n\n::: panel-tabset\n## Traitement l√©ger\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(dbplyr)\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"20Go\"\nconf[\"spark.executor.memory\"] <- \"60Go\"\nconf[\"spark.executor.cores\"] <- 4\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n## Traitement lourd\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(dbplyr)\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"20Go\"\nconf[\"spark.executor.memory\"] <- \"140Go\"\nconf[\"spark.executor.cores\"] <- 8\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n:::\n\n## Chargement des donn√©es en spark\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Depuis HDFS\nmmo_17_df_spark <- spark_read_parquet(sc,\n                                  path = \"hdfs:///dataset/MiDAS_v4/mmo/mmo_2017.parquet\",\n                                  memory = FALSE)\n\n### Passer un dataframe R en spark\nmon_data_frame <- data.frame(c(\"Anna\", \"Paul\"), c(15, 20))\nmon_data_frame_spark <- copy_to(sc, \"mon_data_frame\")\n```\n:::\n\n\n<br>\n\n‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : par d√©faut, `memory = FALSE`\n\n## Sparklyr, c'est comme dplyr\n\n<br>\n\nEnsuite, vous pouvez programmer avec `dplyr` !\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmmo_17_df_spark <- mmo_17_df_spark %>%\n  rename(debut_contrat = DebutCTT) %>%\n  filter(debut_contrat >= as.Date(\"2017-01-01\") & debut_contrat < as.Date(\"2017-02-01\")) %>%\n  mutate(mois_debut_contrat = substr(debut_contrat,6,7))\n```\n:::\n\n\n## La lazy evaluation {.smaller}\n\nSpark distingue deux types d'op√©rations :\n\n-   **les transformations :** prennent en entr√©e un `spark_data_frame` et retournent un `spark_data_frame`, elles ne d√©clenchent aucun calcul\n\n    Par exemple, le programme ci-dessous ne d√©clenche pas d'ex√©cution :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmmo_17_df_spark_mois <- mmo_17_df_spark %>%\n  rename(debut_contrat = DebutCTT) %>%\n  filter(debut_contrat >= as.Date(\"2017-01-01\") & debut_contrat < as.Date(\"2017-06-01\")) %>%\n  mutate(mois_debut_contrat = substr(debut_contrat,6,7))\n```\n:::\n\n\n-   **les actions :** forcent le calcul d'un r√©sultat pour le r√©cup√©rer et d√©clenchent l'ex√©cution de toutes les transformations compil√©es jusqu'√† l'appel de l'action.\n\n    Par exemple, le programme ci-dessous d√©clenche le calcul de toute la cellule pr√©c√©dente :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_debut_contrat_fev_17 <- mmo_17_df_spark_mois %>%\n  group_by(mois_debut_contrat) %>%\n  summarise(nb_contrats = n()) %>%\n  print()\n```\n:::\n\n\n## La lazy evaluation : un gain de temps consid√©rable\n\n<br>\n\n::: callout-tip\n## La gestion des erreurs\n\nEn r√©alit√©, lorsqu'on appuie ysur le bouton `run`, il ne se passe pas \"rien\". Le code est compil√© par spark : les erreurs sont rep√©r√©es avant m√™me que le code soit ex√©cut√© !\n:::\n\nINSERER EXEMPLE ERREUR REPEREE A LA COMPILATION\n\n## R√©cup√©rer un r√©sultat\n\nLes principales actions sont :\n\n-   `print()`\n\n-   `collect()`\n\n-   `head()`\n\n-   `tbl_cache()` (√©crire un `spark_data_frame` en m√©moire pour le r√©utiliser)\n\n## ... presque tout comme dplyr {.smaller .scrollable}\n\nLa majorit√© des commandes `dplyr` fonctionnent sur un spark_data_frame avec le package `sparklyr`. Les divergences principales sont les suivantes :\n\n+--------------------------------+----------------+----------------------------------+\n| Fonctionnalit√©                 | tidyverse      | sparklyr                         |\n+================================+================+==================================+\n| import d'un fichier `.parquet` | `read_parquet` | `spark_read_parquet()`           |\n+--------------------------------+----------------+----------------------------------+\n| tri d'un tableau               | `arrange()`    | `window_order()` ou `sdf_sort()` |\n+--------------------------------+----------------+----------------------------------+\n| op√©rations sur les dates       | `lubridate`    | fonctions Hive                   |\n+--------------------------------+----------------+----------------------------------+\n| empiler des tableaux           | `bind_rows()`  | `sdf_bind_rows()`                |\n+--------------------------------+----------------+----------------------------------+\n| nombre de lignes d'un tableau  | `nrow()`       | `sdf_nrow()`                     |\n+--------------------------------+----------------+----------------------------------+\n| faire pivoter un tableau       | `tidyr`        | `sdf_pivot()`                    |\n+--------------------------------+----------------+----------------------------------+\n| export d'un `spark_data_frame` |                | `spark_write_parquet()`          |\n+--------------------------------+----------------+----------------------------------+\n\n## Quelques fonctions sp√©cifiques {.smaller .scrollable}\n\n::: panel-tabset\n## Dates\n\nLes fonctions de `lubridate()`ne sont pas adapt√©es au `spark_data_frames`.\n\n-   Convertir une cha√Æne de caract√®re de la forme AAAA-MM-DD en Date\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    date_1 <- as.Date(\"2024-05-26\")\n    ```\n    :::\n\n\n-   Calculer une dur√©e entre deux dates\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    PJC_spark <- spark_read_parquet(sc,\n                                    path = \"hdfs:///dataset/MiDAS_v4/pjc.parquet\",\n                                    memory = FALSE)\n    \n    duree_pjc_df <- PJC_spark %>%\n      rename(date_fin_pjc = as.Date(KDFPJ),\n             date_deb_pjc = as.Date(KDDPJ)) %>%\n      mutate(duree_pjc = datediff(date_fin_pjc, date_deb_pjc) + 1) %>%\n      head(5)\n    ```\n    :::\n\n\n-   Ajouter ou soustraire des jours ou des mois √† une date\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    duree_pjc_bis_df <- duree_pjc_df %>%\n      mutate(duree_pjc_plus_5 = date_add(duree_pjc, int(5)),\n             duree_pjc_moins_5 = date_sub(duree_pjc, int(5)),\n             duree_pjc_plus_1_mois = add_months(duree_pjc, int(1))) %>%\n      head(5)\n    ```\n    :::\n\n\n::: callout-note\n## Add_months\n\nSi la date en entr√©e est le dernier jour d'un mois, la date retourn√©e avec `add_months(date_entree, int(1))` sera le dernier jour calendaire du mois suivant.\n:::\n\n::: callout-tip\n## Format\n\nLe `int()` est important car ces fonctions Hive n'accepte que les entiers pour l'ajout de jours : taper uniquement 5 est consid√©r√© comme un flottant dans R.\n:::\n\n## Tableau\n\n-   Tri dans un groupe pour effectuer un calcul s√©quentiel\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_spark <- spark_read_parquet(sc,\n                                    path = \"hdfs:///dataset/MiDAS_v4/odd.parquet\",\n                                    memory = FALSE)\n    \n    ODD_premier <- ODD_spark %>%\n      group_by(id_midas) %>%\n      window_order(id_midas, KDPOD) %>%\n      mutate(date_premier_droit = first(KDPOD)) %>%\n      ungroup() %>%\n      distinct(id_midas, KROD3, date_premier_droit) %>%\n      head(5)\n    ```\n    :::\n\n\n-   Tri pour une sortie : `sdf_sort()` , `arrange()` ne fonctionne pas\n\n-   Concat√©ner les lignes (ou les colonnes `sdf_bind_cols()`)\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_1 <- ODD_spark %>%\n      filter(KDPOD <= as.Date(\"2017-12-31\")) %>%\n      mutate(groupe = \"temoins\")\n    \n    ODD_2 <- ODD_spark %>%\n      filter(KDPOD >= as.Date(\"2021-12-31\")) %>%\n      mutate(groupe = \"traites\")\n    \n    ODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)\n    ```\n    :::\n\n\n-   D√©doublonner une table\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    droits_dans_PJC <- PJC_spark %>%\n      sdf_distinct(id_midas, KROD3)\n    \n    print(head(droits_dans_PJC, 5))\n    \n    PJC_dedoublonnee <- PJC_spark %>%\n      sdf_drop_duplicates()\n    \n    print(head(PJC_dedoublonnee, 5))\n    ```\n    :::\n\n\n-   Pivot : les fonctions du packag `tidyr` ne fonctionnent pas sur donn√©es spark\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_sjr_moyen <- ODD_spark %>%\n      mutate(groupe = ifelse(KDPOD <= as.Date(\"2020-12-31\"), \"controles\", \"traites\")) %>%\n      sdf_pivot(groupe ~ KCRGC,\n        fun.aggregate = list(KQCSJP = \"mean\")\n      )\n    ```\n    :::\n\n\n## Statistiques\n\n-   R√©sum√© statistique : `sdf_describe()` , `summary()`ne fonctionne pas.\n\n-   Dimension : `sdf_dim`, la fonction `nrow()`ne fonctionne pas.\n\n-   Quantiles approximatifs : le calcul des quantiles sur donn√©es distirbu√©es renvoie une approximation car toutes les donn√©es ne peuvent pas √™tre rappatri√©es sur la m√™me machine physique du fait de la volum√©trie, `sdf_quantile()`\n\n-   Echantillonnage al√©atoire : `sdf_random_split`\n:::\n\n## Exporter des donn√©es {.smaller}\n\nExport des spark data frames directement sous HDFS : √† aucun moment on n'ouvre la table : on peut traiter des donn√©es beaucoup plus volumnieuses que la m√©moire RAM !\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma_table <- data.frame(c(\"Anne\", \"Paul\"), c(25,30))\n\nma_table_spark <- copy_to(sc, ma_table)\n\nspark_write_parquet(ma_table_spark, \"hdfs:///resultats/ma_table.parquet\")\n```\n:::\n\n\nPossibilit√© de r√©cup√©rer ce fichier sur la bulle MiDARES = en local.\n\n::: callout-warning\n## Exports simultan√©s\n\nHDFS supporte les exports simultan√©s, mais le temp d'export est plus long lorsque le NameNode est requ√™t√© par plusieurs personnes simultan√©ment : d'apr√®s les tests cluster\n\n-   pour un petit export (5 minutes), le temps peut √™tre multipli√© par 4 ;\n\n-   pour un gros export (15 minutes), le temps peut √™tre multipli√© par 2.\n:::\n\n## Si on souhaite la r√©cup√©rer en local {.smaller}\n\n::: callout-caution\n## Les exports sur HDFS\n\nLorsqu'on exporte une table depuis notre session R vers HDFS, celle-ci est **automatiquement partitionn√©e**, comme le reste des donn√©es.\n\nAinsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.\n\nIl est possible de ma√Ætriser le nombre de partitions avec la commande `sdf_coalesce(partitions = 1)` du package `sparklyr`.\n\nAvec `sdf_coalesce(partitions = 1)`, on n'aura qu'un seul fichier √† t√©l√©charger depuis HDFS.\n\nAvec `sdf_coalesce(partitions = 200)`, on aura 200 morceaux de notre fichier √† t√©l√©charger √† la main (pas possible de faire tout s√©lectionner sous HDFS !).\n\nL'id√©al est d'**adapter le nombre de partitions √† la taille d'un bloc** : un bloc mesure 128 MB.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma_table <- data.frame(c(\"Anne\", \"Paul\"), c(25,30))\n\nma_table_spark <- copy_to(sc, ma_table) %>%\n  sdf_coalesce(partitions = 1)\n\nspark_write_parquet(ma_table_spark, \"hdfs:///resultats/ma_table.parquet\")\n```\n:::\n\n\n## T√©l√©charger des donn√©es en local {.smaller}\n\n::: r-stack\n![](images/hdfs_browse.png){.fragment width=\"1000\" height=\"700\"}\n\n![](/images/hdfs_dowload.PNG){.fragment}\n:::\n\n## Et ensuite ? {.smaller}\n\nSpark est un outil de traitement de donn√©es volumineuses. Il n'est pas toujours adapt√© :\n\n-   pour de toutes petites tables : il ne va pas engendrer de gain de temps\n\n-   pour faire de l'√©conom√©trie pouss√©e : tous les packages R ne sont pas traduits en spark\n\n-   pour ouvrir sa table : on perd les avantages de spark si on collecte toute la table en m√©moire RAM\n\nConseils :\n\n1.  Cr√©er sa table d'√©tude en appariant les tables de MiDAS avec le cluster spark\n\n2.  L'exporter sous HDFS\n\n3.  La t√©l√©charger en local\n\n4.  La charger en R classique pour faire de l'√©conom√©trie\n\n# Optimiser le code : non ! Mais optimiser la m√©moire...\n\n## Comment fonctionne spark ? {.smaller}\n\n-   Apache Spark : **librairie open source** d√©velopp√©e dans le langage `scala`\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    val TopHorrorsIGN2022 = Seq(\n      (9, \"Pearl\"),\n      (6, \"The Sadness\"),\n      (6, \"Offseason\"),\n      (7, \"Hatching\"),\n      (8, \"x\")\n    ).toDF(\"IMDB Rating\", \"IGN Movie Picks\")\n    \n    import org.apache.spark.sql.functions.col\n    \n    val cols = List(col(\"IGN Movie Picks\"), col(\"AVC Movie Picks\"))\n    \n    val query = TopHorrorsIGN2022(\n      \"IGN Movie Picks\"\n    ) === TopHorrorsTheAVClub2022(\"AVC Movie Picks\")\n    \n    val outerJoin = TopHorrorsIGN2022\n      .join(TopHorrorsTheAVClub2022, query, \"outer\")\n      .select(cols: _*)\n    \n    outerJoin.show()\n    ```\n    :::\n\n\n-   `scala` adapt√© pour ma√Ætriser toutes les fonctionnalit√©s de `spark` et optimiser au maximum les traitements en `spark`\n\n-   `spark` est **compatible avec les langages** `scala`, `R`, `python`, `java`, et peut interpr√©ter des commandes **SQL.**\n\n## Le driver en sparklyr {.smaller}\n\n![](/images/schema_cluster.drawio.png){fig-align=\"center\" width=\"400\"}\n\n-   Le programme R est traduit en scala gr√¢ce au package `sparklyr`\n\n-   Le driver √©value le programme, il lit le code `scala` mais n'ex√©cute rien du tout\n\n-   S'il remarque une erreur, l'erreur est envoy√©e directement √† l'utilisateur en session R avant l'ex√©cution du programme : c'est la force de la lazy evaluation.\n\n## Pas besoin d'optimiser son code ! {.smaller}\n\n![](images/catalyst.jpg)\n\nsource : documentation CASD disponible √† [Documentation Data Science](https://casd-eu.gitbook.io/data-science/)\n\n## Catalyst optimise le code pour nous {.smaller}\n\nLe driver contient un programme nomm√© Catalyst qui optimise le code `scala` automatiquement.\n\nSpark optimise automatiquement les programmes soumis :\n\n1.  Compilation des transformations pour soulever les √©ventuelles erreurs\n\n2.  Int√©gration dans un **plan d'ex√©cution** contenant les √©tapes n√©cessaires pour parvenir au r√©sultat demand√© par le programme\n\n3.  Optimisation du plan logique par le module **Catalyst** (driver Spark)\n\n::: callout-warning\n## Les erreurs en sparklyr\n\nPetite pr√©cision sur les erreurs :\n\n-   sparklyr traduit le code R en scala\n\n-   mais √©galement les messages envoy√©s par spark en R\n\n-   les erreurs affich√©es en R ne sont pas toujours bien interpr√©tables\n:::\n\n## Catalyst optimise le code pour nous {.smaller .scrollable}\n\n![](images/dag.webp){fig-align=\"center\"}\n\n## Catalyst optimise le code pour nous\n\nPar exemple si j'√©cris le programme :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnon_optimal <- table_1 %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))\n```\n:::\n\n\n<br>\n\nCatalyst r√©√©crit :\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptimal <- table_1 %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\")) %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))\n```\n:::\n\n\nCette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu'une action d√©clenche l'ex√©cution.\n\n## Catalyst optimise le code pour nous : laissons-le travailler ! {.smaller}\n\n**D√©clencher le moins d'actions possibles** dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.\n\nPour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique. On √©vite quoi ?\n\n. . .\n\nOn √©vite :\n\n-   de mettre des `collect()`sur chaque table interm√©diaire\n\n-   de `collect()` une table enti√®re\n\n-   de `print()` √† chaque √©tape\n\n. . .\n\nSinon Catalyst n'a pas assez de code pour optimiser !\n\n## Catalyst optimise le code pour nous : laissons-le travailler !\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnon_optimal <- table_1 %>% \n    collect() %>%\n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))\n```\n:::\n\n\n. . .\n\nversus\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnon_optimal <- table_1 %>% \n    collect() %>%\n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\")) \n```\n:::\n\n\n## Jointures : un cas particulier\n\nPour effectuer ce type de jointure avec deux tables de volum√©tries diff√©rentes : A est petite, B est tr√®s volumineuse\n\n![](images/join.png)\n\nSolution rapide :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable_finale <- table_volumineuse_comme_PJC %>%\n  right_join(petite_table_mon_champ)\n```\n:::\n\n\nSolution lente :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable_finale <- petite_table_mon_champ %>%\n  left_join(table_volumineuse_comme_PJC)\n```\n:::\n\n\n## Calcul distribu√© et r√©cup√©ration des r√©sultats {.smaller}\n\n![](images/schema_cluster.drawio.png){fig-align=\"center\" width=\"400\"}\n\n::: callout-important\n## Le r√©seau\n\n-   Les workers communiquent avec le driver de la bulle MiDARES en r√©seau\n\n-   Les workers communiquent entre eux en r√©seau pour s'√©changer des donn√©es\n\n-   Le r√©seau est un mode de communication lent\n:::\n\n::: notes\nMtn un peu de th√©orie pour comprendre le calcul distribu√© et mieux l'utiliser\n:::\n\n## Le stockage distribu√© avec HDFS {.smaller}\n\n![](images/stockage_distribue.drawio.png){fig-align=\"center\"}\n\n## Le stockage distribu√© avec HDFS {.smaller}\n\nHadoop Distributed File System (HDFS)\n\n-   **stockage sur diff√©rentes machines :** les diff√©rents ordinateurs workers du cluster\n\n-   donn√©es divis√©es **en blocs** plus petits de taille fixe et r√©partis sur les machines : aucune table de MiDAS n'existe en entier sur le cluster\n\n-   chaque bloc est **r√©pliqu√© trois fois** : il existe trois fois les 10 premi√®res lignes de la table FNA sur trois ordinateurs diff√©rents du cluster (r√©silience)\n\n-   un **NameNode** supervise les **m√©tadonn√©es** et g√®re la structure du syst√®me de fichiers : il sait o√π sont quels fichiers\n\n-   les **DataNodes** stockent effectivement les blocs de donn√©es : les datanodes sont en fait les disques durs des workers du cluster, chaque ordinateur du cluster dispose d'un disque avec une partie des donn√©es MiDAS\n\n-   le **syst√®me HDFS** est reli√© √† la bulle Midares : possible de charger des donn√©es en clique-bouton de la bulle vers HDFS de mani√®re tr√®s rapide et de t√©l√©charger des tables de HDFS pour les r√©cup√©rer en local\n\n## Le r√¥le du cluster manager {.smaller}\n\n![](images/calcul_distribue.drawio.png){fig-align=\"center\"}\n\nLe cluster manager distribue les traitements physiques aux ordinateurs du cluster :\n\n-   il conna√Æt le meilleur plan physique fourni par Catalyst ;\n\n-   il conna√Æt les ressources disponibles et occup√©es par toutes les machines du cluster ;\n\n-   il affecte les ressources disponibles √† la session spark.\n\n## Le r√¥le du worker {.smaller}\n\n![](images/calcul_distribue.drawio.png){fig-align=\"center\"}\n\nLe worker effectue le morceau de programme qu'on lui affecte :\n\n-   il ne conna√Æt que les t√¢ches qu'on lui a affect√©es ;\n\n-   il peut communiquer avec le driver en r√©seau pour renvoyer un r√©sultat ;\n\n-   il peut communiquer avec les autres workers en r√©seau pour partager des donn√©es ou des r√©sultats interm√©diaires : c'est un shuffle.\n\n## La m√©moire du driver\n\n![](images/collect.drawio.png){fig-align=\"center\"}\n\n## L'utilisation de la m√©moire du driver {.smaller .scrollable}\n\nLorsqu'il est n√©cessaire de collecter une table volumineuse, il faut donc pr√©voir assez de m√©moire RAM pour le driver : tous les r√©sultats sont rappatri√©s vers le driver.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2\"}\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"20Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n::: callout-caution\n## Bonne pratique de partage des ressources\n\nLe driver est dans la bulle Midares, qui a vocation √† √™tre r√©duite suite √† la g√©n√©ralisation du cluster.\n\n-   La bulle Midares a besoin de RAM pour fonctionner, 100% des ressources ne sont donc pas disponibles pour `sparklyr`.\n\n-   Pour permettre le **travail simultan√© fluide de 10 utilisateurs**, la m√©moire allou√©e au driver recommand√©e pour chaque utilisateur est de **20 Go**.\n\n-   Il existe des alternatives pour ne pas collecter des r√©sultats trop volumineux dans le driver.\n:::\n\n## Programmer sans collecter {.smaller}\n\nLa programmation en spark doit √™tre adapt√©e aux contraintes de volum√©trie des donn√©es : test de chaque √©tape, puis ne forcer le calcul qu'√† la fin pour que Catalyst optimise l'ensemble du programme\n\nLa principale diff√©rence avec la programmation en R classique est que **la visualisation de tables compl√®tes volumineuses n'est pas toujours possible et n'est pas recommand√©e** :\n\n-   **goulets d'√©tranglement** m√™me avec spark, car toutes les donn√©es sont rapatri√©es vers le driver puis vers la session R : erreurs Out of Memory\n\n-   **longue :** √©change entre tous les noeuds impliqu√©s dans le calcul et le driver, puis un √©change driver-session R en r√©seau = lent ;\n\n-   **beaucoup moins efficace que l'export direct en parquet** du r√©sultat (qui fonctionne toujours) : charger ensuite sa table finale en data frame R classique pour effectuer l'√©tude.\n\nS'il est n√©cessaire de collecter, il faut pr√©voir **beaucoup de RAM pour le driver avec le param√®tre** `spark.driver.memory`, ce qui emp√™che les autres utilisateurs de travailler.\n\n## Programmer sans collecter {.smaller}\n\nLes r√©sultats qu'il est recommand√© de r√©cup√©rer en m√©moire vive en session R sont de la forme suivante :\n\n-   **une table filtr√©e** avec les variables n√©cessaires √† l'√©tude uniquement : sous MiDAS, toutes les jointures, les calculs de variable et les filtres peuvent √™tre effectu√©s de mani√®re efficiente sous la forme de spark_data_frame, sans jamais collecter les donn√©es MiDAS ;\n\n-   des **statistiques descriptives synth√©tiques ;**\n\n-   les **premi√®res lignes** de la table pour v√©rifier que le programme retourne bien le r√©sultat attendu ;\n\n-   une **table agr√©g√©e** pour un graphique par exemple, √† l'aide de la fonction `summarise()`.\n\n## Programmer sans collecter {.smaller}\n\nJe sais que la cr√©ation de ma table donne le r√©sultat souhait√©e (car j'ai regard√© ce dont elle a l'air avvec `head()`), maintenant je vais l'appeler une dizaine de fois pour collecter uniquement des statistiques descriptives.\n\nQue se passe-t-il √† chaque fois que je collecte une statistique descriptive ?\n\n. . .\n\nLa cr√©ation de la table va √™tre ex√©cut√©e √† nouveau : tr√®s long ?\n\nComment faire ?\n\n::: panel-tabset\n## Cache\n\nLa cr√©ation de la table est ex√©cut√©e une seule fois, le r√©sultat est conserv√© en m√©moire vive\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma_table_spark <- MMO_2017 %>%\n  filter(DebutCTT > as.Date(\"2017-06-01\")) %>%\n  mutate(duree_CTT = DATEDIFF(FinCTT,DebutCTT) + 1) %>%\n  sdf_register(name = \"ma_table_spark\")\n\ntbl_cache(\"ma_table_spark\")\n```\n:::\n\n\n## Persist\n\nLa cr√©ation de la table est ex√©cut√©e une seule fois, le r√©sultat est conserv√© sur le disque\n\n\n::: {.cell}\n\n```{.r .cell-code}\nma_table_spark <- MMO_2017 %>%\n  filter(DebutCTT > as.Date(\"2017-06-01\")) %>%\n  mutate(duree_CTT = DATEDIFF(FinCTT,DebutCTT) + 1) %>%\n  sdf_persist(storage.level = \"DISK_ONLY\")\n\ntbl_cache(\"ma_table_spark\")\n```\n:::\n\n:::\n\n::: notes\nR√©ponse attendue : c'est une action donc ca d√©clenche la cr√©ation de la table Indice : cr√©ation de table contient uniquement des transformations\n:::\n\n## Optimiser la m√©moire : conclusion\n\nPour programmer en spark sans aucune erreur :\n\n1.  D√©clencher une action avec plusieurs transformations pour laisser Catalyst optimiser\n\n2.  Ne pas collecter tout une table\n\n3.  Persister ou cacher une table qu'on va appeler plusieurs fois pour ne collecter que des statistiques descriptives\n\n4.  Ne pas persister trop de tables : occupe de la m√©moire RAM\n\n5.  Consulter le programme exemple sur la bulle CASD si besoin\n\n# Les bonnes pratiques\n\n## Mode local : sch√©ma {.smaller}\n\n![](images/mode_local.PNG)\n\n## Mode local : √† √©viter {.smaller}\n\nEn mode local :\n\n-   les ressources utilis√©es sont celles de la bulle uniquement : bloque les autres utilisateurs\n\n-   il faut allouer suffisamment de coeurs √† la JVM pour parall√©liser\n\n-   m√™me si l'utilisateur choisit des ressources faibles, les ressources r√©elles utilis√©es dans une session spark peuvent √™tre plus √©lev√©es : mauvaise gestion de l'allocation des ressources entre utilisateurs\n\n-   acc√©l√©ration sensible par rapport √† un mode de programmation classique s√©quentiel sur un unique coeur si beaucoup de ressources\n\n-   Sur la bulle CASD, mauvaise gestion de la r√©partition des ressources en spark local : l'utilisation simultan√©e de spark par plusieurs membres de la bulle entra√Ænent des ralentissements consid√©rables\n\n    ‚ñ∂Ô∏èmode local √† √©viter absolument\n\n## Traitement MAP distribu√©\n\n![](images/map_distribue.drawio.png){fig-align=\"center\"}\n\n## Traitement REDUCE distribu√©\n\n![](images/reduce_distribue.drawio.png){fig-align=\"center\"}\n\n## Inutile de prendre toutes les ressources {.smaller}\n\n![](images/reduce_distribue.drawio.png){fig-align=\"center\"}\n\nComme nous l'avons vu, les traitements REDUCE ne se pr√™tent pas tr√®s bien au calcul distribu√© :\n\n-   augmenter le nombre de workers augmente la probabilit√© de devoir effectuer des shuffles\n\n-   il est recommand√© de se limiter √† deux workers comme dans la configuration propos√©e\n\n-   r√©server d'autres ressources n'est souvent pas efficient et monopolise les ressources pour les autres utilisateurs.\n\n## Fermer sa session {.smaller}\n\n-   Une fois les ressources r√©serv√©es, tant que la session R est ouverte, les ressources restent r√©serv√©es √† l'utilisateur : personne ne peut les prendre\n\n-   Si on ne ferme pas sa session, on bloque les autres\n\n-   Si une session reste ouverte trop longtemps et bloque les autres, le CASD pourra la ferme √† distance : bien enregistrer ses r√©sultats avant de partir !\n\n## Mutualiser les exp√©riences {.smaller}\n\n-   Sessions de passage d'un code sur le cluster\n\n-   Contributions √† la documentation MiDAS\n\n-   Appeler un coll√®gue si erreur en sparklyr\n\n# Pour aller plus loin\n\n## Partitionnement\n\nLe format `.parquet` (avec `arrow`) et le framework `spark` permettent de g√©rer le partitionnement des donn√©es.\n\nSi les op√©rations sont souvent effectu√©es par r√©gions par exemple, il est utile de forcer le stockage des donn√©es d'une m√™me r√©gion au m√™me endroit physique et acc√©l√®re drastiquement le temps de calcul :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_write_parquet(ma_table, \"hdfs:///resultats/ma_table.parquet\", partition_by = c(\"region\"))\n```\n:::\n\n\n## SparkUI  {.smaller .scrollable}\n\nSpark UI permet de consulter le plan logique et physique du traitement demand√©. Trois outils permettent d'optimiser les traitements :\n\n::: panel-tabset\n## DAG\n\n![](images/dag.webp)\n\n## GC\n\nV√©rifier que le `gc time` est inf√©rieur √† 10% du temps pour ex√©cuter la t√¢che ‚úÖ\n\n![](images/gc.png)\n\n## M√©moire\n\nV√©rifier que la `storage memory` ne sature pas la m√©moire ‚úÖ\n\n![](images/gc.png)\n:::\n\n## Yarn {.smaller .scrollable}\n\n-   **yarn** : disponibilit√© des ressources\n\n    ![](images/yarn_scheduler.PNG)\n\n-   **Sparkhistory** pour des traitements de sessions ferm√©es\n\nLe sparkhistory entra√Æne l'enregistrement de logs assez lourdes, il est donc d√©sactiv√© par d√©faut. Pour l'activer sur un programme :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf <- spark_config()\nconf[\"spark.eventLog.enabled\"] <- \"true\"\nconf[\"spark.eventLog.dir\"] <- \"hdfs://midares-deb11-nn-01.midares.local:9000/spark-logs\"\nconf[\"appName\"] <- \"un_nom_de_traitement\"\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n## Pyspark\n\n![](images/pyspark.drawio.png){fig-align=\"center\"}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}