{
  "hash": "754169f27ca3151678ed19791a5de0b2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Initiation √† Spark avec R en mode cluster\"\nformat: \n  revealjs:\n    incremental: true\n    slide-numbers : true\n---\n\n\n## Au programme {.smaller}\n\n1.  MiDAS : une base de donn√©es volumineuse üíæ\n\n2.  Manipuler un appariement : une op√©ration co√ªteuse üí≤\n\n3.  Initiation au calcul distribu√© : quelles ressources r√©server ? üñ•Ô∏èüñ•Ô∏èüñ•Ô∏è\n\n4.  Sparklyr : la solution ergonomique de spark sous R üë®‚Äçüíª\n\n5.  Pour aller plus loin ‚è©\n\n## MiDAS : une base de donn√©es volumineuse {.smaller}\n\nMiDAS croise trois bases de donn√©es administratives exhaustives :\n\n-   les donn√©es sur **l'inscription et l'indemnisation des demandeurs d'emploi** de France Travail : le Fichier Historique Statistique (FHS) et le Fichier National des Allocataires (FNA) ;\n\n-   les donn√©es sur les b√©n√©ficiaires de **minima sociaux** (RSA, PPA, AAH) et les caract√©ristiques des **m√©nages** de la CNAF : Allstat-FR6 ;\n\n-   les donn√©es sur les **contrats salari√©s** de la DSN : MMO de la Dares.\n\n## MiDAS : une base de donn√©es volumineuse {.smaller}\n\nChaque vague de MiDAS correspond √† environ **600 Go** de donn√©es au format sas. Les vagues fonctionnent par empilement :\n\n-   le gain de **profondeur temporelle** et l'entr√©e dans le champ de nouvelles personnes\n\n-   les **vagues sont appariables entre elles**\n\n## MiDAS : une base de donn√©es volumineuse {.smaller}\n\nMiDAS est l'une des bases de donn√©es les plus volumineuses du SSP :![Quelques bases du SSP](donnees_ssp.PNG)\n\nLes administrations dont les donn√©es sont comparables √† MiDAS utilisent un cluster Spark : Insee, Drees, Acoss...\n\n‚ñ∂Ô∏èLe cluster spark est la solution la plus efficiente pour traiter des donn√©es de cette ampleur. Apprendre √† l'utiliser pourra vous √™tre utile dans d'autres contextes que celui de la Dares.\n\n## Structure de l'appariement {.smaller}\n\n![](structure_midas.PNG){fig-align=\"center\"}\n\n::: callout-tip\n## Pourquoi Spark ?\n\nLa manipulation des donn√©es MiDAS en l'√©tat implique de nombreuses op√©rations de jointures qui n√©cessitent une puissance de calcul et un temps certains.\n:::\n\n## Le format parquet {.smaller .scrollable}\n\nLes donn√©es sont converties au **format parquet** d√®s leur r√©ception et mises √† disposition sur la bulle CASD du projet MiDares sous l'espace commun. Le format parquet est un format de donn√©es adapt√© aux donn√©es volumineuses :\n\n-   il **compresse** efficacement les donn√©es : taux de compression de 5 √† 10 par rapport au format csv\n\n-   il est orient√© **colonnes**\n\n-   il permet le chargement efficace **en m√©moire** des donn√©es\n\n-   Il permet le **stockage partitionn√©** des donn√©es\n\n-   il permet un traitement de cette partition qui conserve les donn√©es non n√©cessaires **sur disque**\n\n-   Il est **ind√©pendant du logiciel** utilis√© : il peut donc √™tre trait√© par spark et par R.\n\n# Manipuler un appariement : une op√©ration co√ªteuse\n\n## L'espace MiDares {.smaller .scrollable}\n\n::: panel-tabset\n### Ressources\n\nDes ressources partag√©es entre tous les utilsateurs simultan√©s :\n\n-   512 Go de m√©moire vive (ou RAM) : passage √† 256 Go\n\n::: callout-note\n## La m√©moire vive\n\nLa m√©moire vive, aussi appel√©e RAM, se distingue de la m√©moire de stockage (disque) par sa **rapidit√©**, notamment pour fournir des donn√©es au processeur pour effectuer des calculs, par sa **volatilit√©** (toutes les donn√©es sont perdues si l'ordinateur n'est plus aliment√©) et par l'acc√®s direct aux informations qui y sont stock√©es, **quasi instantann√©**.\n:::\n\n-   Un processeur (ou CPU) compos√© de 32 coeurs : passage √† 16 coeurs\n\n::: callout-note\n## Le processeur\n\nLe processeur permet d'**ex√©cuter des t√¢ches et des programmes** : convertir un fichier, ex√©cuter un logiciel... Il est compos√© d'un ou de plusieurs **coeurs** : un coeur ne peut ex√©cuter qu'une seule t√¢che √† la fois. Si le processeur contient plusieurs coeurs, il peut ex√©cuter autant de t√¢ches en parall√®le qu'il a de coeurs. Un processeur se caract√©rise aussi par sa **fr√©quence** : elle est globalement proportionnelle au nombre d'op√©rations qu'il est capable d'effetuer par seconde.\n:::\n\n### Sch√©ma\n\n![](schema_ordinateur.png)\n:::\n\n## Programmer en m√©moire vive {.smaller}\n\n-   **R : la m√©moire vive, √©tat dans l'environnement**\n\n-   SAS : lecture/√©criture sur le disque\n\n-   MiDAS au format sas \\>\\> taille de la m√©moire vive disponible du serveur CASD --\\> format `.parquet`\n\n-   **Impossible de charger tout MiDAS en m√©moire vive**\n\n    Des solutions existent pour manipuler les donn√©es sous R sans les charger enti√®rement en m√©moire vive :\n\n-   `arrow` (avec des requ√™tes `dplyr`)\n\n-   `duckDB` : recommand√© par le SSPLab pour des donn√©es jusqu'√† 100Go\n\n    ‚ñ∂Ô∏è Insuffisantes pour les traitements les plus co√ªteux sur MiDAS en R : la partie de la m√©moire vive utilis√©e pour stocker les donn√©es correspond √† autant de puissance de calcul indisponible pour les traitements.\n\n## Les traitements co√ªteux en puissance de calcul {.smaller}\n\n-   les jointures\n\n-   les op√©rations en `group_by()`\n\n-   `distinct()`\n\n    ‚ñ∂Ô∏è Ex√©cution s√©quentielle sur un coeur du processeur + beaucoup de m√©moire vive (donn√©es temporaires)\n\n    ‚ñ∂Ô∏è Erreur \"out of memory\".\n\n## Un traitement peu co√ªteux {.smaller}\n\n![](formation%20sparklyr-Page-1.drawio.png){fig-align=\"center\" width=\"800\"}\n\nCe traitement est peu co√ªteux :\n\n-   chargement d'une seule colonne en RAM : format parquet orient√© colonnes\n\n-   peu de m√©moire d'ex√©cution : R est un langage vectoris√©\n\n## Un traitement co√ªteux {.smaller}\n\n![](formation%20sparklyr-Page-2.drawio.png){fig-align=\"center\" width=\"850\"}\n\nCe traitement n√©cessite :\n\n-   le chargement de davantage de colonnes en m√©moire vive ;\n\n-   davantage de m√©moire d'ex√©cution pour effectuer l'intersection (`inner_join()`).\n\n# Initiation au calcul distribu√©\n\n## Calcul distribu√© et calcul parall√®le {.smaller}\n\n::: panel-tabset\n### Calcul non distribu√©\n\nLorsqu'un traitement Big Data est demand√© par l'utilisateur dans la session R, plusieurs probl√®mes peuvent se poser :\n\n-   la taille des donn√©es : charg√©es en m√©moire pour effectuer les calculs avec R\n\n-   le temps de calcul : si plusieurs √©tapes sont n√©cessaires pour un traitement, elles sont effectu√©es de mani√®re s√©quentielle par le processeur (tr√®s long)\n\n-   l'optimisation du programme\n\n### Calcul distribu√© avec spark\n\nLe calcul distribu√© avec spark apporte une solution √† ces probl√©matiques :\n\n-   chargement des donn√©es en m√©moire parcimonieux et non syst√©matique\n\n-   ex√©cution de t√¢ches en parall√®le sur plusieurs coeurs du processeur, voire sur plusieurs ordinateurs diff√©rents\n\n-   optimisation automatique du code\n:::\n\n## Le cluster de calcul Midares : mode interactif {.smaller}\n\n![](schema_cluster.drawio.png){fig-align=\"center\" width=\"691\"}\n\n## Spark {.smaller .scrollable}\n\n-   Apache Spark : **librairie open source** d√©velopp√©e dans le langage `scala`\n\n-   **Scala** : langage compil√©, rapide et distribuable qui peut √™tre ex√©cut√© dans une machine virtuelle Java\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    val TopHorrorsIGN2022 = Seq(\n      (9, \"Pearl\"),\n      (6, \"The Sadness\"),\n      (6, \"Offseason\"),\n      (7, \"Hatching\"),\n      (8, \"x\")\n    ).toDF(\"IMDB Rating\", \"IGN Movie Picks\")\n    \n    val TopHorrorsTheAVClub2022 = Seq(\n      (7, \"Nope\"),\n      (9, \"Pearl\"),\n      (8, \"x\"),\n      (5, \"Barbarian\"),\n      (5, \"Bones And All\")\n    ).toDF(\"IMDB Rating\", \"AVC Movie Picks\")\n    \n    import org.apache.spark.sql.functions.col\n    \n    val cols = List(col(\"IGN Movie Picks\"), col(\"AVC Movie Picks\"))\n    \n    val query = TopHorrorsIGN2022(\n      \"IGN Movie Picks\"\n    ) === TopHorrorsTheAVClub2022(\"AVC Movie Picks\")\n    \n    val outerJoin = TopHorrorsIGN2022\n      .join(TopHorrorsTheAVClub2022, query, \"outer\")\n      .select(cols: _*)\n    \n    outerJoin.show()\n    ```\n    :::\n\n\n-   `scala` adapt√© pour ma√Ætriser toutes les fonctionnalit√©s de `spark` et optimiser au maximum les traitements en `spark`\n\n-   `spark` est **compatible avec les langages** `scala`, `R`, `python`, `java`, et peut interpr√©ter des commandes **SQL.**\n\n-   Deux packages existent sous R :\n\n    -   **sparkR** propos√© par Apache Spark\n\n    -   **sparklyr**, qui permet d'utiliser directement des commandes dplyr traduites en spark par le package.\n\n## Mode local : concurrence {.smaller}\n\n![](mode_local.PNG)\n\n## Mode local : concurrence {.smaller}\n\nEn mode local :\n\n-   une unique machine Java\n\n-   parall√©lisation des t√¢ches sur diff√©rents coeurs de cette machine virtuelle\n\n-   pas de stockage distribu√©, ca n'est pas du calcul distribu√© √† proprement parler\n\n-   acc√©l√©ration par rapport √† un mode de programmation classique s√©quentiel sur un unique coeur si beaucoup de ressources\n\n-   Sur la bulle CASD, mauvaise gestion de la r√©partition des ressources en spark local\n\n    ‚ñ∂Ô∏èmode local √† √©viter absolument\n\n## Mode cluster : non concurrence {.smaller}\n\n![](mode_cluster.PNG)\n\nLe mode cluster permet une r√©elle distribution sur diff√©rents noeuds, qui sont en fait des ordinateurs distincts d'un serveur. Ces machines communiquent en r√©seau.\n\n## Installation de spark sous CASD\n\nVoir la fiche d√©di√©e sur le site\n\n## Sparklyr et SparkR {.smaller}\n\nDeux packages permettent de programmer avec Spark sous R :\n\n-   **SparkR :** ce package, maintenu par Apache Spark, permet d'utiliser une syntaxe proche de `spark`, `scala`, ou directement du code `SQL` pour manipuler des donn√©es dans une session R.\n\n-   **Sparklyr :** ce package permet d'utiliser directement la syntaxe `dplyr` dans une session Spark sous R.\n\n**Sparklyr** fonctionne selon ces √©tapes :\n\n1.  La **JVM driver spark est instanci√©e dans la bulle Midares** pour utiliser `sparklyr`.\n\n2.  Les instructions `dplyr` appel√©es sur un `spark_data_frame` sont **traduites par les fonctions du package** `sparklyr` **en** `scala`, puis envoy√©es au driver.\n\n3.  Le programme en `scala` est ex√©cut√© sur le **cluster**.\n\n4.  Si une **erreur** est renvoy√©e par le driver, elle est interpr√©t√©e par R avant d'√™tre affich√©e en session R.\n\n## Sparklyr mode cluster\n\n![](schema_cluster.drawio.png){fig-align=\"center\" width=\"691\"}\n\n## Configuration cluster {.smaller .scrollable}\n\nDeux √©tapes majeures dans le traitement de donn√©es sous R diff√®re en sparklyr par rapport √† une programmation classique en `dplyr` :\n\n::: panel-tabset\n### Configuration\n\nIl est n√©cessaire de configurer la session spark pour √©tablir une connexion entre la session R et un cluster spark. Les param√®tres √† d√©finir sont :\n\n-   Les ressources physiques utilis√©es :\n\n    1.  par le **driver** : avec `spark.driver.memory` **(avec parcimonie)**\n\n    2.  par chaque **worker** avec `spark.executor.memory`(valeur max **140 Go**) et `spark.executor.cores` (valeur max **8 coeurs**)\n\n    3.  le nombre de **workers** avec `spark.executor.instances` **(2 ou 3 suffisent)**\n\n    4.  La **file** sur laquelle on travaille avec `spark.yarn.queue` **(prod ou dev)**\n\n-   le nombre de **partitions** de chaque `spark_data_frame` avec `spark.sql.shuffle.partitions` **(200 par d√©faut)**\n\n-   la **limite de taille des r√©sulats** qui peuvent √™tre **collect√©s** par le driver avec `spark.driver.maxResultSize` **(0 est la meilleure option)**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n### Import-export\n\nLes donn√©es doivent √™tre disponibles dans les workers sous forme de `spark_data_frame` :\n\n-   **cach√© en m√©moire directement** : si utilis√©es plusieurs fois pour gagner du temps\n\n-   laiss√© sur disque tant qu'aucune action ne d√©clenche un traitement qui n√©cessite son chargement en m√©moire\n\n    ‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : avec la configuration pr√©sent√©e, le chargement du FNA, du FHS et des MMO prend au moins 25 minutes.\n\n-   Pour passer un `data.frame` R en spark_data_frame : `copy_to()`\n\n\n::: {.cell}\n\n:::\n\n:::\n\n## Configuration des ressources cluster\n\n![](mode_cluster.PNG)\n\n## L'utilisation de la m√©moire dans un worker {.smaller .scrollable}\n\n::: columns\n::: {.column width=\"50%\"}\n![](memoire_worker_1.drawio.png)\n:::\n\n::: {.column width=\"50%\"}\n![](memoire_worker_2.drawio.png)\n:::\n:::\n\n::: callout-tip\nNe pas charger plusieurs fois les m√™mes donn√©es en cache, ou si besoin augmenter la part de la m√©moire allou√©e au stockage avec `spark.memory.storageFraction`.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"4\"}\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.memory.fraction\"] <- 0.8\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"5\"}\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.memory.fraction\"] <- 0.8\nconf[\"spark.memory.storageFraction\"] <- 0.4\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n## Le stockage distribu√© : HDFS {.smaller .scrollable}\n\n-   **stockage sur diff√©rentes machines :** ici les noeuds du cluster spark, c'est-√†-dire les diff√©rents ordinateurs workers du cluster\n\n-   donn√©es divis√©es **en blocs** plus petits de taille fixe et r√©partis sur les machines\n\n-   chaque bloc est **r√©pliqu√© trois fois** pour √™tre r√©silient face aux pannes\n\n-   un **NameNode** supervise les **m√©tadonn√©es** et g√®re la structure du syst√®me de fichiers\n\n-   les **DataNodes** stockent effectivement les blocs de donn√©es\n\n-   le **syst√®me HDFS** est reli√© √† la bulle Midares : possible de charger des donn√©es en clique-bouton de la bulle vers HDFS de mani√®re tr√®s rapide et de t√©l√©charger des tables de HDFS pour les r√©cup√©rer en local\n\n    ::: callout-caution\n    ## Les exports sur HDFS\n\n    Lorsqu'on exporte une table depuis notre session R vers HDFS, celle-ci est **automatiquement partitionn√©e**, comme le reste des donn√©es.\n\n    Ainsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.\n\n    Il est possible de ma√Ætriser le nombre de partitions avec la commande `sdf_coalesce(partitions = 5)` du package `sparklyr`.\n\n    L'id√©al est d'**adapter le nombre de partitions √† la taille d'un bloc** : un bloc mesure 128 MB. Lorsqu'un bloc disque est utilis√©, m√™me √† 1%, il n'est pas utilisable pour un autre stockage.\n\n    Exporter un fichier de 1MB en 200 partitions r√©serve 200 blocs inutilement.\n    :::\n\n## Le stockage distribu√© : HDFS {.smaller .scrollable}\n\n![](stockage_distribue.drawio.png){fig-align=\"center\" width=\"2000\"}\n\n‚ñ∂Ô∏è Les r√©plications de donn√©es ont deux fonctions :\n\n-   augementer la **flexibilit√© de la distribution** des traitements\n\n-   augmenter la **r√©silience** en cas de panne d'un noeud\n\n## La lazy evaluation {.smaller .scrollable}\n\nSpark distingue deux types d'op√©rations :\n\n-   **les transformations :** ce sont des op√©rations qui prennent en entr√©e un `spark_data_frame` et retournent un `spark_data_frame`, elles ne d√©clenchent aucun calcul lorsqu'elles sont appel√©es.\n\n    Par exemple, le programme ci-dessous est compil√© instantan√©ment et ne d√©clenche pas d'ex√©cution :\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    une_transformation <- un_spark_data_frame %>%\n      group_by(identifiant) %>%\n      mutate(une_somme = sum(revenus))\n    ```\n    :::\n\n\n-   **les actions :** ce sont des op√©rations qui demandent le calcul d'un r√©sultat et qui d√©clenchent le calcul et l'ex√©cution de toutes les transformations compil√©es jusqu'√† l'appel de l'action.\n\n    Par exemple, le programme ci-dessous d√©clenche le calcul de la cellule `une_transformation` et de la moyenne des revenus :\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    revenu_moyen <- une_transformation %>%\n      summarise(revenu_moyen = mean(une_somme)) %>%\n      print()\n    ```\n    :::\n\n\n    Les principales actions sont : `print()`, `collect()`, `head()`, `tbl_cache()` (√©crire un `spark_data_frame` en m√©moire pour le r√©utiliser).\n\n## La lazy evaluation {.smaller .scrollable}\n\nSpark optimise automatiquement les programmes soumis :\n\n1.  Compilation des transformations\n\n2.  Int√©gration dans un **plan d'ex√©cution** : √©ventuelles erreurs du programme soulev√©es avant l'ex√©cution\n\n3.  Optimisation du plan logique par le module **Catalyst** (driver Spark)\n\n    Par exemple si j'√©cris le programme :\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    non_optimal <- table_1 %>%\n      mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%\n      filter(debut_contrat >= as.Date(\"2023-01-01\"))\n    ```\n    :::\n\n\n    Catalyst r√©√©crit :\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    non_optimal <- table_1 %>%\n      filter(debut_contrat >= as.Date(\"2023-01-01\")) %>%\n      mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))\n    ```\n    :::\n\n\n    Cette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu'une action d√©clenche l'ex√©cution.\n\n4.  R√©alisation de plans physiques possibles et s√©lection du **meilleur plan physique** (au regard de la localisation des donn√©es requises).\n\n5.  **D√©clencher le moins d'actions possibles** dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.\n\n6.  Pour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique.\n\n## Le plan d'ex√©cution {.smaller}\n\n![](catalyst.jpg)\n\nsource : documentation CASD disponible √† [Documentation Data Science](https://casd-eu.gitbook.io/data-science/)\n\n## R√©cup√©rer un r√©sultat {.smaller}\n\nLes r√©sultats qu'il est recommand√© de r√©cup√©rer en m√©moire vive en session R sont de la forme suivante :\n\n-   **une table filtr√©e** avec les variables n√©cessaires √† l'√©tude uniquement : sous MiDAS, toutes les jointures, les calculs de variable et les filtres peuvent √™tre effectu√©s de mani√®re efficiente sous la forme de spark_data_frame, sans jamais collecter les donn√©es MiDAS ;\n\n-   des **statistiques descriptives synth√©tiques ;**\n\n-   les **premi√®res lignes** de la table pour v√©rifier que le programme retourne bien le r√©sultat attendu ;\n\n-   une **table agr√©g√©e** pour un graphique par exemple, √† l'aide de la fonction `summarise()`.\n\n## L'utilisation de la m√©moire du driver {.smaller}\n\n![](collect.drawio.png)\n\n## L'utilisation de la m√©moire du driver {.smaller .scrollable}\n\nLorsqu'il est n√©cessaire de collecter une table volumineuse, il faut donc pr√©voir assez de m√©moire RAM pour le driver.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2\"}\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n```\n:::\n\n\n::: callout-caution\n## Bonne pratique de partage des ressources\n\nLe driver est instanci√© dans la bulle Midares, qui a vocation √† √™tre r√©duite suite √† la g√©n√©ralisation du cluster.\n\n-   La bulle Midares a besoin de RAM minimale pour fonctionner, 100% des ressources ne sont donc pas disponibles pour `sparklyr`.\n\n-   Pour permettre le **travail simultan√© fluide de 10 utilisateurs**, la m√©moire allou√©e au driver recommand√©e pour chaque utilisateur est de **15 Go**.\n\n-   L'export d'une table `sdf` directement au format `.parquet` est une alternative plus rapide, plus efficiente et qui permet par la suite de charger ses donn√©es en R classique et de travailler sur un `df` R sans utiliser `sparklyr`.\n:::\n\n## Comment tester son code pour collecter le moins possible ? {.smaller .scrollable}\n\nLa programmation en spark doit √™tre adapt√©e aux contraintes de volum√©trie des donn√©es : test de chaque √©tape, puis ne forcer le calcul qu'√† la fin pour que Catalyst optimise l'ensemble du programme\n\nLa principale diff√©rence avec la programmation en R classique est que **la visualisation de tables compl√®tes volumineuses n'est pas recommand√©e** :\n\n-   **goulets d'√©tranglement** m√™me avec spark, car toutes les donn√©es sont rapatri√©es vers le driver puis vers la session R ;\n\n-   **longue :** √©change entre tous les noeuds impliqu√©s dans le calcul et le driver, puis un √©change driver-session R ;\n\n-   **beaucoup moins efficace que l'export direct en parquet** du r√©sultat (presque instantann√©) : charger ensuite sa table finale en data frame R classique pour effectuer l'√©tude.\n\nS'il est n√©cessaire de collecter, il faut pr√©voir **beaucoup de RAM pour le driver avec le param√®tre** `spark.driver.memory`**.**\n\n# Sparklyr : la solution ergonomique de spark sous R\n\n## Ce qui change pour l'utilisateur {.smaller}\n\nLa majorit√© des commandes `dplyr` fonctionnent sur un spark_data_frame avec le package `sparklyr`. Les divergences sont les suivantes :\n\n-   pour effectuer des op√©rations avec les dates, il faut utiliser les fonctions Hive sp√©cifiques.\n\n-   `arrange()` ne fonctionne pas sur un spark_data_frame, il faut lui substituer `window_order()`.\n\n-   des fonctions sp√©cifiques aux spark data frames : `sdf_bind_rows()` pour empiler les lignes par exemple.\n\n## Quelques fonctions sp√©cifiques {.smaller .scrollable}\n\n::: panel-tabset\n## Dates\n\nLes fonctions de `lubridate()`ne sont pas adapt√©es au `spark_data_frames`.\n\n-   Convertir une cha√Æne de caract√®re de la forme AAAA-MM-DD en Date\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    date_1 <- as.Date(\"2024-05-26\")\n    ```\n    :::\n\n\n-   Calculer une dur√©e entre deux dates\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    PJC_spark <- spark_read_parquet(sc,\n                                    path = \"hdfs:///dataset/MiDAS_v4/pjc.parquet\",\n                                    memory = FALSE)\n    \n    duree_pjc_df <- PJC_spark %>%\n      rename(date_fin_pjc = as.Date(KDFPJ),\n             date_deb_pjc = as.Date(KDDPJ)) %>%\n      mutate(duree_pjc = datediff(date_fin_pjc, date_deb_pjc) + 1) %>%\n      head(5)\n    ```\n    :::\n\n\n-   Ajouter ou soustraire des jours ou des mois √† une date\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    duree_pjc_bis_df <- duree_pjc_df %>%\n      mutate(duree_pjc_plus_5 = date_add(duree_pjc, int(5)),\n             duree_pjc_moins_5 = date_sub(duree_pjc, int(5)),\n             duree_pjc_plus_1_mois = add_months(duree_pjc, int(1))) %>%\n      head(5)\n    ```\n    :::\n\n\n::: callout-note\n## Add_months\n\nSi la date en entr√©e est le dernier jour d'un mois, la date retourn√©e avec `add_months(date_entree, int(1))` sera le dernier jour calendaire du mois suivant.\n:::\n\n::: callout-tip\n## Format\n\nLe `int()` est important car ces fonctions Hive n'accepte que les entiers pour l'ajout de jours : taper uniquement 5 est consid√©r√© comme un flottant dans R.\n:::\n\n## Tableau\n\n-   Tri dans un groupe pour effectuer un calcul s√©quentiel\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_spark <- spark_read_parquet(sc,\n                                    path = \"hdfs:///dataset/MiDAS_v4/odd.parquet\",\n                                    memory = FALSE)\n    \n    ODD_premier <- ODD_spark %>%\n      group_by(id_midas) %>%\n      window_order(id_midas, KDPOD) %>%\n      mutate(date_premier_droit = first(KDPOD)) %>%\n      ungroup() %>%\n      distinct(id_midas, KROD3, date_premier_droit) %>%\n      head(5)\n    ```\n    :::\n\n\n-   Tri pour une sortie : `sdf_sort()` , `arrange()` ne fonctionne pas\n\n-   Concat√©ner les lignes (ou les colonnes `sdf_bind_cols()`)\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_1 <- ODD_spark %>%\n      filter(KDPOD <= as.Date(\"2017-12-31\")) %>%\n      mutate(groupe = \"temoins\")\n    \n    ODD_2 <- ODD_spark %>%\n      filter(KDPOD >= as.Date(\"2021-12-31\")) %>%\n      mutate(groupe = \"traites\")\n    \n    ODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)\n    ```\n    :::\n\n\n-   D√©doublonner une table\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    droits_dans_PJC <- PJC_spark %>%\n      sdf_distinct(id_midas, KROD3)\n    \n    print(head(droits_dans_PJC, 5))\n    \n    PJC_dedoublonnee <- PJC_spark %>%\n      sdf_drop_duplicates()\n    \n    print(head(PJC_dedoublonnee, 5))\n    ```\n    :::\n\n\n-   Pivot : les fonctions du packag `tidyr` ne fonctionnent pas sur donn√©es spark\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_sjr_moyen <- ODD_spark %>%\n      mutate(groupe = ifelse(KDPOD <= as.Date(\"2020-12-31\"), \"controles\", \"traites\")) %>%\n      sdf_pivot(groupe ~ KCRGC,\n        fun.aggregate = list(KQCSJP = \"mean\")\n      )\n    ```\n    :::\n\n\n## Statistiques\n\n-   R√©sum√© statistique : `sdf_describe()` , `summary()`ne fonctionne pas.\n\n-   Dimension : `sdf_dim`, la fonction `nrow()`ne fonctionne pas.\n\n-   Quantiles approximatifs : le calcul des quantiles sur donn√©es distirbu√©es renvoie une approximation car toutes les donn√©es ne peuvent pas √™tre rappatri√©es sur la m√™me machine physique du fait de la volum√©trie, `sdf_quantile()`\n\n-   Echantillonnage al√©atoire : `sdf_random_split`\n:::\n\n## Quelques tips d'optimisation {.smaller .scrollable}\n\n::: panel-tabset\n### Jointures\n\nPour effectuer ce type de jointure avec deux tables de volum√©tries diff√©rentes : A est petite, B est tr√®s volumineuse\n\n![](join.png)\n\nSolution rapide :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable_finale <- table_volumineuse_comme_PJC %>%\n  right_join(petite_table_mon_champ)\n```\n:::\n\n\nSolution lente :\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable_finale <- petite_table_mon_champ %>%\n  left_join(table_volumineuse_comme_PJC)\n```\n:::\n\n\n### Persist\n\nLorsqu'une table interm√©diaire est utilis√©e plusieurs fois dans un traitement, il est possible de la persister, c'est-√†-dire enregistrer ce `spark_data_frame`sur le disque ou dans la m√©moire des noeuds.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable_1 <- mon_champ %>%\n  left_join(ODD, by = c(\"id_midas\", \"KROD3\")) %>%\n  rename(duree_potentielle_indemnisation = KPJDXP,\n         SJR = KQCSJP,\n         date_debut_indemnisation = KDPOD) %>%\n  sdf_persist()\n\nduree <- table_1 %>%\n  summarise(duree_moy = mean(duree_potentielle_indemnisation),\n            duree_med = median(duree_potentielle_indemnisation)) %>%\n  collect()\n\nSJR <- table_1 %>%\n  summarise(SJR_moy = mean(SJR),\n            SJR_med = median(SJR)) %>%\n  collect()\n```\n:::\n\n\n### Chargement\n\nLorsqu'on charge des donn√©es dans le cluster Spark et que la table est appel√©e plusieurs fois dans le programme, il est conseill√© de la charger en m√©moire vive directement.\n\nAttention, si beaucoup de tables volumineuses sont charg√©es en m√©moire, la fraction de la m√©moire spark d√©di√©e au stockage peut √™tre insuffisante ou bien il peut ne pas rester assez de spark memory pour l'ex√©cution.\n\n### Export et partitions\n\nLe format `.parquet` (avec `arrow`) et le framework `spark` permettent de g√©rer le partitionnement des donn√©es.\n\nSi les op√©rations sont souvent effectu√©es par r√©gions par exemple, il est utile de forcer le stockage des donn√©es d'une m√™me r√©gion au m√™me endroit physique et acc√©l√®re drastiquement le temps de calcul\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspark_write_parquet(DE, partition_by = c(\"REGIND\"))\n```\n:::\n\n\n::: callout-warning\n## Exports simultan√©s\n\nHDFS supporte les exports simultan√©s, mais le temp d'export est plus long lorsque le NameNode est requ√™t√© par plusieurs personnes simultan√©ment : d'apr√®s les tests cluster\n\n-   pour un petit export (5 minutes), le temps peut √™tre multipli√© par 4 ;\n\n-   pour un gros export (15 minutes), le temps peut √™tre multipli√© par 2.\n:::\n:::\n\n## Forcer le calcul {.smaller}\n\nQuelques actions :\n\n-   collecter la table enti√®re üõë\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    spark_data_frame_1 %>%\n      collect()\n    ```\n    :::\n\n\n-   afficher les premi√®res lignes\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    spark_data_frame_1 %>%\n      head(10)\n    ```\n    :::\n\n\n-   Mettre les donner en cache\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    spark_data_frame_1 %>%\n      sdf_register() %>%\n      tbl_cache()\n    \n    sc %>% spark_session() %>% invoke(\"catalog\") %>% \n      invoke(\"clearCache\")\n    ```\n    :::\n\n\n## Les erreurs en sparklyr {.smaller}\n\n`sparklyr` traduit le code `dplyr` fourni en `scala`, mais interpr√®te √©galement les messages d'erreurs envoy√©s du cluster vers la session R.\n\n`sparklyr` n'est cependant pas performant pour interpr√©ter ces erreurs.\n\nN'h√©sitez pas √† enregistrer le code g√©n√©rant un message d'erreur dans Documents publics/erreurs_sparklyr\n\nUn test du code pas-√†-pas permet d'isoler le probl√®me.\n\n## Bonnes pratiques {.smaller}\n\n-   D√©connexion ou fermeture R pour lib√©rer les ressources üõë\n\n-   Ne plus utiliser spark en local üñ•Ô∏èüñ•Ô∏èüñ•Ô∏è\n\n-   Pyspark ou Sparklyr pour la production ‚ùì\n\n-   Utilisation parcimonieuse des ressources ‚öñÔ∏è\n\n-   Envoi des erreurs sparklyr üì©\n\n# Pour aller plus loin\n\n## L'architecture Map Reduce\n\n![](map_reduce.png)\n\n## La gestion de la m√©moire avec spark {.smaller .scrollable}\n\nLes **shuffles** sont les op√©rations les plus gourmandes en temps.\n\n::: callout-note\n## Qu'est-ce qu'un shuffle ?\n\nUn shuffle est un **√©change de donn√©es entre diff√©rents noeuds** du cluster.\n\nNous avons vu qu'utiliser `spark`dans un cluster implique de distribuer √©galement le stockage des donn√©es.\n\nPar exemple :\n\n1.  je demande un traitement sur la table PJC du FNA\n\n2.  si un noeud contenant d√©j√† les donn√©es de PJC est disponible, le cluster manager envoie le traitement √† ce noeud\n\n3.  si tous les noeuds contenant les donn√©es de PJC sont d√©j√† r√©serv√©s, alors le cluster manager demande le traitement √† un autre noeud, par exemple le noeud 1\n\n4.  il demande √† un noeud contenant les donn√©es PJC, par exemple le noeud 4, d'envoyer ces donn√©es au noeud 1 qui va ex√©cuter le traitement\n\n5.  cet √©change de donn√©es est en r√©seau filaire : un √©change filaire est beaucoup plus lent qu'un envoi interne par le disque du noeud 1 √† la RAM du noeud 1\n\n6.  c'est pourquoi pour optimiser un programme spark, il est possible de limiter les shuffles\n:::\n\n## SparkUI : un outil d'optimisation {.smaller .scrollable}\n\nSpark UI permet de consulter le plan logique et physique du traitement demand√©. Trois outils permettent d'optimiser les traitements :\n\n::: panel-tabset\n## DAG\n\n![](dag.webp)\n\n## GC\n\nV√©rifier que le `gc time` est inf√©rieur √† 10% du temps pour ex√©cuter la t√¢che ‚úÖ\n\n![](gc.png)\n\n## M√©moire\n\nV√©rifier que la `storage memory` ne sature pas la m√©moire ‚úÖ\n\n![](gc.png)\n:::\n\n## Utiliser les interfaces {.smaller}\n\n-   **yarn** : disponibilit√© des ressources\n\n    ![](yarn_scheduler.png){width=\"600\"}\n\n-   **Sparkhistory** pour des traitements de sessions ferm√©es\n\n## Ma session ne s'instancie jamais {.smaller}\n\nSi l'instruction `sc <- spark_connect(master = \"yarn\", config = conf` prend plus de 10 minutes, il est utile d'ouvrir l'interface de yarn pour v√©rifier que la file n'est pas d√©j√† enti√®rement occup√©e. L'erreur peut ne survenir qu'au bout d'une vingtaine de minutes : le job est `ACCEPTED` dans yarn, ou `FAILED` si la session n'a pas pu √™tre instanci√©e par manque de ressources disponibles.\n\n![](yarn_accepted.jpg)\n\n## Exporter de HDFS au local {.smaller}\n\n::: r-stack\n![](hdfs_browse.png){.fragment width=\"1000\" height=\"700\"}\n\n![](hdfs_download.png){.fragment width=\"1000\" height=\"700\"}\n:::\n\n## Pyspark : mode cluster\n\n![](pyspark.drawio.png)\n\n## Les avantages de pyspark {.smaller}\n\n-   Mode cluster : une machine du cluster peut prendre le r√¥le de driver üñ•Ô∏è\n\n-   Spark context dans le cluster : fermer sa session anaconda ne stoppe pas le traitement ‚ôæÔ∏è\n\n-   Plusieurs sessions simultan√©es üë©‚Äçüíªüë©‚Äçüíªüë©‚Äçüíª\n\n-   Stabilit√© : compatibilit√© assur√©e avec Apache Spark, probl√©matique de production üîÑ\n\n-   Lisibilit√© du code üëì\n\n-   Temps de connexion et d'ex√©cution r√©duit ‚è≤Ô∏è\n\n-   Utilisation optimale de SparkUI üìä\n\n## Merci pour votre attention !\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}