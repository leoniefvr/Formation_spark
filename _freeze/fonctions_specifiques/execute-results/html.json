{
  "hash": "e3704428d4830c9b5d69756bb3588c3d",
  "result": {
    "markdown": "---\ntitle: \"Fonctions spécifiques\"\n---\n\n\nLa majorité des commandes `dplyr` fonctionnent sur un spark_data_frame avec le package `sparklyr`. Les divergences principales sont les suivantes :\n\n| Fonctionnalité                 | tidyverse      | sparklyr                         |\n|--------------------------------|----------------|----------------------------------|\n| import d'un fichier `.parquet` | `read_parquet` | `spark_read_parquet()`           |\n| tri d'un tableau               | `arrange()`    | `window_order()` ou `sdf_sort()` |\n| opérations sur les dates       | `lubridate`    | fonctions Hive                   |\n| empiler des tableaux           | `bind_rows()`  | `sdf_bind_rows()`                |\n| nombre de lignes d'un tableau  | `nrow()`       | `sdf_nrow()`                     |\n| faire pivoter un tableau       | `tidyr`        | `sdf_pivot()`                    |\n| export d'un `spark_data_frame` |                | `spark_write_parquet()`          |\n\n## Tableau\n\n-   Tri dans un groupe pour effectuer un calcul séquentiel\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_spark <- spark_read_parquet(sc,\n                                    path = \"hdfs:///dataset/MiDAS_v4/odd.parquet\",\n                                    memory = FALSE)\n    \n    ODD_premier <- ODD_spark %>%\n      group_by(id_midas) %>%\n      window_order(id_midas, KDPOD) %>%\n      mutate(date_premier_droit = first(KDPOD)) %>%\n      ungroup() %>%\n      distinct(id_midas, KROD3, date_premier_droit) %>%\n      head(5)\n    ```\n    :::\n\n\n-   Tri pour une sortie : `sdf_sort()` , `arrange()` ne fonctionne pas\n\n-   Concaténer les lignes (ou les colonnes `sdf_bind_cols()`)\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_1 <- ODD_spark %>%\n      filter(KDPOD <= as.Date(\"2017-12-31\")) %>%\n      mutate(groupe = \"temoins\")\n    \n    ODD_2 <- ODD_spark %>%\n      filter(KDPOD >= as.Date(\"2021-12-31\")) %>%\n      mutate(groupe = \"traites\")\n    \n    ODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)\n    ```\n    :::\n\n\n-   Dédoublonner une table\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    droits_dans_PJC <- PJC_spark %>%\n      sdf_distinct(id_midas, KROD3)\n    \n    print(head(droits_dans_PJC, 5))\n    \n    PJC_dedoublonnee <- PJC_spark %>%\n      sdf_drop_duplicates()\n    \n    print(head(PJC_dedoublonnee, 5))\n    ```\n    :::\n\n\n-   Pivot : les fonctions du packag `tidyr` ne fonctionnent pas sur données spark\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ODD_sjr_moyen <- ODD_spark %>%\n      mutate(groupe = ifelse(KDPOD <= as.Date(\"2020-12-31\"), \"controles\", \"traites\")) %>%\n      sdf_pivot(groupe ~ KCRGC,\n        fun.aggregate = list(KQCSJP = \"mean\")\n      )\n    ```\n    :::\n\n\n## Statistiques\n\n-   Résumé statistique : `sdf_describe()` , `summary()`ne fonctionne pas.\n\n-   Dimension : `sdf_dim`, la fonction `nrow()`ne fonctionne pas.\n\n-   Quantiles approximatifs : le calcul des quantiles sur données distirbuées renvoie une approximation car toutes les données ne peuvent pas être rappatriées sur la même machine physique du fait de la volumétrie, `sdf_quantile()`\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}