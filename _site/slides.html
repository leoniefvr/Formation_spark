<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Formation sparklyr - Initiation à Spark avec R en mode cluster</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Initiation à Spark avec R en mode cluster</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Formation sparklyr</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Introduction</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./slides_v.html" class="sidebar-item-text sidebar-link">Slides</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./configuration.html" class="sidebar-item-text sidebar-link">Configuration</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fonctions_specifiques.html" class="sidebar-item-text sidebar-link">Fonctions spécifiques à sparklyr</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dates.html" class="sidebar-item-text sidebar-link">Les dates avec sparklyr</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./oom.html" class="sidebar-item-text sidebar-link">Out of memory : help !</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./errors.html" class="sidebar-item-text sidebar-link">Guide des erreurs</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bonnes_pratiques.html" class="sidebar-item-text sidebar-link">Bonnes pratiques</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ressources.html" class="sidebar-item-text sidebar-link">Ressources</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#au-programme" id="toc-au-programme" class="nav-link active" data-scroll-target="#au-programme">Au programme</a></li>
  <li><a href="#midas-une-base-de-données-volumineuse" id="toc-midas-une-base-de-données-volumineuse" class="nav-link" data-scroll-target="#midas-une-base-de-données-volumineuse">MiDAS : une base de données volumineuse</a></li>
  <li><a href="#midas-une-base-de-données-volumineuse-1" id="toc-midas-une-base-de-données-volumineuse-1" class="nav-link" data-scroll-target="#midas-une-base-de-données-volumineuse-1">MiDAS : une base de données volumineuse</a></li>
  <li><a href="#midas-une-base-de-données-volumineuse-2" id="toc-midas-une-base-de-données-volumineuse-2" class="nav-link" data-scroll-target="#midas-une-base-de-données-volumineuse-2">MiDAS : une base de données volumineuse</a></li>
  <li><a href="#structure-de-lappariement" id="toc-structure-de-lappariement" class="nav-link" data-scroll-target="#structure-de-lappariement">Structure de l’appariement</a></li>
  <li><a href="#le-format-parquet" id="toc-le-format-parquet" class="nav-link" data-scroll-target="#le-format-parquet">Le format parquet</a></li>
  <li><a href="#manipuler-un-appariement-une-opération-coûteuse" id="toc-manipuler-un-appariement-une-opération-coûteuse" class="nav-link" data-scroll-target="#manipuler-un-appariement-une-opération-coûteuse">Manipuler un appariement : une opération coûteuse</a>
  <ul class="collapse">
  <li><a href="#lespace-midares" id="toc-lespace-midares" class="nav-link" data-scroll-target="#lespace-midares">L’espace MiDares</a></li>
  <li><a href="#programmer-en-mémoire-vive" id="toc-programmer-en-mémoire-vive" class="nav-link" data-scroll-target="#programmer-en-mémoire-vive">Programmer en mémoire vive</a></li>
  <li><a href="#les-traitements-coûteux-en-puissance-de-calcul" id="toc-les-traitements-coûteux-en-puissance-de-calcul" class="nav-link" data-scroll-target="#les-traitements-coûteux-en-puissance-de-calcul">Les traitements coûteux en puissance de calcul</a></li>
  <li><a href="#un-traitement-peu-coûteux-un-traitement-map" id="toc-un-traitement-peu-coûteux-un-traitement-map" class="nav-link" data-scroll-target="#un-traitement-peu-coûteux-un-traitement-map">Un traitement peu coûteux : un traitement MAP</a></li>
  <li><a href="#un-traitement-coûteux-un-traitement-reduce" id="toc-un-traitement-coûteux-un-traitement-reduce" class="nav-link" data-scroll-target="#un-traitement-coûteux-un-traitement-reduce">Un traitement coûteux : un traitement REDUCE</a></li>
  </ul></li>
  <li><a href="#initiation-au-calcul-distribué" id="toc-initiation-au-calcul-distribué" class="nav-link" data-scroll-target="#initiation-au-calcul-distribué">Initiation au calcul distribué</a>
  <ul class="collapse">
  <li><a href="#calcul-distribué-et-calcul-parallèle" id="toc-calcul-distribué-et-calcul-parallèle" class="nav-link" data-scroll-target="#calcul-distribué-et-calcul-parallèle">Calcul distribué et calcul parallèle</a></li>
  <li><a href="#un-traitement-map-distribué" id="toc-un-traitement-map-distribué" class="nav-link" data-scroll-target="#un-traitement-map-distribué">Un traitement MAP distribué</a></li>
  <li><a href="#un-traitement-reduce-distribué" id="toc-un-traitement-reduce-distribué" class="nav-link" data-scroll-target="#un-traitement-reduce-distribué">Un traitement REDUCE distribué</a></li>
  <li><a href="#spark" id="toc-spark" class="nav-link" data-scroll-target="#spark">Spark</a></li>
  <li><a href="#installation-de-spark-sous-casd" id="toc-installation-de-spark-sous-casd" class="nav-link" data-scroll-target="#installation-de-spark-sous-casd">Installation de spark sous CASD</a></li>
  <li><a href="#la-machine-virtuelle-java" id="toc-la-machine-virtuelle-java" class="nav-link" data-scroll-target="#la-machine-virtuelle-java">La machine virtuelle Java</a></li>
  <li><a href="#deux-manières-dutiliser-spark" id="toc-deux-manières-dutiliser-spark" class="nav-link" data-scroll-target="#deux-manières-dutiliser-spark">Deux manières d’utiliser Spark</a></li>
  <li><a href="#mode-local-schéma" id="toc-mode-local-schéma" class="nav-link" data-scroll-target="#mode-local-schéma">Mode local : schéma</a></li>
  <li><a href="#mode-local-à-éviter" id="toc-mode-local-à-éviter" class="nav-link" data-scroll-target="#mode-local-à-éviter">Mode local : à éviter</a></li>
  <li><a href="#le-cluster-de-calcul-midares-présentation" id="toc-le-cluster-de-calcul-midares-présentation" class="nav-link" data-scroll-target="#le-cluster-de-calcul-midares-présentation">Le cluster de calcul Midares : présentation</a></li>
  <li><a href="#se-connecter-à-spark-sur-un-cluster" id="toc-se-connecter-à-spark-sur-un-cluster" class="nav-link" data-scroll-target="#se-connecter-à-spark-sur-un-cluster">Se connecter à Spark sur un cluster</a></li>
  <li><a href="#une-connexion" id="toc-une-connexion" class="nav-link" data-scroll-target="#une-connexion">Une connexion</a></li>
  <li><a href="#la-vie-dun-programme-rédigé-en-sparklyr" id="toc-la-vie-dun-programme-rédigé-en-sparklyr" class="nav-link" data-scroll-target="#la-vie-dun-programme-rédigé-en-sparklyr">La vie d’un programme rédigé en sparklyr</a></li>
  <li><a href="#la-lazy-evaluation" id="toc-la-lazy-evaluation" class="nav-link" data-scroll-target="#la-lazy-evaluation">La lazy evaluation</a></li>
  <li><a href="#la-vie-dun-programme-rédigé-en-sparklyr-1" id="toc-la-vie-dun-programme-rédigé-en-sparklyr-1" class="nav-link" data-scroll-target="#la-vie-dun-programme-rédigé-en-sparklyr-1">La vie d’un programme rédigé en sparklyr</a></li>
  <li><a href="#le-rôle-du-driver" id="toc-le-rôle-du-driver" class="nav-link" data-scroll-target="#le-rôle-du-driver">Le rôle du driver</a></li>
  <li><a href="#le-plan-dexécution" id="toc-le-plan-dexécution" class="nav-link" data-scroll-target="#le-plan-dexécution">Le plan d’exécution</a></li>
  <li><a href="#le-rôle-du-driver-catalyst" id="toc-le-rôle-du-driver-catalyst" class="nav-link" data-scroll-target="#le-rôle-du-driver-catalyst">Le rôle du driver : Catalyst</a></li>
  <li><a href="#le-rôle-du-driver-catalyst-1" id="toc-le-rôle-du-driver-catalyst-1" class="nav-link" data-scroll-target="#le-rôle-du-driver-catalyst-1">Le rôle du driver : Catalyst</a></li>
  <li><a href="#le-rôle-du-driver-catalyst-2" id="toc-le-rôle-du-driver-catalyst-2" class="nav-link" data-scroll-target="#le-rôle-du-driver-catalyst-2">Le rôle du driver : Catalyst</a></li>
  <li><a href="#le-rôle-du-cluster-manager" id="toc-le-rôle-du-cluster-manager" class="nav-link" data-scroll-target="#le-rôle-du-cluster-manager">Le rôle du cluster manager</a></li>
  <li><a href="#le-rôle-du-worker" id="toc-le-rôle-du-worker" class="nav-link" data-scroll-target="#le-rôle-du-worker">Le rôle du worker</a></li>
  <li><a href="#où-sont-les-données" id="toc-où-sont-les-données" class="nav-link" data-scroll-target="#où-sont-les-données">Où sont les données ?</a></li>
  <li><a href="#où-sont-les-données-1" id="toc-où-sont-les-données-1" class="nav-link" data-scroll-target="#où-sont-les-données-1">Où sont les données ?</a></li>
  <li><a href="#transfert-de-la-bulle-à-hdfs" id="toc-transfert-de-la-bulle-à-hdfs" class="nav-link" data-scroll-target="#transfert-de-la-bulle-à-hdfs">Transfert de la bulle à HDFS</a></li>
  <li><a href="#transfert-de-hdfs-à-la-bulle" id="toc-transfert-de-hdfs-à-la-bulle" class="nav-link" data-scroll-target="#transfert-de-hdfs-à-la-bulle">Transfert de HDFS à la bulle</a></li>
  <li><a href="#mais-où-sont-réellement-les-données-hdfs" id="toc-mais-où-sont-réellement-les-données-hdfs" class="nav-link" data-scroll-target="#mais-où-sont-réellement-les-données-hdfs">Mais où sont réellement les données ? HDFS</a></li>
  </ul></li>
  <li><a href="#programmer-avec-sparklyr" id="toc-programmer-avec-sparklyr" class="nav-link" data-scroll-target="#programmer-avec-sparklyr">Programmer avec sparklyr</a>
  <ul class="collapse">
  <li><a href="#paramétrer-sa-session" id="toc-paramétrer-sa-session" class="nav-link" data-scroll-target="#paramétrer-sa-session">Paramétrer sa session</a></li>
  <li><a href="#mode-cluster-non-concurrence-grâce-au-cluster-manager" id="toc-mode-cluster-non-concurrence-grâce-au-cluster-manager" class="nav-link" data-scroll-target="#mode-cluster-non-concurrence-grâce-au-cluster-manager">Mode cluster : non concurrence grâce au cluster manager</a></li>
  <li><a href="#importer-les-données-depuis-hdfs-sous-r" id="toc-importer-les-données-depuis-hdfs-sous-r" class="nav-link" data-scroll-target="#importer-les-données-depuis-hdfs-sous-r">Importer les données depuis HDFS sous R</a></li>
  <li><a href="#les-exports-sur-hdfs" id="toc-les-exports-sur-hdfs" class="nav-link" data-scroll-target="#les-exports-sur-hdfs">Les exports sur HDFS</a></li>
  <li><a href="#les-shuffles" id="toc-les-shuffles" class="nav-link" data-scroll-target="#les-shuffles">Les shuffles</a></li>
  <li><a href="#récupérer-un-résultat" id="toc-récupérer-un-résultat" class="nav-link" data-scroll-target="#récupérer-un-résultat">Récupérer un résultat</a></li>
  <li><a href="#lutilisation-de-la-mémoire-du-driver" id="toc-lutilisation-de-la-mémoire-du-driver" class="nav-link" data-scroll-target="#lutilisation-de-la-mémoire-du-driver">L’utilisation de la mémoire du driver</a></li>
  <li><a href="#lutilisation-de-la-mémoire-du-driver-1" id="toc-lutilisation-de-la-mémoire-du-driver-1" class="nav-link" data-scroll-target="#lutilisation-de-la-mémoire-du-driver-1">L’utilisation de la mémoire du driver</a></li>
  <li><a href="#comment-tester-son-code-pour-collecter-le-moins-possible" id="toc-comment-tester-son-code-pour-collecter-le-moins-possible" class="nav-link" data-scroll-target="#comment-tester-son-code-pour-collecter-le-moins-possible">Comment tester son code pour collecter le moins possible ?</a></li>
  </ul></li>
  <li><a href="#sparklyr-la-solution-ergonomique-de-spark-sous-r" id="toc-sparklyr-la-solution-ergonomique-de-spark-sous-r" class="nav-link" data-scroll-target="#sparklyr-la-solution-ergonomique-de-spark-sous-r">Sparklyr : la solution ergonomique de spark sous R</a>
  <ul class="collapse">
  <li><a href="#ce-qui-change-pour-lutilisateur" id="toc-ce-qui-change-pour-lutilisateur" class="nav-link" data-scroll-target="#ce-qui-change-pour-lutilisateur">Ce qui change pour l’utilisateur</a></li>
  <li><a href="#quelques-fonctions-spécifiques" id="toc-quelques-fonctions-spécifiques" class="nav-link" data-scroll-target="#quelques-fonctions-spécifiques">Quelques fonctions spécifiques</a></li>
  <li><a href="#quelques-tips-doptimisation" id="toc-quelques-tips-doptimisation" class="nav-link" data-scroll-target="#quelques-tips-doptimisation">Quelques tips d’optimisation</a></li>
  <li><a href="#forcer-le-calcul" id="toc-forcer-le-calcul" class="nav-link" data-scroll-target="#forcer-le-calcul">Forcer le calcul</a></li>
  <li><a href="#les-erreurs-en-sparklyr" id="toc-les-erreurs-en-sparklyr" class="nav-link" data-scroll-target="#les-erreurs-en-sparklyr">Les erreurs en sparklyr</a></li>
  <li><a href="#bonnes-pratiques" id="toc-bonnes-pratiques" class="nav-link" data-scroll-target="#bonnes-pratiques">Bonnes pratiques</a></li>
  </ul></li>
  <li><a href="#pour-aller-plus-loin" id="toc-pour-aller-plus-loin" class="nav-link" data-scroll-target="#pour-aller-plus-loin">Pour aller plus loin</a>
  <ul class="collapse">
  <li><a href="#larchitecture-map-reduce" id="toc-larchitecture-map-reduce" class="nav-link" data-scroll-target="#larchitecture-map-reduce">L’architecture Map Reduce</a></li>
  <li><a href="#la-gestion-de-la-mémoire-avec-spark" id="toc-la-gestion-de-la-mémoire-avec-spark" class="nav-link" data-scroll-target="#la-gestion-de-la-mémoire-avec-spark">La gestion de la mémoire avec spark</a></li>
  <li><a href="#lutilisation-de-la-mémoire-dans-un-worker" id="toc-lutilisation-de-la-mémoire-dans-un-worker" class="nav-link" data-scroll-target="#lutilisation-de-la-mémoire-dans-un-worker">L’utilisation de la mémoire dans un worker</a></li>
  <li><a href="#sparkui-un-outil-doptimisation" id="toc-sparkui-un-outil-doptimisation" class="nav-link" data-scroll-target="#sparkui-un-outil-doptimisation">SparkUI : un outil d’optimisation</a></li>
  <li><a href="#utiliser-les-interfaces" id="toc-utiliser-les-interfaces" class="nav-link" data-scroll-target="#utiliser-les-interfaces">Utiliser les interfaces</a></li>
  <li><a href="#ma-session-ne-sinstancie-jamais" id="toc-ma-session-ne-sinstancie-jamais" class="nav-link" data-scroll-target="#ma-session-ne-sinstancie-jamais">Ma session ne s’instancie jamais</a></li>
  <li><a href="#exporter-de-hdfs-au-local" id="toc-exporter-de-hdfs-au-local" class="nav-link" data-scroll-target="#exporter-de-hdfs-au-local">Exporter de HDFS au local</a></li>
  <li><a href="#pyspark-mode-cluster" id="toc-pyspark-mode-cluster" class="nav-link" data-scroll-target="#pyspark-mode-cluster">Pyspark : mode cluster</a></li>
  <li><a href="#les-avantages-de-pyspark" id="toc-les-avantages-de-pyspark" class="nav-link" data-scroll-target="#les-avantages-de-pyspark">Les avantages de pyspark</a></li>
  <li><a href="#merci-pour-votre-attention" id="toc-merci-pour-votre-attention" class="nav-link" data-scroll-target="#merci-pour-votre-attention">Merci pour votre attention !</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Initiation à Spark avec R en mode cluster</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="au-programme" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="au-programme">Au programme</h2>
<ol type="1">
<li><p>MiDAS : une base de données volumineuse 💾</p></li>
<li><p>Manipuler un appariement : une opération coûteuse 💲</p></li>
<li><p>Initiation au calcul distribué : quelles ressources réserver ? 🖥️🖥️🖥️</p></li>
<li><p>Sparklyr : la solution ergonomique de spark sous R 👨‍💻</p></li>
<li><p>Pour aller plus loin ⏩</p></li>
</ol>
</section>
<section id="midas-une-base-de-données-volumineuse" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="midas-une-base-de-données-volumineuse">MiDAS : une base de données volumineuse</h2>
<p>MiDAS croise trois bases de données administratives exhaustives :</p>
<ul>
<li><p>les données sur <strong>l’inscription et l’indemnisation des demandeurs d’emploi</strong> de France Travail : le Fichier Historique Statistique (FHS) et le Fichier National des Allocataires (FNA) ;</p></li>
<li><p>les données sur les bénéficiaires de <strong>minima sociaux</strong> (RSA, PPA, AAH) et les caractéristiques des <strong>ménages</strong> de la CNAF : Allstat-FR6 ;</p></li>
<li><p>les données sur les <strong>contrats salariés</strong> de la DSN : MMO de la Dares.</p></li>
</ul>
</section>
<section id="midas-une-base-de-données-volumineuse-1" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="midas-une-base-de-données-volumineuse-1">MiDAS : une base de données volumineuse</h2>
<p>Chaque vague de MiDAS correspond à environ <strong>600 Go</strong> de données au format sas. Les vagues fonctionnent par empilement :</p>
<ul>
<li><p>le gain de <strong>profondeur temporelle</strong> et l’entrée dans le champ de nouvelles personnes</p></li>
<li><p>les <strong>vagues sont appariables entre elles</strong></p></li>
</ul>
</section>
<section id="midas-une-base-de-données-volumineuse-2" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="midas-une-base-de-données-volumineuse-2">MiDAS : une base de données volumineuse</h2>
<p>MiDAS est l’une des bases de données les plus volumineuses du SSP :<img src="donnees_ssp.PNG" class="img-fluid" alt="Quelques bases du SSP"></p>
<p>Les administrations dont les données sont comparables à MiDAS utilisent un cluster Spark : Insee, Drees, Acoss…</p>
<p>▶️Le cluster spark est la solution la plus efficiente pour traiter des données de cette ampleur. Apprendre à l’utiliser pourra vous être utile dans d’autres contextes que celui de la Dares.</p>
</section>
<section id="structure-de-lappariement" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="structure-de-lappariement">Structure de l’appariement</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="structure_midas.PNG" class="img-fluid figure-img"></p>
</figure>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Pourquoi Spark ?
</div>
</div>
<div class="callout-body-container callout-body">
<p>La manipulation des données MiDAS en l’état implique de nombreuses opérations de jointures qui nécessitent une puissance de calcul et un temps certains.</p>
</div>
</div>
</section>
<section id="le-format-parquet" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="le-format-parquet">Le format parquet</h2>
<p>Les données sont converties au <strong>format parquet</strong> dès leur réception et mises à disposition sur la bulle CASD du projet MiDares sous l’espace commun. Le format parquet est un format de données adapté aux données volumineuses :</p>
<ul>
<li><p>il <strong>compresse</strong> efficacement les données : taux de compression de 5 à 10 par rapport au format csv</p></li>
<li><p>il est orienté <strong>colonnes</strong></p></li>
<li><p>il permet le chargement efficace <strong>en mémoire</strong> des données</p></li>
<li><p>Il permet le <strong>stockage partitionné</strong> des données</p></li>
<li><p>il permet un traitement de cette partition qui conserve les données non nécessaires <strong>sur disque</strong></p></li>
<li><p>Il est <strong>indépendant du logiciel</strong> utilisé : il peut donc être traité par spark et par R.</p></li>
</ul>
</section>
<section id="manipuler-un-appariement-une-opération-coûteuse" class="level1">
<h1>Manipuler un appariement : une opération coûteuse</h1>
<section id="lespace-midares" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="lespace-midares">L’espace MiDares</h2>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Ressources</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Schéma</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>Des ressources partagées entre tous les utilsateurs simultanés :</p>
<ul>
<li>512 Go de mémoire vive (ou RAM) : passage à 256 Go</li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
La mémoire vive
</div>
</div>
<div class="callout-body-container callout-body">
<p>La mémoire vive, aussi appelée RAM, se distingue de la mémoire de stockage (disque) par sa <strong>rapidité</strong>, notamment pour fournir des données au processeur pour effectuer des calculs, par sa <strong>volatilité</strong> (toutes les données sont perdues si l’ordinateur n’est plus alimenté) et par l’accès direct aux informations qui y sont stockées, <strong>quasi instantanné</strong>.</p>
</div>
</div>
<ul>
<li>Un processeur (ou CPU) composé de 32 coeurs : passage à 16 coeurs</li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Le processeur
</div>
</div>
<div class="callout-body-container callout-body">
<p>Le processeur permet d’<strong>exécuter des tâches et des programmes</strong> : convertir un fichier, exécuter un logiciel… Il est composé d’un ou de plusieurs <strong>coeurs</strong> : un coeur ne peut exécuter qu’une seule tâche à la fois. Si le processeur contient plusieurs coeurs, il peut exécuter autant de tâches en parallèle qu’il a de coeurs. Un processeur se caractérise aussi par sa <strong>fréquence</strong> : elle est globalement proportionnelle au nombre d’opérations qu’il est capable d’effetuer par seconde.</p>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p><img src="schema_ordinateur.png" class="img-fluid"></p>
</div>
</div>
</div>
</section>
<section id="programmer-en-mémoire-vive" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="programmer-en-mémoire-vive">Programmer en mémoire vive</h2>
<ul>
<li><p><strong>R : la mémoire vive, état dans l’environnement</strong></p></li>
<li><p>SAS : lecture/écriture sur le disque</p></li>
<li><p>MiDAS au format sas &gt;&gt; taille de la mémoire vive disponible du serveur CASD –&gt; format <code>.parquet</code></p></li>
<li><p><strong>Impossible de charger tout MiDAS en mémoire vive</strong></p>
<p>Des solutions existent pour manipuler les données sous R sans les charger entièrement en mémoire vive :</p></li>
<li><p><code>arrow</code> (avec des requêtes <code>dplyr</code>)</p></li>
<li><p><code>duckDB</code> : recommandé par le SSPLab pour des données jusqu’à 100Go</p>
<p>▶️ Insuffisantes pour les traitements les plus coûteux sur MiDAS en R : la partie de la mémoire vive utilisée pour stocker les données correspond à autant de puissance de calcul indisponible pour les traitements.</p></li>
</ul>
</section>
<section id="les-traitements-coûteux-en-puissance-de-calcul" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="les-traitements-coûteux-en-puissance-de-calcul">Les traitements coûteux en puissance de calcul</h2>
<ul>
<li><p>les jointures</p></li>
<li><p>les opérations en <code>group_by()</code></p></li>
<li><p><code>distinct()</code></p>
<p>▶️ Exécution séquentielle sur un coeur du processeur + beaucoup de mémoire vive (données temporaires)</p>
<p>▶️ Erreur “out of memory”.</p></li>
</ul>
</section>
<section id="un-traitement-peu-coûteux-un-traitement-map" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="un-traitement-peu-coûteux-un-traitement-map">Un traitement peu coûteux : un traitement MAP</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="formation sparklyr-Page-1.drawio.png" class="img-fluid figure-img" width="800"></p>
</figure>
</div>
<p>Ce traitement est peu coûteux :</p>
<ul>
<li><p>chargement d’une seule colonne en RAM : format parquet orienté colonnes</p></li>
<li><p>peu de mémoire d’exécution : R est un langage vectorisé</p></li>
</ul>
</section>
<section id="un-traitement-coûteux-un-traitement-reduce" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="un-traitement-coûteux-un-traitement-reduce">Un traitement coûteux : un traitement REDUCE</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="formation sparklyr-Page-2.drawio.png" class="img-fluid figure-img" width="850"></p>
</figure>
</div>
<p>Ce traitement nécessite :</p>
<ul>
<li><p>le chargement de davantage de colonnes en mémoire vive ;</p></li>
<li><p>davantage de mémoire d’exécution pour effectuer l’intersection (<code>inner_join()</code>).</p></li>
</ul>
</section>
</section>
<section id="initiation-au-calcul-distribué" class="level1">
<h1>Initiation au calcul distribué</h1>
<section id="calcul-distribué-et-calcul-parallèle" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="calcul-distribué-et-calcul-parallèle">Calcul distribué et calcul parallèle</h2>
<div class="columns">
<div class="column" style="width:50%;">
<section id="calcul-non-distribué" class="level3">
<h3 class="anchored" data-anchor-id="calcul-non-distribué">Calcul non distribué</h3>
<p>Les problématiques Big Data en R sont les suivantes :</p>
<ul>
<li><p>la taille des données : chargées en mémoire pour effectuer les calculs avec R</p></li>
<li><p>le temps de calcul : les étapes du traitement sont effectuées de manière séquentielle par le processeur (très long)</p></li>
<li><p>l’optimisation du programme</p></li>
</ul>
</section>
</div><div class="column" style="width:50%;">
<section id="calcul-distribué-spark" class="level3">
<h3 class="anchored" data-anchor-id="calcul-distribué-spark">Calcul distribué spark</h3>
<p>Le calcul distribué avec spark apporte une solution à ces problématiques :</p>
<ul>
<li><p>chargement des données en mémoire parcimonieux et non systématique</p></li>
<li><p>exécution de tâches en parallèle sur plusieurs coeurs du processeur, voire sur plusieurs ordinateurs différents</p></li>
<li><p>optimisation automatique du code</p></li>
</ul>
</section>
</div>
</div>
</section>
<section id="un-traitement-map-distribué" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="un-traitement-map-distribué">Un traitement MAP distribué</h2>
<p><img src="map_distribue.drawio.png" class="img-fluid"></p>
<p>Si les données sont stockées sur différents ordinateurs :</p>
<ul>
<li><p>les calculs peuvent être effectués en parallèle ;</p></li>
<li><p>gain de temps lié à l’augmentation des ressources informatiques pour effectuer le calcul et à la parallélisation.</p></li>
</ul>
<p>Les traitements MAP se prêtent parfaitement au calcul distribué et parallèle.</p>
</section>
<section id="un-traitement-reduce-distribué" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="un-traitement-reduce-distribué">Un traitement REDUCE distribué</h2>
<p><img src="reduce_distribue.drawio.png" class="img-fluid"></p>
<p>Si les données sont stockées sur différents ordinateurs :</p>
<ul>
<li><p>il faut les rappatrier au même endroit pour effectuer la jointure ;</p></li>
<li><p>cet échange est effectué en réseau entre les ordinateurs : l’envoi réseau a un coût non négligeable en temps.</p></li>
</ul>
<p>Les traitements REDUCE ne se prêtent pas bien au calcul distribué et parallèle.</p>
</section>
<section id="spark" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="spark">Spark</h2>
<ul>
<li><p>Apache Spark : <strong>librairie open source</strong> développée dans le langage <code>scala</code></p></li>
<li><p><strong>Scala</strong> : langage compilé, rapide et distribuable qui peut être exécuté dans une machine virtuelle Java</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>val TopHorrorsIGN2022 <span class="ot">=</span> <span class="fu">Seq</span>(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">9</span>, <span class="st">"Pearl"</span>),</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">6</span>, <span class="st">"The Sadness"</span>),</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">6</span>, <span class="st">"Offseason"</span>),</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">7</span>, <span class="st">"Hatching"</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">8</span>, <span class="st">"x"</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>)<span class="fu">.toDF</span>(<span class="st">"IMDB Rating"</span>, <span class="st">"IGN Movie Picks"</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>val TopHorrorsTheAVClub2022 <span class="ot">=</span> <span class="fu">Seq</span>(</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">7</span>, <span class="st">"Nope"</span>),</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">9</span>, <span class="st">"Pearl"</span>),</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">8</span>, <span class="st">"x"</span>),</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">5</span>, <span class="st">"Barbarian"</span>),</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  (<span class="dv">5</span>, <span class="st">"Bones And All"</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>)<span class="fu">.toDF</span>(<span class="st">"IMDB Rating"</span>, <span class="st">"AVC Movie Picks"</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>import org.apache.spark.sql.functions.col</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>val cols <span class="ot">=</span> <span class="fu">List</span>(<span class="fu">col</span>(<span class="st">"IGN Movie Picks"</span>), <span class="fu">col</span>(<span class="st">"AVC Movie Picks"</span>))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>val query <span class="ot">=</span> <span class="fu">TopHorrorsIGN2022</span>(</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="st">"IGN Movie Picks"</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>) <span class="sc">==</span><span class="er">=</span> <span class="fu">TopHorrorsTheAVClub2022</span>(<span class="st">"AVC Movie Picks"</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>val outerJoin <span class="ot">=</span> TopHorrorsIGN2022</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">.join</span>(TopHorrorsTheAVClub2022, query, <span class="st">"outer"</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">.select</span>(cols<span class="sc">:</span> _<span class="sc">*</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="fu">outerJoin.show</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
<li><p><code>scala</code> adapté pour maîtriser toutes les fonctionnalités de <code>spark</code> et optimiser au maximum les traitements en <code>spark</code></p></li>
<li><p><code>spark</code> est <strong>compatible avec les langages</strong> <code>scala</code>, <code>R</code>, <code>python</code>, <code>java</code>, et peut interpréter des commandes <strong>SQL.</strong></p></li>
<li><p>Deux packages existent sous R :</p>
<ul>
<li><p><strong>sparkR</strong> proposé par Apache Spark</p></li>
<li><p><strong>sparklyr</strong>, qui permet d’utiliser directement des commandes dplyr traduites en spark par le package.</p></li>
</ul></li>
</ul>
</section>
<section id="installation-de-spark-sous-casd" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="installation-de-spark-sous-casd">Installation de spark sous CASD</h2>
<p>Voir la fiche dédiée sur le site</p>
</section>
<section id="la-machine-virtuelle-java" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="la-machine-virtuelle-java">La machine virtuelle Java</h2>
<p>Spark est rédigé en scala, un langage qui a besoin d’une machine virtuelle Java pour être exécuté. La machine virtuelle Java est scalable : l’utilisateur peut choisir quelles ressources physiques elle a le droit d’utiliser sur l’ensemble des ressources physiques disponibles sur l’ordinateur. C’est un mini ordinateur créé par spark à l’intérieur de notre propre ordinateur, qui utilise les ressources de ce dernier.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Machine virtuelle
</div>
</div>
<div class="callout-body-container callout-body">
<p>Une machine virtuelle a les mêmes caractéristiques qu’un ordinateur :</p>
<ul>
<li><p>un système d’exploitation : Windows, Linux, MacOS</p></li>
<li><p>des ressources physiques : CPU, RAM et stockage disque</p></li>
</ul>
<p>La différence avec un ordinateur : une machine virtuelle peut être créée sur un serveur physique en réservant une petite partie des ressources du serveur seulement, ce qui permet de créer plusieurs ordinateurs différents sur une seule infractructure physique</p>
</div>
</div>
</section>
<section id="deux-manières-dutiliser-spark" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="deux-manières-dutiliser-spark">Deux manières d’utiliser Spark</h2>
<div class="columns">
<div class="column" style="width:50%;">
<section id="avec-un-seul-ordinateur" class="level3">
<h3 class="anchored" data-anchor-id="avec-un-seul-ordinateur">Avec un seul ordinateur</h3>
<p>Ce mode est appelé Spark local.</p>
<ul>
<li><p>une unique machine virtuelle Java est créée pour exécuter le code spark</p></li>
<li><p>tâches parallélisées sur les différents coeurs (CPU) du processeur de la machine virtuelle Java</p></li>
<li><p>l’ordinateur sur lequel est créée cette machine virtuelle Java est la bulle MiDARES, équivalent d’un unique gros ordinateur</p></li>
</ul>
</section>
</div><div class="column" style="width:50%;">
<section id="sur-un-cluster-de-calcul" class="level3">
<h3 class="anchored" data-anchor-id="sur-un-cluster-de-calcul">Sur un cluster de calcul</h3>
<p>Un cluster de calcul est un ensemble d’ordinateurs ou machines virtuelles connectés en réseau.</p>
<ul>
<li><p>une machine virtuelle Java est créée par spark dans chaque ordinateur du cluster</p></li>
<li><p>tâches parallélisées sur les différents ordinateurs du cluster</p></li>
<li><p>la session R reste sur la bulle MiDARES, le code R est traduit en scala puis envoyé sur le cluster pour être exécuté.</p></li>
</ul>
</section>
</div>
</div>
</section>
<section id="mode-local-schéma" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="mode-local-schéma">Mode local : schéma</h2>
<p><img src="mode_local.PNG" class="img-fluid"></p>
</section>
<section id="mode-local-à-éviter" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="mode-local-à-éviter">Mode local : à éviter</h2>
<p>En mode local :</p>
<ul>
<li><p>les ressources utilisées par la machine virtuelle sont celles de la bulle</p></li>
<li><p>il faut allouer suffisamment de coeurs à la JVM pour paralléliser</p></li>
<li><p>même si l’utilisateur choisit des ressources faibles, les ressources réelles utilisées dans une session spark peuvent être plus élevées : mauvaise gestion de l’allocation des ressources</p></li>
<li><p>accélération sensible par rapport à un mode de programmation classique séquentiel sur un unique coeur si beaucoup de ressources</p></li>
<li><p>Sur la bulle CASD, mauvaise gestion de la répartition des ressources en spark local : l’utilisation simultanée de spark par plusieurs membres de la bulle entraînent des ralentissements considérables</p>
<p>▶️mode local à éviter absolument</p></li>
</ul>
</section>
<section id="le-cluster-de-calcul-midares-présentation" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="le-cluster-de-calcul-midares-présentation">Le cluster de calcul Midares : présentation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="schema_cluster.drawio.png" class="img-fluid figure-img" width="691"></p>
</figure>
</div>
</section>
<section id="se-connecter-à-spark-sur-un-cluster" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="se-connecter-à-spark-sur-un-cluster">Se connecter à Spark sur un cluster</h2>
<p>Se connecter à spark revient à demander à spark de créer toutes les JVM demandées capables de lire du scala.</p>
<p>Pour se connecter à spark depuis R avec le package <code>sparklyr</code> :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="fu">library</span>(sparklyr)</span>
<span id="cb2-2"><a href="#cb2-2"></a></span>
<span id="cb2-3"><a href="#cb2-3"></a>conf <span class="ot">&lt;-</span> <span class="fu">spark_config</span>()</span>
<span id="cb2-4"><a href="#cb2-4"></a>conf<span class="sc">$</span>spark.executor.instances <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"yarn"</span>, <span class="at">config =</span> conf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Le paramètre <code>spark.executor.instances</code> correspond au nombre d’ordinateurs sur lequel on souhaite paralléliser le travail d’exécution de code. Ici, l’utilisateur demande 5 ordinateurs du cluster.</p>
<p>Nous verrons plus loin quels paramètres nous devons préciser dans le fichier de configuration.</p>
</section>
<section id="une-connexion" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="une-connexion">Une connexion</h2>
<p>Toutes les JVM demandées (5) sont instanciées dans les ordinateurs du cluster, avec les paramètres définis.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="schema_cluster.drawio.png" class="img-fluid figure-img" width="691"></p>
</figure>
</div>
</section>
<section id="la-vie-dun-programme-rédigé-en-sparklyr" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="la-vie-dun-programme-rédigé-en-sparklyr">La vie d’un programme rédigé en sparklyr</h2>
<p>Avec <code>sparklyr</code>, il est possible de programmer directement en <code>dplyr</code> pour utiliser spark.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># un data frame que j'envoie dans spark</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>un_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>), <span class="fu">c</span>(<span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span>))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(un_df) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"col_num"</span>, <span class="st">"col_char"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># C'est maintenant un spark_data_frame</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">copy_to</span>(sc, un_df)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>un_df_transforme <span class="ot">&lt;-</span> un_df <span class="sc">%&gt;%</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">une_nouvelle_col =</span> col_num<span class="sc">*</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si j’exécute ce programme, je ne pourrai pas ouvrir <code>un_df_transforme</code>, d’ailleurs, il ne se sera rien passé.</p>
</section>
<section id="la-lazy-evaluation" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="la-lazy-evaluation">La lazy evaluation</h2>
<p>Spark distingue deux types d’opérations :</p>
<ul>
<li><p><strong>les transformations :</strong> ce sont des opérations qui prennent en entrée un <code>spark_data_frame</code> et retournent un <code>spark_data_frame</code>, elles ne déclenchent aucun calcul lorsqu’elles sont appelées.</p>
<p>Par exemple, le programme ci-dessous est compilé instantanément et ne déclenche pas d’exécution :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>une_transformation <span class="ot">&lt;-</span> un_spark_data_frame <span class="sc">%&gt;%</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(identifiant) <span class="sc">%&gt;%</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">une_somme =</span> <span class="fu">sum</span>(revenus))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
<li><p><strong>les actions :</strong> ce sont des opérations qui demandent le calcul d’un résultat et qui déclenchent le calcul et l’exécution de toutes les transformations compilées jusqu’à l’appel de l’action.</p>
<p>Par exemple, le programme ci-dessous déclenche le calcul de la cellule <code>une_transformation</code> et de la moyenne des revenus :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>revenu_moyen <span class="ot">&lt;-</span> une_transformation <span class="sc">%&gt;%</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">revenu_moyen =</span> <span class="fu">mean</span>(une_somme)) <span class="sc">%&gt;%</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Les principales actions sont : <code>print()</code>, <code>collect()</code>, <code>head()</code>, <code>tbl_cache()</code> (écrire un <code>spark_data_frame</code> en mémoire pour le réutiliser).</p></li>
</ul>
</section>
<section id="la-vie-dun-programme-rédigé-en-sparklyr-1" class="level2">
<h2 class="anchored" data-anchor-id="la-vie-dun-programme-rédigé-en-sparklyr-1">La vie d’un programme rédigé en sparklyr</h2>
<p>Prenons l’exemple d’un programme contenant une action.</p>
<div class="cell">

</div>
</section>
<section id="le-rôle-du-driver" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="le-rôle-du-driver">Le rôle du driver</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="schema_cluster.drawio.png" class="img-fluid figure-img" width="400"></p>
</figure>
</div>
<ul>
<li><p>Le programme R est traduit en scala grâce au package <code>sparklyr</code></p></li>
<li><p>Le driver évalue le programme, il lit le code <code>scala</code> mais n’exécute rien du tout</p></li>
<li><p>S’il remarque une erreur, l’erreur est envoyée directement à l’utilisateur en session R avant l’exécution du programme : c’est la force de la lazy evaluation.</p></li>
</ul>
</section>
<section id="le-plan-dexécution" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="le-plan-dexécution">Le plan d’exécution</h2>
<p><img src="catalyst.jpg" class="img-fluid"></p>
<p>source : documentation CASD disponible à <a href="https://casd-eu.gitbook.io/data-science/">Documentation Data Science</a></p>
<p>AJOUTER UN DAG</p>
</section>
<section id="le-rôle-du-driver-catalyst" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="le-rôle-du-driver-catalyst">Le rôle du driver : Catalyst</h2>
<p>Le driver contient un programme nommé Catalyst qui optimise le code <code>scala</code> automatiquement.</p>
<p>Spark optimise automatiquement les programmes soumis :</p>
<ol type="1">
<li><p>Compilation des transformations pour soulever les éventuelles erreurs</p></li>
<li><p>Intégration dans un <strong>plan d’exécution</strong> contenant les étapes nécessaires pour parvenir au résultat demandé par le programme</p></li>
<li><p>Optimisation du plan logique par le module <strong>Catalyst</strong> (driver Spark)</p></li>
</ol>
<p>Par exemple si j’écris le programme :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>non_optimal <span class="ot">&lt;-</span> table_1 <span class="sc">%&gt;%</span>   </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">duree_contrat =</span> <span class="fu">DATEDIFF</span>(fin_contrat, debut_contrat)) <span class="sc">%&gt;%</span>   </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(debut_contrat <span class="sc">&gt;=</span> <span class="fu">as.Date</span>(<span class="st">"2023-01-01"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<pre><code>Catalyst réécrit :</code></pre>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>optimal <span class="ot">&lt;-</span> table_1 <span class="sc">%&gt;%</span>   </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(debut_contrat <span class="sc">&gt;=</span> <span class="fu">as.Date</span>(<span class="st">"2023-01-01"</span>)) <span class="sc">%&gt;%</span>   </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">duree_contrat =</span> <span class="fu">DATEDIFF</span>(fin_contrat, debut_contrat))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Cette optimisation est réalisée sur toutes les transformations compilée avant qu’une action déclenche l’exécution.</p>
</section>
<section id="le-rôle-du-driver-catalyst-1" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="le-rôle-du-driver-catalyst-1">Le rôle du driver : Catalyst</h2>
<p><img src="dag.webp" class="img-fluid"></p>
</section>
<section id="le-rôle-du-driver-catalyst-2" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="le-rôle-du-driver-catalyst-2">Le rôle du driver : Catalyst</h2>
<ol start="4" type="1">
<li><p>Réalisation de plans physiques possibles et sélection du <strong>meilleur plan physique</strong> (au regard de la localisation des données requises). Le plan physique est la distribution des différents calculs aux machines du cluster.</p></li>
<li><p><strong>Déclencher le moins d’actions possibles</strong> dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.</p></li>
<li><p>Pour profiter des avantages de spark, la manière de programmer recommandée est différente de celle prédominante en R classique.</p></li>
</ol>
</section>
<section id="le-rôle-du-cluster-manager" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="le-rôle-du-cluster-manager">Le rôle du cluster manager</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="schema_cluster.drawio.png" class="img-fluid figure-img" width="400"></p>
</figure>
</div>
<p>Le cluster manager distribue les traitements physiques aux ordinateurs du cluster :</p>
<ul>
<li><p>il connaît le meilleur plan physique fourni par Catalyst ;</p></li>
<li><p>il connaît les ressources disponibles et occupées par toutes les machines du cluster ;</p></li>
<li><p>il affecte les ressources disponibles à la session spark.</p></li>
</ul>
</section>
<section id="le-rôle-du-worker" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="le-rôle-du-worker">Le rôle du worker</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="schema_cluster.drawio.png" class="img-fluid figure-img" width="400"></p>
</figure>
</div>
<p>Le worker effectue le morceau de programme qu’on lui affecte et renvoie le résultat au driver, qui lui-même affiche le résultat en session R :</p>
<ul>
<li><p>il ne connaît que les tâches qu’on lui a affectées ;</p></li>
<li><p>il peut communiquer avec le driver en réseau pour renvoyer un résultat ;</p></li>
<li><p>il peut communiquer avec les autres workers en réseau pour partager des données ou des résultats intermédiaires : c’est un shuffle.</p></li>
</ul>
</section>
<section id="où-sont-les-données" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="où-sont-les-données">Où sont les données ?</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="schema_cluster.drawio.png" class="img-fluid figure-img" width="400"></p>
</figure>
</div>
</section>
<section id="où-sont-les-données-1" class="level2">
<h2 class="anchored" data-anchor-id="où-sont-les-données-1">Où sont les données ?</h2>
<p><img src="hdfs_browse.png" class="img-fluid"></p>
</section>
<section id="transfert-de-la-bulle-à-hdfs" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="transfert-de-la-bulle-à-hdfs">Transfert de la bulle à HDFS</h2>
<p><img src="hdfs_dowload.PNG" class="img-fluid"></p>
</section>
<section id="transfert-de-hdfs-à-la-bulle" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="transfert-de-hdfs-à-la-bulle">Transfert de HDFS à la bulle</h2>
<p><img src="hdfs_midas.PNG" class="img-fluid"></p>
</section>
<section id="mais-où-sont-réellement-les-données-hdfs" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="mais-où-sont-réellement-les-données-hdfs">Mais où sont réellement les données ? HDFS</h2>
<p>Hadoop Distributed File System (HDFS)</p>
<ul>
<li><p><strong>stockage sur différentes machines :</strong> ici les noeuds du cluster spark, c’est-à-dire les différents ordinateurs workers du cluster</p></li>
<li><p>données divisées <strong>en blocs</strong> plus petits de taille fixe et répartis sur les machines : aucune table de MiDAS n’existe en entier sur le cluster</p></li>
<li><p>chaque bloc est <strong>répliqué trois fois</strong> : il existe trois fois les 10 premières lignes de la table FNA sur trois ordinateurs différents du cluster (résilience)</p></li>
<li><p>un <strong>NameNode</strong> supervise les <strong>métadonnées</strong> et gère la structure du système de fichiers</p></li>
<li><p>les <strong>DataNodes</strong> stockent effectivement les blocs de données : les datanodes sont en fait les disques des workers du cluster, chaque ordinateur du cluster dispose d’un disque avec une partie des données MiDAS</p></li>
<li><p>le <strong>système HDFS</strong> est relié à la bulle Midares : possible de charger des données en clique-bouton de la bulle vers HDFS de manière très rapide et de télécharger des tables de HDFS pour les récupérer en local</p></li>
</ul>
</section>
</section>
<section id="programmer-avec-sparklyr" class="level1">
<h1>Programmer avec sparklyr</h1>
<section id="paramétrer-sa-session" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="paramétrer-sa-session">Paramétrer sa session</h2>
<p>Il faut préciser quelles ressources réserver pour chaque unité spark : le driver, le nombre d’ordinateurs workers (appelées instances), la RAM, le nombre de coeurs</p>
<p>La configuration par défaut est :</p>
<p>Il est nécessaire de configurer la session spark pour établir une connexion entre la session R et un cluster spark. Les paramètres à définir sont :</p>
<ul>
<li><p>Les ressources physiques utilisées :</p>
<ol type="1">
<li><p>par le <strong>driver</strong> : avec <code>spark.driver.memory</code> <strong>(avec parcimonie)</strong></p></li>
<li><p>par chaque <strong>worker</strong> avec <code>spark.executor.memory</code>(valeur max <strong>140 Go</strong>) et <code>spark.executor.cores</code> (valeur max <strong>8 coeurs</strong>)</p></li>
<li><p>le nombre de <strong>workers</strong> avec <code>spark.executor.instances</code> <strong>(2 ou 3 suffisent)</strong></p></li>
<li><p>La <strong>file</strong> sur laquelle on travaille avec <code>spark.yarn.queue</code> <strong>(prod ou dev)</strong></p></li>
</ol></li>
<li><p>le nombre de <strong>partitions</strong> de chaque <code>spark_data_frame</code> avec <code>spark.sql.shuffle.partitions</code> <strong>(200 par défaut)</strong></p></li>
<li><p>la <strong>limite de taille des résulats</strong> qui peuvent être <strong>collectés</strong> par le driver avec <code>spark.driver.maxResultSize</code> <strong>(0 est la meilleure option)</strong></p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>conf <span class="ot">&lt;-</span> <span class="fu">spark_config</span>()</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>conf[<span class="st">"spark.driver.memory"</span>] <span class="ot">&lt;-</span> <span class="st">"40Go"</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>conf[<span class="st">"spark.executor.memory"</span>] <span class="ot">&lt;-</span> <span class="st">"60Go"</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>conf[<span class="st">"spark.executor.cores"</span>] <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>conf[<span class="st">"spark.executor.instances"</span>] <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>cont[<span class="st">"spark.yarn.queue"</span>] <span class="ot">&lt;-</span> <span class="st">"prod"</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>conf[<span class="st">"spark.driver.maxResultSize"</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>conf[<span class="st">"spark.sql.shuffle.partitions"</span>] <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"yarn"</span>, <span class="at">config =</span> conf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="mode-cluster-non-concurrence-grâce-au-cluster-manager" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="mode-cluster-non-concurrence-grâce-au-cluster-manager">Mode cluster : non concurrence grâce au cluster manager</h2>
<p><img src="mode_cluster.PNG" class="img-fluid"></p>
<p>Le mode cluster permet une réelle distribution sur différents noeuds, qui sont en fait des ordinateurs distincts d’un serveur. Ces machines communiquent en réseau.</p>
<p>Capture d’écran réservation des ressources</p>
<p>Il est donc nécessaire de se déconnecter pour libérer les ressources : des ressources réservées, même lorsqu’aucun programme ne tourne, ne peuvent jamais être affectées à d’autres utilisateurs.</p>
<div class="cell">

</div>
</section>
<section id="importer-les-données-depuis-hdfs-sous-r" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="importer-les-données-depuis-hdfs-sous-r">Importer les données depuis HDFS sous R</h2>
<p>Les données doivent être disponibles dans les workers sous forme de <code>spark_data_frame</code> :</p>
<ul>
<li><p><strong>caché en mémoire directement</strong> : si utilisées de très nombreuses fois pour gagner du temps</p></li>
<li><p>laissé sur disque tant qu’aucune action ne déclenche un traitement qui nécessite son chargement en mémoire</p>
<p>▶️ chargement en mémoire vive couteux en temps : avec la configuration présentée, le chargement du FNA, du FHS et des MMO prend au moins 25 minutes.</p></li>
<li><p>Pour passer un <code>data.frame</code> R en spark_data_frame : <code>copy_to()</code></p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>pjc_df_spark <span class="ot">&lt;-</span> <span class="fu">spark_read_parquet</span>(sc,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">path =</span> <span class="st">"hdfs:///dataset/MiDAS_v4/FNA/pjc.parquet"</span>,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">memory =</span> <span class="cn">TRUE</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>pjc_filtree <span class="ot">&lt;-</span> pjc_df_spark <span class="sc">%&gt;%</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(KDDPJ <span class="sc">&gt;=</span> <span class="fu">as.Date</span>(<span class="st">"2022-01-01"</span>))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_write_parquet</span>(pjc_filtree, <span class="st">"hdfs:///tmp/pjc_filtree.parquet"</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>pjc_df_spark <span class="ot">&lt;-</span> <span class="fu">copy_to</span>(sc, <span class="st">"PJC"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="les-exports-sur-hdfs" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="les-exports-sur-hdfs">Les exports sur HDFS</h2>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Les exports sur HDFS
</div>
</div>
<div class="callout-body-container callout-body">
<p>Lorsqu’on exporte une table depuis notre session R vers HDFS, celle-ci est <strong>automatiquement partitionnée</strong>, comme le reste des données.</p>
<p>Ainsi, cette table sera stockée en plusieurs morceaux sous HDFS et répliquée.</p>
<p>Il est possible de maîtriser le nombre de partitions avec la commande <code>sdf_coalesce(partitions = 5)</code> du package <code>sparklyr</code>.</p>
<p>L’idéal est d’<strong>adapter le nombre de partitions à la taille d’un bloc</strong> : un bloc mesure 128 MB. Lorsqu’un bloc disque est utilisé, même à 1%, il n’est pas utilisable pour un autre stockage.</p>
<p>Exporter un fichier de 1MB en 200 partitions réserve 200 blocs inutilement.</p>
</div>
</div>
</section>
<section id="les-shuffles" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="les-shuffles">Les shuffles</h2>
<p><img src="reduce_distribue.drawio.png" class="img-fluid"></p>
<p>Comme nous l’avons vu, les traitements REDUCE ne se prêtent pas très bien au calcul distribué :</p>
<ul>
<li><p>augmenter le nombre de workers augmente la probabilité de devoir effectuer des shuffles</p></li>
<li><p>il est recommandé de se limiter à deux workers comme dans la configuration proposée</p></li>
<li><p>réserver d’autres ressources n’est souvent pas efficient et monopolise les ressources pour les autres utilisateurs.</p></li>
</ul>
</section>
<section id="récupérer-un-résultat" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="récupérer-un-résultat">Récupérer un résultat</h2>
<p>Les résultats qu’il est recommandé de récupérer en mémoire vive en session R sont de la forme suivante :</p>
<ul>
<li><p><strong>une table filtrée</strong> avec les variables nécessaires à l’étude uniquement : sous MiDAS, toutes les jointures, les calculs de variable et les filtres peuvent être effectués de manière efficiente sous la forme de spark_data_frame, sans jamais collecter les données MiDAS ;</p></li>
<li><p>des <strong>statistiques descriptives synthétiques ;</strong></p></li>
<li><p>les <strong>premières lignes</strong> de la table pour vérifier que le programme retourne bien le résultat attendu ;</p></li>
<li><p>une <strong>table agrégée</strong> pour un graphique par exemple, à l’aide de la fonction <code>summarise()</code>.</p></li>
</ul>
</section>
<section id="lutilisation-de-la-mémoire-du-driver" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="lutilisation-de-la-mémoire-du-driver">L’utilisation de la mémoire du driver</h2>
<p><img src="collect.drawio.png" class="img-fluid"></p>
</section>
<section id="lutilisation-de-la-mémoire-du-driver-1" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="lutilisation-de-la-mémoire-du-driver-1">L’utilisation de la mémoire du driver</h2>
<p>Lorsqu’il est nécessaire de collecter une table volumineuse, il faut donc prévoir assez de mémoire RAM pour le driver.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>conf <span class="ot">&lt;-</span> <span class="fu">spark_config</span>()</span>
<span id="cb11-2"><a href="#cb11-2"></a>conf[<span class="st">"spark.driver.memory"</span>] <span class="ot">&lt;-</span> <span class="st">"40Go"</span></span>
<span id="cb11-3"><a href="#cb11-3"></a>conf[<span class="st">"spark.executor.memory"</span>] <span class="ot">&lt;-</span> <span class="st">"80Go"</span></span>
<span id="cb11-4"><a href="#cb11-4"></a>conf[<span class="st">"spark.executor.cores"</span>] <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb11-5"><a href="#cb11-5"></a>conf[<span class="st">"spark.executor.instances"</span>] <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb11-6"><a href="#cb11-6"></a>cont[<span class="st">"spark.yarn.queue"</span>] <span class="ot">&lt;-</span> <span class="st">"prod"</span></span>
<span id="cb11-7"><a href="#cb11-7"></a>conf[<span class="st">"spark.driver.maxResultSize"</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb11-8"><a href="#cb11-8"></a>conf[<span class="st">"spark.sql.shuffle.partitions"</span>] <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb11-9"><a href="#cb11-9"></a></span>
<span id="cb11-10"><a href="#cb11-10"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"yarn"</span>, <span class="at">config =</span> conf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Bonne pratique de partage des ressources
</div>
</div>
<div class="callout-body-container callout-body">
<p>Le driver est instancié dans la bulle Midares, qui a vocation à être réduite suite à la généralisation du cluster.</p>
<ul>
<li><p>La bulle Midares a besoin de RAM minimale pour fonctionner, 100% des ressources ne sont donc pas disponibles pour <code>sparklyr</code>.</p></li>
<li><p>Pour permettre le <strong>travail simultané fluide de 10 utilisateurs</strong>, la mémoire allouée au driver recommandée pour chaque utilisateur est de <strong>15 Go</strong>.</p></li>
<li><p><strong>L’export d’une table</strong> <code>sdf</code> directement au format <code>.parquet</code> est une alternative plus rapide, plus efficiente et qui permet par la suite de charger ses données en R classique et de travailler sur un <code>df</code> R sans utiliser <code>sparklyr</code>.</p></li>
</ul>
</div>
</div>
</section>
<section id="comment-tester-son-code-pour-collecter-le-moins-possible" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="comment-tester-son-code-pour-collecter-le-moins-possible">Comment tester son code pour collecter le moins possible ?</h2>
<p>La programmation en spark doit être adaptée aux contraintes de volumétrie des données : test de chaque étape, puis ne forcer le calcul qu’à la fin pour que Catalyst optimise l’ensemble du programme</p>
<p>La principale différence avec la programmation en R classique est que <strong>la visualisation de tables complètes volumineuses n’est pas recommandée</strong> :</p>
<ul>
<li><p><strong>goulets d’étranglement</strong> même avec spark, car toutes les données sont rapatriées vers le driver puis vers la session R ;</p></li>
<li><p><strong>longue :</strong> échange entre tous les noeuds impliqués dans le calcul et le driver, puis un échange driver-session R ;</p></li>
<li><p><strong>beaucoup moins efficace que l’export direct en parquet</strong> du résultat (presque instantanné) : charger ensuite sa table finale en data frame R classique pour effectuer l’étude.</p></li>
</ul>
<p>S’il est nécessaire de collecter, il faut prévoir <strong>beaucoup de RAM pour le driver avec le paramètre</strong> <code>spark.driver.memory</code><strong>.</strong></p>
</section>
</section>
<section id="sparklyr-la-solution-ergonomique-de-spark-sous-r" class="level1">
<h1>Sparklyr : la solution ergonomique de spark sous R</h1>
<section id="ce-qui-change-pour-lutilisateur" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="ce-qui-change-pour-lutilisateur">Ce qui change pour l’utilisateur</h2>
<p>La majorité des commandes <code>dplyr</code> fonctionnent sur un spark_data_frame avec le package <code>sparklyr</code>. Les divergences principales sont les suivantes :</p>
<table class="table">
<colgroup>
<col style="width: 37%">
<col style="width: 23%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Fonctionnalité</th>
<th>tidyverse</th>
<th>sparklyr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>import d’un fichier <code>.parquet</code></td>
<td><code>read_parquet</code></td>
<td><code>spark_read_parquet()</code></td>
</tr>
<tr class="even">
<td>tri d’un tableau</td>
<td><code>arrange()</code></td>
<td><code>window_order()</code> ou <code>sdf_sort()</code></td>
</tr>
<tr class="odd">
<td>opérations sur les dates</td>
<td><code>lubridate</code></td>
<td>fonctions Hive</td>
</tr>
<tr class="even">
<td>empiler des tableaux</td>
<td><code>bind_rows()</code></td>
<td><code>sdf_bind_rows()</code></td>
</tr>
<tr class="odd">
<td>nombre de lignes d’un tableau</td>
<td><code>nrow()</code></td>
<td><code>sdf_nrow()</code></td>
</tr>
<tr class="even">
<td>faire pivoter un tableau</td>
<td><code>tidyr</code></td>
<td><code>sdf_pivot()</code></td>
</tr>
<tr class="odd">
<td>export d’un <code>spark_data_frame</code></td>
<td></td>
<td><code>spark_write_parquet()</code></td>
</tr>
</tbody>
</table>
</section>
<section id="quelques-fonctions-spécifiques" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="quelques-fonctions-spécifiques">Quelques fonctions spécifiques</h2>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Dates</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Tableau</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false">Statistiques</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>Les fonctions de <code>lubridate()</code>ne sont pas adaptées au <code>spark_data_frames</code>.</p>
<ul>
<li><p>Convertir une chaîne de caractère de la forme AAAA-MM-DD en Date</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>date_1 <span class="ot">&lt;-</span> <span class="fu">as.Date</span>(<span class="st">"2024-05-26"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
<li><p>Calculer une durée entre deux dates</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>PJC_spark <span class="ot">&lt;-</span> <span class="fu">spark_read_parquet</span>(sc,</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>                                <span class="at">path =</span> <span class="st">"hdfs:///dataset/MiDAS_v4/pjc.parquet"</span>,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                                <span class="at">memory =</span> <span class="cn">FALSE</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>duree_pjc_df <span class="ot">&lt;-</span> PJC_spark <span class="sc">%&gt;%</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">date_fin_pjc =</span> <span class="fu">as.Date</span>(KDFPJ),</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">date_deb_pjc =</span> <span class="fu">as.Date</span>(KDDPJ)) <span class="sc">%&gt;%</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">duree_pjc =</span> <span class="fu">datediff</span>(date_fin_pjc, date_deb_pjc) <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
<li><p>Ajouter ou soustraire des jours ou des mois à une date</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>duree_pjc_bis_df <span class="ot">&lt;-</span> duree_pjc_df <span class="sc">%&gt;%</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">duree_pjc_plus_5 =</span> <span class="fu">date_add</span>(duree_pjc, <span class="fu">int</span>(<span class="dv">5</span>)),</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">duree_pjc_moins_5 =</span> <span class="fu">date_sub</span>(duree_pjc, <span class="fu">int</span>(<span class="dv">5</span>)),</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">duree_pjc_plus_1_mois =</span> <span class="fu">add_months</span>(duree_pjc, <span class="fu">int</span>(<span class="dv">1</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Add_months
</div>
</div>
<div class="callout-body-container callout-body">
<p>Si la date en entrée est le dernier jour d’un mois, la date retournée avec <code>add_months(date_entree, int(1))</code> sera le dernier jour calendaire du mois suivant.</p>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Format
</div>
</div>
<div class="callout-body-container callout-body">
<p>Le <code>int()</code> est important car ces fonctions Hive n’accepte que les entiers pour l’ajout de jours : taper uniquement 5 est considéré comme un flottant dans R.</p>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<ul>
<li><p>Tri dans un groupe pour effectuer un calcul séquentiel</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>ODD_spark <span class="ot">&lt;-</span> <span class="fu">spark_read_parquet</span>(sc,</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>                                <span class="at">path =</span> <span class="st">"hdfs:///dataset/MiDAS_v4/odd.parquet"</span>,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                                <span class="at">memory =</span> <span class="cn">FALSE</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>ODD_premier <span class="ot">&lt;-</span> ODD_spark <span class="sc">%&gt;%</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(id_midas) <span class="sc">%&gt;%</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">window_order</span>(id_midas, KDPOD) <span class="sc">%&gt;%</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">date_premier_droit =</span> <span class="fu">first</span>(KDPOD)) <span class="sc">%&gt;%</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(id_midas, KROD3, date_premier_droit) <span class="sc">%&gt;%</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
<li><p>Tri pour une sortie : <code>sdf_sort()</code> , <code>arrange()</code> ne fonctionne pas</p></li>
<li><p>Concaténer les lignes (ou les colonnes <code>sdf_bind_cols()</code>)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>ODD_1 <span class="ot">&lt;-</span> ODD_spark <span class="sc">%&gt;%</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(KDPOD <span class="sc">&lt;=</span> <span class="fu">as.Date</span>(<span class="st">"2017-12-31"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">groupe =</span> <span class="st">"temoins"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>ODD_2 <span class="ot">&lt;-</span> ODD_spark <span class="sc">%&gt;%</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(KDPOD <span class="sc">&gt;=</span> <span class="fu">as.Date</span>(<span class="st">"2021-12-31"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">groupe =</span> <span class="st">"traites"</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>ODD_evaluation <span class="ot">&lt;-</span> <span class="fu">sdf_bind_rows</span>(ODD_1, ODD_2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
<li><p>Dédoublonner une table</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>droits_dans_PJC <span class="ot">&lt;-</span> PJC_spark <span class="sc">%&gt;%</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sdf_distinct</span>(id_midas, KROD3)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">head</span>(droits_dans_PJC, <span class="dv">5</span>))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>PJC_dedoublonnee <span class="ot">&lt;-</span> PJC_spark <span class="sc">%&gt;%</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sdf_drop_duplicates</span>()</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">head</span>(PJC_dedoublonnee, <span class="dv">5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
<li><p>Pivot : les fonctions du packag <code>tidyr</code> ne fonctionnent pas sur données spark</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>ODD_sjr_moyen <span class="ot">&lt;-</span> ODD_spark <span class="sc">%&gt;%</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">groupe =</span> <span class="fu">ifelse</span>(KDPOD <span class="sc">&lt;=</span> <span class="fu">as.Date</span>(<span class="st">"2020-12-31"</span>), <span class="st">"controles"</span>, <span class="st">"traites"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sdf_pivot</span>(groupe <span class="sc">~</span> KCRGC,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun.aggregate =</span> <span class="fu">list</span>(<span class="at">KQCSJP =</span> <span class="st">"mean"</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
</ul>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">
<ul>
<li><p>Résumé statistique : <code>sdf_describe()</code> , <code>summary()</code>ne fonctionne pas.</p></li>
<li><p>Dimension : <code>sdf_dim</code>, la fonction <code>nrow()</code>ne fonctionne pas.</p></li>
<li><p>Quantiles approximatifs : le calcul des quantiles sur données distirbuées renvoie une approximation car toutes les données ne peuvent pas être rappatriées sur la même machine physique du fait de la volumétrie, <code>sdf_quantile()</code></p></li>
<li><p>Echantillonnage aléatoire : <code>sdf_random_split</code></p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="quelques-tips-doptimisation" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="quelques-tips-doptimisation">Quelques tips d’optimisation</h2>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Jointures</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Persist</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false">Chargement</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-4" role="tab" aria-controls="tabset-3-4" aria-selected="false">Export et partitions</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p>Pour effectuer ce type de jointure avec deux tables de volumétries différentes : A est petite, B est très volumineuse</p>
<p><img src="join.png" class="img-fluid"></p>
<p>Solution rapide :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>table_finale <span class="ot">&lt;-</span> table_volumineuse_comme_PJC <span class="sc">%&gt;%</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">right_join</span>(petite_table_mon_champ)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Solution lente :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>table_finale <span class="ot">&lt;-</span> petite_table_mon_champ <span class="sc">%&gt;%</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(table_volumineuse_comme_PJC)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>Lorsqu’une table intermédiaire est utilisée plusieurs fois dans un traitement, il est possible de la persister, c’est-à-dire enregistrer ce <code>spark_data_frame</code>sur le disque ou dans la mémoire des noeuds.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>table_1 <span class="ot">&lt;-</span> mon_champ <span class="sc">%&gt;%</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">left_join</span>(ODD, <span class="at">by =</span> <span class="fu">c</span>(<span class="st">"id_midas"</span>, <span class="st">"KROD3"</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">duree_potentielle_indemnisation =</span> KPJDXP,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">SJR =</span> KQCSJP,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">date_debut_indemnisation =</span> KDPOD) <span class="sc">%&gt;%</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sdf_persist</span>()</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>duree <span class="ot">&lt;-</span> table_1 <span class="sc">%&gt;%</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">duree_moy =</span> <span class="fu">mean</span>(duree_potentielle_indemnisation),</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">duree_med =</span> <span class="fu">median</span>(duree_potentielle_indemnisation)) <span class="sc">%&gt;%</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect</span>()</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>SJR <span class="ot">&lt;-</span> table_1 <span class="sc">%&gt;%</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">SJR_moy =</span> <span class="fu">mean</span>(SJR),</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>            <span class="at">SJR_med =</span> <span class="fu">median</span>(SJR)) <span class="sc">%&gt;%</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<p>Lorsqu’on charge des données dans le cluster Spark et que la table est appelée plusieurs fois dans le programme, il est conseillé de la charger en mémoire vive directement.</p>
<p>Attention, si beaucoup de tables volumineuses sont chargées en mémoire, la fraction de la mémoire spark dédiée au stockage peut être insuffisante ou bien il peut ne pas rester assez de spark memory pour l’exécution.</p>
</div>
<div id="tabset-3-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-4-tab">
<p>Le format <code>.parquet</code> (avec <code>arrow</code>) et le framework <code>spark</code> permettent de gérer le partitionnement des données.</p>
<p>Si les opérations sont souvent effectuées par régions par exemple, il est utile de forcer le stockage des données d’une même région au même endroit physique et accélère drastiquement le temps de calcul</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">spark_write_parquet</span>(DE, <span class="at">partition_by =</span> <span class="fu">c</span>(<span class="st">"REGIND"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout-warning callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Exports simultanés
</div>
</div>
<div class="callout-body-container callout-body">
<p>HDFS supporte les exports simultanés, mais le temp d’export est plus long lorsque le NameNode est requêté par plusieurs personnes simultanément : d’après les tests cluster</p>
<ul>
<li><p>pour un petit export (5 minutes), le temps peut être multiplié par 4 ;</p></li>
<li><p>pour un gros export (15 minutes), le temps peut être multiplié par 2.</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="forcer-le-calcul" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="forcer-le-calcul">Forcer le calcul</h2>
<p>Quelques actions :</p>
<ul>
<li><p>collecter la table entière 🛑</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>spark_data_frame_1 <span class="sc">%&gt;%</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
<li><p>afficher les premières lignes</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>spark_data_frame_1 <span class="sc">%&gt;%</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
<li><p>Mettre les donner en cache</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>spark_data_frame_1 <span class="sc">%&gt;%</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sdf_register</span>() <span class="sc">%&gt;%</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tbl_cache</span>()</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>sc <span class="sc">%&gt;%</span> <span class="fu">spark_session</span>() <span class="sc">%&gt;%</span> <span class="fu">invoke</span>(<span class="st">"catalog"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">invoke</span>(<span class="st">"clearCache"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></li>
</ul>
</section>
<section id="les-erreurs-en-sparklyr" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="les-erreurs-en-sparklyr">Les erreurs en sparklyr</h2>
<p><code>sparklyr</code> traduit le code <code>dplyr</code> fourni en <code>scala</code>, mais interprète également les messages d’erreurs envoyés du cluster vers la session R.</p>
<p><code>sparklyr</code> n’est cependant pas performant pour interpréter ces erreurs.</p>
<p>N’hésitez pas à enregistrer le code générant un message d’erreur dans Documents publics/erreurs_sparklyr</p>
<p>Un test du code pas-à-pas permet d’isoler le problème.</p>
</section>
<section id="bonnes-pratiques" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="bonnes-pratiques">Bonnes pratiques</h2>
<ul>
<li><p>Déconnexion ou fermeture R pour libérer les ressources 🛑</p></li>
<li><p>Ne plus utiliser spark en local 🖥️🖥️🖥️</p></li>
<li><p>Pyspark ou Sparklyr pour la production ❓</p></li>
<li><p>Utilisation parcimonieuse des ressources ⚖️</p></li>
<li><p>Envoi des erreurs sparklyr 📩</p></li>
</ul>
</section>
</section>
<section id="pour-aller-plus-loin" class="level1">
<h1>Pour aller plus loin</h1>
<section id="larchitecture-map-reduce" class="level2">
<h2 class="anchored" data-anchor-id="larchitecture-map-reduce">L’architecture Map Reduce</h2>
<p><img src="map_reduce.png" class="img-fluid"></p>
</section>
<section id="la-gestion-de-la-mémoire-avec-spark" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="la-gestion-de-la-mémoire-avec-spark">La gestion de la mémoire avec spark</h2>
<p>Les <strong>shuffles</strong> sont les opérations les plus gourmandes en temps.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Qu’est-ce qu’un shuffle ?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Un shuffle est un <strong>échange de données entre différents noeuds</strong> du cluster.</p>
<p>Nous avons vu qu’utiliser <code>spark</code> dans un cluster implique de distribuer également le stockage des données.</p>
<p>Par exemple :</p>
<ol type="1">
<li><p>je demande un traitement sur la table PJC du FNA</p></li>
<li><p>si un noeud contenant déjà les données de PJC est disponible, le cluster manager envoie le traitement à ce noeud</p></li>
<li><p>si tous les noeuds contenant les données de PJC sont déjà réservés, alors le cluster manager demande le traitement à un autre noeud, par exemple le noeud 1</p></li>
<li><p>il demande à un noeud contenant les données PJC, par exemple le noeud 4, d’envoyer ces données au noeud 1 qui va exécuter le traitement</p></li>
<li><p>cet échange de données est en réseau filaire : un échange filaire est beaucoup plus lent qu’un envoi interne par le disque du noeud 1 à la RAM du noeud 1</p></li>
<li><p>c’est pourquoi pour optimiser un programme spark, il est possible de limiter les shuffles</p></li>
</ol>
</div>
</div>
</section>
<section id="lutilisation-de-la-mémoire-dans-un-worker" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="lutilisation-de-la-mémoire-dans-un-worker">L’utilisation de la mémoire dans un worker</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><img src="memoire_worker_1.drawio.png" class="img-fluid"></p>
</div><div class="column" style="width:50%;">
<p><img src="memoire_worker_2.drawio.png" class="img-fluid"></p>
</div>
</div>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ne pas charger plusieurs fois les mêmes données en cache, ou si besoin augmenter la part de la mémoire allouée au stockage avec <code>spark.memory.storageFraction</code>.</p>
</div>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1"></a>conf <span class="ot">&lt;-</span> <span class="fu">spark_config</span>()</span>
<span id="cb26-2"><a href="#cb26-2"></a>conf[<span class="st">"spark.driver.memory"</span>] <span class="ot">&lt;-</span> <span class="st">"40Go"</span></span>
<span id="cb26-3"><a href="#cb26-3"></a>conf[<span class="st">"spark.executor.memory"</span>] <span class="ot">&lt;-</span> <span class="st">"80Go"</span></span>
<span id="cb26-4"><a href="#cb26-4"></a>conf[<span class="st">"spark.memory.fraction"</span>] <span class="ot">&lt;-</span> <span class="fl">0.8</span></span>
<span id="cb26-5"><a href="#cb26-5"></a>conf[<span class="st">"spark.executor.cores"</span>] <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb26-6"><a href="#cb26-6"></a>conf[<span class="st">"spark.executor.instances"</span>] <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb26-7"><a href="#cb26-7"></a>cont[<span class="st">"spark.yarn.queue"</span>] <span class="ot">&lt;-</span> <span class="st">"prod"</span></span>
<span id="cb26-8"><a href="#cb26-8"></a>conf[<span class="st">"spark.driver.maxResultSize"</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb26-9"><a href="#cb26-9"></a>conf[<span class="st">"spark.sql.shuffle.partitions"</span>] <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb26-10"><a href="#cb26-10"></a></span>
<span id="cb26-11"><a href="#cb26-11"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"yarn"</span>, <span class="at">config =</span> conf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a>conf <span class="ot">&lt;-</span> <span class="fu">spark_config</span>()</span>
<span id="cb27-2"><a href="#cb27-2"></a>conf[<span class="st">"spark.driver.memory"</span>] <span class="ot">&lt;-</span> <span class="st">"40Go"</span></span>
<span id="cb27-3"><a href="#cb27-3"></a>conf[<span class="st">"spark.executor.memory"</span>] <span class="ot">&lt;-</span> <span class="st">"80Go"</span></span>
<span id="cb27-4"><a href="#cb27-4"></a>conf[<span class="st">"spark.memory.fraction"</span>] <span class="ot">&lt;-</span> <span class="fl">0.8</span></span>
<span id="cb27-5"><a href="#cb27-5"></a>conf[<span class="st">"spark.memory.storageFraction"</span>] <span class="ot">&lt;-</span> <span class="fl">0.4</span></span>
<span id="cb27-6"><a href="#cb27-6"></a>conf[<span class="st">"spark.executor.cores"</span>] <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb27-7"><a href="#cb27-7"></a>conf[<span class="st">"spark.executor.instances"</span>] <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb27-8"><a href="#cb27-8"></a>cont[<span class="st">"spark.yarn.queue"</span>] <span class="ot">&lt;-</span> <span class="st">"prod"</span></span>
<span id="cb27-9"><a href="#cb27-9"></a>conf[<span class="st">"spark.driver.maxResultSize"</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb27-10"><a href="#cb27-10"></a>conf[<span class="st">"spark.sql.shuffle.partitions"</span>] <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb27-11"><a href="#cb27-11"></a></span>
<span id="cb27-12"><a href="#cb27-12"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"yarn"</span>, <span class="at">config =</span> conf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="sparkui-un-outil-doptimisation" class="level2 smaller scrollable">
<h2 class="smaller scrollable anchored" data-anchor-id="sparkui-un-outil-doptimisation">SparkUI : un outil d’optimisation</h2>
<p>Spark UI permet de consulter le plan logique et physique du traitement demandé. Trois outils permettent d’optimiser les traitements :</p>
<div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">DAG</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">GC</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-3" role="tab" aria-controls="tabset-4-3" aria-selected="false">Mémoire</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<p><img src="dag.webp" class="img-fluid"></p>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<p>Vérifier que le <code>gc time</code> est inférieur à 10% du temps pour exécuter la tâche ✅</p>
<p><img src="gc.png" class="img-fluid"></p>
</div>
<div id="tabset-4-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-3-tab">
<p>Vérifier que la <code>storage memory</code> ne sature pas la mémoire ✅</p>
<p><img src="gc.png" class="img-fluid"></p>
</div>
</div>
</div>
</section>
<section id="utiliser-les-interfaces" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="utiliser-les-interfaces">Utiliser les interfaces</h2>
<ul>
<li><p><strong>yarn</strong> : disponibilité des ressources</p>
<p><img src="yarn_scheduler.PNG" class="img-fluid"></p></li>
<li><p><strong>Sparkhistory</strong> pour des traitements de sessions fermées</p></li>
</ul>
<p>Le sparkhistory entraîne l’enregistrement de logs assez lourdes, il est donc désactivé par défaut. Pour l’activer sur un programme :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>conf <span class="ot">&lt;-</span> <span class="fu">spark_config</span>()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>conf[<span class="st">"spark.eventLog.enabled"</span>] <span class="ot">&lt;-</span> <span class="st">"true"</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>conf[<span class="st">"spark.eventLog.dir"</span>] <span class="ot">&lt;-</span> <span class="st">"hdfs://midares-deb11-nn-01.midares.local:9000/spark-logs"</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>conf[<span class="st">"appName"</span>] <span class="ot">&lt;-</span> <span class="st">"un_nom_de_traitement"</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">spark_connect</span>(<span class="at">master =</span> <span class="st">"yarn"</span>, <span class="at">config =</span> conf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="ma-session-ne-sinstancie-jamais" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="ma-session-ne-sinstancie-jamais">Ma session ne s’instancie jamais</h2>
<p>Si l’instruction <code>sc &lt;- spark_connect(master = "yarn", config = conf</code> prend plus de 10 minutes, il est utile d’ouvrir l’interface de yarn pour vérifier que la file n’est pas déjà entièrement occupée. L’erreur peut ne survenir qu’au bout d’une vingtaine de minutes : le job est <code>ACCEPTED</code> dans yarn, ou <code>FAILED</code> si la session n’a pas pu être instanciée par manque de ressources disponibles.</p>
<p><img src="yarn_accepted.jpg" class="img-fluid"></p>
</section>
<section id="exporter-de-hdfs-au-local" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="exporter-de-hdfs-au-local">Exporter de HDFS au local</h2>
<div class="r-stack">
<p><img src="hdfs_browse.png" class="fragment" width="1000" height="700"></p>
<p><img src="hdfs_download.png" class="fragment" width="1000" height="700"></p>
</div>
</section>
<section id="pyspark-mode-cluster" class="level2">
<h2 class="anchored" data-anchor-id="pyspark-mode-cluster">Pyspark : mode cluster</h2>
<p><img src="pyspark.drawio.png" class="img-fluid"></p>
</section>
<section id="les-avantages-de-pyspark" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="les-avantages-de-pyspark">Les avantages de pyspark</h2>
<ul>
<li><p>Mode cluster : une machine du cluster peut prendre le rôle de driver 🖥️</p></li>
<li><p>Spark context dans le cluster : fermer sa session anaconda ne stoppe pas le traitement ♾️</p></li>
<li><p>Plusieurs sessions simultanées 👩‍💻👩‍💻👩‍💻</p></li>
<li><p>Stabilité : compatibilité assurée avec Apache Spark, problématique de production 🔄</p></li>
<li><p>Lisibilité du code 👓</p></li>
<li><p>Temps de connexion et d’exécution réduit ⏲️</p></li>
<li><p>Utilisation optimale de SparkUI 📊</p></li>
</ul>
</section>
<section id="merci-pour-votre-attention" class="level2">
<h2 class="anchored" data-anchor-id="merci-pour-votre-attention">Merci pour votre attention !</h2>


</section>
</section>

</main> <!-- /main -->

<script>
  // htmlwidgets need to know to resize themselves when slides are shown/hidden.
  // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
  // slide changes (different for each slide format).
  (function () {
    // dispatch for htmlwidgets
    function fireSlideEnter() {
      const event = window.document.createEvent("Event");
      event.initEvent("slideenter", true, true);
      window.document.dispatchEvent(event);
    }

    function fireSlideChanged(previousSlide, currentSlide) {
      fireSlideEnter();

      // dispatch for shiny
      if (window.jQuery) {
        if (previousSlide) {
          window.jQuery(previousSlide).trigger("hidden");
        }
        if (currentSlide) {
          window.jQuery(currentSlide).trigger("shown");
        }
      }
    }

    // hookup for slidy
    if (window.w3c_slidy) {
      window.w3c_slidy.add_observer(function (slide_num) {
        // slide_num starts at position 1
        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
      });
    }

  })();
</script>

<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>