[
  {
    "objectID": "slides.html#au-programme",
    "href": "slides.html#au-programme",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Au programme",
    "text": "Au programme\n\nMiDAS : une base de donn√©es volumineuse üíæ\nManipuler un appariement : une op√©ration co√ªteuse üí≤\nInitiation au calcul distribu√© : quelles ressources r√©server ? üñ•Ô∏èüñ•Ô∏èüñ•Ô∏è\nSparklyr : la solution ergonomique de spark sous R üë®‚Äçüíª\nPour aller plus loin ‚è©"
  },
  {
    "objectID": "slides.html#midas-une-base-de-donn√©es-volumineuse",
    "href": "slides.html#midas-une-base-de-donn√©es-volumineuse",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "MiDAS : une base de donn√©es volumineuse",
    "text": "MiDAS : une base de donn√©es volumineuse\nMiDAS croise trois bases de donn√©es administratives exhaustives :\n\nles donn√©es sur l‚Äôinscription et l‚Äôindemnisation des demandeurs d‚Äôemploi de France Travail : le Fichier Historique Statistique (FHS) et le Fichier National des Allocataires (FNA) ;\nles donn√©es sur les b√©n√©ficiaires de minima sociaux (RSA, PPA, AAH) et les caract√©ristiques des m√©nages de la CNAF : Allstat-FR6 ;\nles donn√©es sur les contrats salari√©s de la DSN : MMO de la Dares."
  },
  {
    "objectID": "slides.html#midas-une-base-de-donn√©es-volumineuse-1",
    "href": "slides.html#midas-une-base-de-donn√©es-volumineuse-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "MiDAS : une base de donn√©es volumineuse",
    "text": "MiDAS : une base de donn√©es volumineuse\nChaque vague de MiDAS correspond √† environ 600 Go de donn√©es au format sas. Les vagues fonctionnent par empilement :\n\nle gain de profondeur temporelle et l‚Äôentr√©e dans le champ de nouvelles personnes\nles vagues sont appariables entre elles"
  },
  {
    "objectID": "slides.html#midas-une-base-de-donn√©es-volumineuse-2",
    "href": "slides.html#midas-une-base-de-donn√©es-volumineuse-2",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "MiDAS : une base de donn√©es volumineuse",
    "text": "MiDAS : une base de donn√©es volumineuse\nMiDAS est l‚Äôune des bases de donn√©es les plus volumineuses du SSP :\nLes administrations dont les donn√©es sont comparables √† MiDAS utilisent un cluster Spark : Insee, Drees, Acoss‚Ä¶\n‚ñ∂Ô∏èLe cluster spark est la solution la plus efficiente pour traiter des donn√©es de cette ampleur. Apprendre √† l‚Äôutiliser pourra vous √™tre utile dans d‚Äôautres contextes que celui de la Dares."
  },
  {
    "objectID": "slides.html#structure-de-lappariement",
    "href": "slides.html#structure-de-lappariement",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Structure de l‚Äôappariement",
    "text": "Structure de l‚Äôappariement\n\n\n\n\n\n\n\nPourquoi Spark ?\n\n\nLa manipulation des donn√©es MiDAS en l‚Äô√©tat implique de nombreuses op√©rations de jointures qui n√©cessitent une puissance de calcul et un temps certains."
  },
  {
    "objectID": "slides.html#le-format-parquet",
    "href": "slides.html#le-format-parquet",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le format parquet",
    "text": "Le format parquet\nLes donn√©es sont converties au format parquet d√®s leur r√©ception et mises √† disposition sur la bulle CASD du projet MiDares sous l‚Äôespace commun. Le format parquet est un format de donn√©es adapt√© aux donn√©es volumineuses :\n\nil compresse efficacement les donn√©es : taux de compression de 5 √† 10 par rapport au format csv\nil est orient√© colonnes\nil permet le chargement efficace en m√©moire des donn√©es\nIl permet le stockage partitionn√© des donn√©es\nil permet un traitement de cette partition qui conserve les donn√©es non n√©cessaires sur disque\nIl est ind√©pendant du logiciel utilis√© : il peut donc √™tre trait√© par spark et par R."
  },
  {
    "objectID": "slides.html#lespace-midares",
    "href": "slides.html#lespace-midares",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "L‚Äôespace MiDares",
    "text": "L‚Äôespace MiDares\n\nRessourcesSch√©ma\n\n\nDes ressources partag√©es entre tous les utilsateurs simultan√©s :\n\n512 Go de m√©moire vive (ou RAM) : passage √† 256 Go\n\n\n\n\n\n\n\nLa m√©moire vive\n\n\nLa m√©moire vive, aussi appel√©e RAM, se distingue de la m√©moire de stockage (disque) par sa rapidit√©, notamment pour fournir des donn√©es au processeur pour effectuer des calculs, par sa volatilit√© (toutes les donn√©es sont perdues si l‚Äôordinateur n‚Äôest plus aliment√©) et par l‚Äôacc√®s direct aux informations qui y sont stock√©es, quasi instantann√©.\n\n\n\n\nUn processeur (ou CPU) compos√© de 32 coeurs : passage √† 16 coeurs\n\n\n\n\n\n\n\nLe processeur\n\n\nLe processeur permet d‚Äôex√©cuter des t√¢ches et des programmes : convertir un fichier, ex√©cuter un logiciel‚Ä¶ Il est compos√© d‚Äôun ou de plusieurs coeurs : un coeur ne peut ex√©cuter qu‚Äôune seule t√¢che √† la fois. Si le processeur contient plusieurs coeurs, il peut ex√©cuter autant de t√¢ches en parall√®le qu‚Äôil a de coeurs. Un processeur se caract√©rise aussi par sa fr√©quence : elle est globalement proportionnelle au nombre d‚Äôop√©rations qu‚Äôil est capable d‚Äôeffetuer par seconde."
  },
  {
    "objectID": "slides.html#programmer-en-m√©moire-vive",
    "href": "slides.html#programmer-en-m√©moire-vive",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Programmer en m√©moire vive",
    "text": "Programmer en m√©moire vive\n\nR : la m√©moire vive, √©tat dans l‚Äôenvironnement\nSAS : lecture/√©criture sur le disque\nMiDAS au format sas >> taille de la m√©moire vive disponible du serveur CASD ‚Äì> format .parquet\nImpossible de charger tout MiDAS en m√©moire vive\nDes solutions existent pour manipuler les donn√©es sous R sans les charger enti√®rement en m√©moire vive :\narrow (avec des requ√™tes dplyr)\nduckDB : recommand√© par le SSPLab pour des donn√©es jusqu‚Äô√† 100Go\n‚ñ∂Ô∏è Insuffisantes pour les traitements les plus co√ªteux sur MiDAS en R : la partie de la m√©moire vive utilis√©e pour stocker les donn√©es correspond √† autant de puissance de calcul indisponible pour les traitements."
  },
  {
    "objectID": "slides.html#les-traitements-co√ªteux-en-puissance-de-calcul",
    "href": "slides.html#les-traitements-co√ªteux-en-puissance-de-calcul",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Les traitements co√ªteux en puissance de calcul",
    "text": "Les traitements co√ªteux en puissance de calcul\n\nles jointures\nles op√©rations en group_by()\ndistinct()\n‚ñ∂Ô∏è Ex√©cution s√©quentielle sur un coeur du processeur + beaucoup de m√©moire vive (donn√©es temporaires)\n‚ñ∂Ô∏è Erreur ‚Äúout of memory‚Äù."
  },
  {
    "objectID": "slides.html#un-traitement-peu-co√ªteux",
    "href": "slides.html#un-traitement-peu-co√ªteux",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Un traitement peu co√ªteux",
    "text": "Un traitement peu co√ªteux\n\nCe traitement est peu co√ªteux :\n\nchargement d‚Äôune seule colonne en RAM : format parquet orient√© colonnes\npeu de m√©moire d‚Äôex√©cution : R est un langage vectoris√©",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#un-traitement-co√ªteux",
    "href": "slides.html#un-traitement-co√ªteux",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Un traitement co√ªteux",
    "text": "Un traitement co√ªteux\n\nCe traitement n√©cessite :\n\nle chargement de davantage de colonnes en m√©moire vive ;\ndavantage de m√©moire d‚Äôex√©cution pour effectuer l‚Äôintersection (inner_join()).",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#calcul-distribu√©-et-calcul-parall√®le",
    "href": "slides.html#calcul-distribu√©-et-calcul-parall√®le",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Calcul distribu√© et calcul parall√®le",
    "text": "Calcul distribu√© et calcul parall√®le\n\n\nCalcul non distribu√©\nLes probl√©matiques Big Data en R sont les suivantes :\n\nla taille des donn√©es : charg√©es en m√©moire pour effectuer les calculs avec R\nle temps de calcul : les √©tapes du traitement sont effectu√©es de mani√®re s√©quentielle par le processeur (tr√®s long)\nl‚Äôoptimisation du programme\n\n\nCalcul distribu√© spark\nLe calcul distribu√© avec spark apporte une solution √† ces probl√©matiques :\n\nchargement des donn√©es en m√©moire parcimonieux et non syst√©matique\nex√©cution de t√¢ches en parall√®le sur plusieurs coeurs du processeur, voire sur plusieurs ordinateurs diff√©rents\noptimisation automatique du code"
  },
  {
    "objectID": "slides.html#le-cluster-de-calcul-midares-mode-interactif",
    "href": "slides.html#le-cluster-de-calcul-midares-mode-interactif",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le cluster de calcul Midares : mode interactif",
    "text": "Le cluster de calcul Midares : mode interactif",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#spark",
    "href": "slides.html#spark",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Spark",
    "text": "Spark\n\nApache Spark : librairie open source d√©velopp√©e dans le langage scala\nScala : langage compil√©, rapide et distribuable qui peut √™tre ex√©cut√© dans une machine virtuelle Java\n\nval TopHorrorsIGN2022 = Seq(\n  (9, \"Pearl\"),\n  (6, \"The Sadness\"),\n  (6, \"Offseason\"),\n  (7, \"Hatching\"),\n  (8, \"x\")\n).toDF(\"IMDB Rating\", \"IGN Movie Picks\")\n\nval TopHorrorsTheAVClub2022 = Seq(\n  (7, \"Nope\"),\n  (9, \"Pearl\"),\n  (8, \"x\"),\n  (5, \"Barbarian\"),\n  (5, \"Bones And All\")\n).toDF(\"IMDB Rating\", \"AVC Movie Picks\")\n\nimport org.apache.spark.sql.functions.col\n\nval cols = List(col(\"IGN Movie Picks\"), col(\"AVC Movie Picks\"))\n\nval query = TopHorrorsIGN2022(\n  \"IGN Movie Picks\"\n) === TopHorrorsTheAVClub2022(\"AVC Movie Picks\")\n\nval outerJoin = TopHorrorsIGN2022\n  .join(TopHorrorsTheAVClub2022, query, \"outer\")\n  .select(cols: _*)\n\nouterJoin.show()\n\nscala adapt√© pour ma√Ætriser toutes les fonctionnalit√©s de spark et optimiser au maximum les traitements en spark\nspark est compatible avec les langages scala, R, python, java, et peut interpr√©ter des commandes SQL.\nDeux packages existent sous R :\n\nsparkR propos√© par Apache Spark\nsparklyr, qui permet d‚Äôutiliser directement des commandes dplyr traduites en spark par le package."
  },
  {
    "objectID": "slides.html#mode-local-concurrence",
    "href": "slides.html#mode-local-concurrence",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mode local : concurrence",
    "text": "Mode local : concurrence",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#mode-cluster-non-concurrence",
    "href": "slides.html#mode-cluster-non-concurrence",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mode cluster : non concurrence",
    "text": "Mode cluster : non concurrence\n\nLe mode cluster permet une r√©elle distribution sur diff√©rents noeuds, qui sont en fait des ordinateurs distincts d‚Äôun serveur. Ces machines communiquent en r√©seau.",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#installation-de-spark-sous-casd",
    "href": "slides.html#installation-de-spark-sous-casd",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Installation de spark sous CASD",
    "text": "Installation de spark sous CASD\nVoir la fiche d√©di√©e sur le site"
  },
  {
    "objectID": "slides.html#le-stockage-distribu√©-hdfs",
    "href": "slides.html#le-stockage-distribu√©-hdfs",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le stockage distribu√© : HDFS",
    "text": "Le stockage distribu√© : HDFS\n\nstockage sur diff√©rentes machines : ici les noeuds du cluster spark, c‚Äôest-√†-dire les diff√©rents ordinateurs workers du cluster\ndonn√©es divis√©es en blocs plus petits de taille fixe et r√©partis sur les machines\nchaque bloc est r√©pliqu√© trois fois pour √™tre r√©silient face aux pannes\nun NameNode supervise les m√©tadonn√©es et g√®re la structure du syst√®me de fichiers\nles DataNodes stockent effectivement les blocs de donn√©es\nle syst√®me HDFS est reli√© √† la bulle Midares : possible de charger des donn√©es en clique-bouton de la bulle vers HDFS de mani√®re tr√®s rapide et de t√©l√©charger des tables de HDFS pour les r√©cup√©rer en local\n\n\n\n\n\n\nLes exports sur HDFS\n\n\nLorsqu‚Äôon exporte une table depuis notre session R vers HDFS, celle-ci est automatiquement partitionn√©e, comme le reste des donn√©es.\nAinsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.\nIl est possible de ma√Ætriser le nombre de partitions avec la commande sdf_coalesce(partitions = 5) du package sparklyr.\nL‚Äôid√©al est d‚Äôadapter le nombre de partitions √† la taille d‚Äôun bloc : un bloc mesure 128 MB. Lorsqu‚Äôun bloc disque est utilis√©, m√™me √† 1%, il n‚Äôest pas utilisable pour un autre stockage.\nExporter un fichier de 1MB en 200 partitions r√©serve 200 blocs inutilement.",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#le-stockage-distribu√©-hdfs-1",
    "href": "slides.html#le-stockage-distribu√©-hdfs-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le stockage distribu√© : HDFS",
    "text": "Le stockage distribu√© : HDFS\n\n‚ñ∂Ô∏è Les r√©plications de donn√©es ont deux fonctions :\n\naugementer la flexibilit√© de la distribution des traitements\naugmenter la r√©silience en cas de panne d‚Äôun noeud",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#la-lazy-evaluation",
    "href": "slides.html#la-lazy-evaluation",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La lazy evaluation",
    "text": "La lazy evaluation\nSpark distingue deux types d‚Äôop√©rations :\n\nles transformations : ce sont des op√©rations qui prennent en entr√©e un spark_data_frame et retournent un spark_data_frame, elles ne d√©clenchent aucun calcul lorsqu‚Äôelles sont appel√©es.\nPar exemple, le programme ci-dessous est compil√© instantan√©ment et ne d√©clenche pas d‚Äôex√©cution :\n\nune_transformation <- un_spark_data_frame %>%\n  group_by(identifiant) %>%\n  mutate(une_somme = sum(revenus))\n\nles actions : ce sont des op√©rations qui demandent le calcul d‚Äôun r√©sultat et qui d√©clenchent le calcul et l‚Äôex√©cution de toutes les transformations compil√©es jusqu‚Äô√† l‚Äôappel de l‚Äôaction.\nPar exemple, le programme ci-dessous d√©clenche le calcul de la cellule une_transformation et de la moyenne des revenus :\n\nrevenu_moyen <- une_transformation %>%\n  summarise(revenu_moyen = mean(une_somme)) %>%\n  print()\n\nLes principales actions sont : print(), collect(), head(), tbl_cache() (√©crire un spark_data_frame en m√©moire pour le r√©utiliser)."
  },
  {
    "objectID": "slides.html#la-lazy-evaluation-1",
    "href": "slides.html#la-lazy-evaluation-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La lazy evaluation",
    "text": "La lazy evaluation\nSpark optimise automatiquement les programmes soumis :\n\nCompilation des transformations\nInt√©gration dans un plan d‚Äôex√©cution : √©ventuelles erreurs du programme soulev√©es avant l‚Äôex√©cution\nOptimisation du plan logique par le module Catalyst (driver Spark)\nPar exemple si j‚Äô√©cris le programme :\n\nnon_optimal &lt;- table_1 %&gt;%\n  mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %&gt;%\n  filter(debut_contrat &gt;= as.Date(\"2023-01-01\"))\n\nCatalyst r√©√©crit :\n\nnon_optimal &lt;- table_1 %&gt;%\n  filter(debut_contrat &gt;= as.Date(\"2023-01-01\")) %&gt;%\n  mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))\n\nCette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu‚Äôune action d√©clenche l‚Äôex√©cution.\nR√©alisation de plans physiques possibles et s√©lection du meilleur plan physique (au regard de la localisation des donn√©es requises).\nD√©clencher le moins d‚Äôactions possibles dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.\nPour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique.",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#le-plan-dex√©cution",
    "href": "slides.html#le-plan-dex√©cution",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le plan d‚Äôex√©cution",
    "text": "Le plan d‚Äôex√©cution\n\nsource : documentation CASD disponible √† Documentation Data Science\nAJOUTER UN DAG"
  },
  {
    "objectID": "slides.html#r√©cup√©rer-un-r√©sultat",
    "href": "slides.html#r√©cup√©rer-un-r√©sultat",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "R√©cup√©rer un r√©sultat",
    "text": "R√©cup√©rer un r√©sultat\nLes r√©sultats qu‚Äôil est recommand√© de r√©cup√©rer en m√©moire vive en session R sont de la forme suivante :\n\nune table filtr√©e avec les variables n√©cessaires √† l‚Äô√©tude uniquement : sous MiDAS, toutes les jointures, les calculs de variable et les filtres peuvent √™tre effectu√©s de mani√®re efficiente sous la forme de spark_data_frame, sans jamais collecter les donn√©es MiDAS ;\ndes statistiques descriptives synth√©tiques ;\nles premi√®res lignes de la table pour v√©rifier que le programme retourne bien le r√©sultat attendu ;\nune table agr√©g√©e pour un graphique par exemple, √† l‚Äôaide de la fonction summarise()."
  },
  {
    "objectID": "slides.html#sparklyr-et-sparkr",
    "href": "slides.html#sparklyr-et-sparkr",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Sparklyr et SparkR",
    "text": "Sparklyr et SparkR\nDeux packages permettent de programmer avec Spark sous R :\n\nSparkR : ce package, maintenu par Apache Spark, permet d‚Äôutiliser une syntaxe proche de spark, scala, ou directement du code SQL pour manipuler des donn√©es dans une session R.\nSparklyr : ce package permet d‚Äôutiliser directement la syntaxe dplyr dans une session Spark sous R.\n\nSparklyr fonctionne selon ces √©tapes :\n\nLa JVM driver spark est instanci√©e dans la bulle Midares pour utiliser sparklyr.\nLes instructions dplyr appel√©es sur un spark_data_frame sont traduites par les fonctions du package sparklyr en scala, puis envoy√©es au driver.\nLe programme en scala est ex√©cut√© sur le cluster.\nSi une erreur est renvoy√©e par le driver, elle est interpr√©t√©e par R avant d‚Äô√™tre affich√©e en session R.",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#configuration-cluster",
    "href": "slides.html#configuration-cluster",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Configuration cluster",
    "text": "Configuration cluster\nDeux √©tapes majeures dans le traitement de donn√©es sous R diff√®re en sparklyr par rapport √† une programmation classique en dplyr :\n\nConfigurationImport-export\n\n\nIl est n√©cessaire de configurer la session spark pour √©tablir une connexion entre la session R et un cluster spark. Les param√®tres √† d√©finir sont :\n\nLes ressources physiques utilis√©es :\n\npar le driver : avec spark.driver.memory (avec parcimonie)\npar chaque worker avec spark.executor.memory(valeur max 140 Go) et spark.executor.cores (valeur max 8 coeurs)\nle nombre de workers avec spark.executor.instances (2 ou 3 suffisent)\nLa file sur laquelle on travaille avec spark.yarn.queue (prod ou dev)\n\nle nombre de partitions de chaque spark_data_frame avec spark.sql.shuffle.partitions (200 par d√©faut)\nla limite de taille des r√©sulats qui peuvent √™tre collect√©s par le driver avec spark.driver.maxResultSize (0 est la meilleure option)\n\n\nconf &lt;- spark_config()\nconf[\"spark.driver.memory\"] &lt;- \"40Go\"\nconf[\"spark.executor.memory\"] &lt;- \"80Go\"\nconf[\"spark.executor.cores\"] &lt;- 5\nconf[\"spark.executor.instances\"] &lt;- 2\ncont[\"spark.yarn.queue\"] &lt;- \"prod\"\nconf[\"spark.driver.maxResultSize\"] &lt;- 0\nconf[\"spark.sql.shuffle.partitions\"] &lt;- 200\n\nsc &lt;- spark_connect(master = \"yarn\", config = conf)\n\n\n\nLes donn√©es doivent √™tre disponibles dans les workers sous forme de spark_data_frame :\n\ncach√© en m√©moire directement : si utilis√©es plusieurs fois pour gagner du temps\nlaiss√© sur disque tant qu‚Äôaucune action ne d√©clenche un traitement qui n√©cessite son chargement en m√©moire\n‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : avec la configuration pr√©sent√©e, le chargement du FNA, du FHS et des MMO prend au moins 25 minutes.\nPour passer un data.frame R en spark_data_frame : copy_to()",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#lutilisation-de-la-m√©moire-dans-un-worker",
    "href": "slides.html#lutilisation-de-la-m√©moire-dans-un-worker",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "L‚Äôutilisation de la m√©moire dans un worker",
    "text": "L‚Äôutilisation de la m√©moire dans un worker\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\nNe pas charger plusieurs fois les m√™mes donn√©es en cache, ou si besoin augmenter la part de la m√©moire allou√©e au stockage avec spark.memory.storageFraction.\n\n\n\n\n\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.memory.fraction\"] <- 0.8\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n\n\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.memory.fraction\"] <- 0.8\nconf[\"spark.memory.storageFraction\"] <- 0.4\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)"
  },
  {
    "objectID": "slides.html#lutilisation-de-la-m√©moire-du-driver",
    "href": "slides.html#lutilisation-de-la-m√©moire-du-driver",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "L‚Äôutilisation de la m√©moire du driver",
    "text": "L‚Äôutilisation de la m√©moire du driver"
  },
  {
    "objectID": "slides.html#ce-qui-change-pour-lutilisateur",
    "href": "slides.html#ce-qui-change-pour-lutilisateur",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Ce qui change pour l‚Äôutilisateur",
    "text": "Ce qui change pour l‚Äôutilisateur\nLa majorit√© des commandes dplyr fonctionnent sur un spark_data_frame avec le package sparklyr. Les divergences principales sont les suivantes :\n\n\n\n\n\n\n\n\nFonctionnalit√©\ntidyverse\nsparklyr\n\n\n\n\nimport d‚Äôun fichier .parquet\nread_parquet\nspark_read_parquet()\n\n\ntri d‚Äôun tableau\narrange()\nwindow_order() ou sdf_sort()\n\n\nop√©rations sur les dates\nlubridate\nfonctions Hive\n\n\nempiler des tableaux\nbind_rows()\nsdf_bind_rows()\n\n\nnombre de lignes d‚Äôun tableau\nnrow()\nsdf_nrow()\n\n\nfaire pivoter un tableau\ntidyr\nsdf_pivot()\n\n\nexport d‚Äôun spark_data_frame\n\nspark_write_parquet()"
  },
  {
    "objectID": "slides.html#quelques-fonctions-sp√©cifiques",
    "href": "slides.html#quelques-fonctions-sp√©cifiques",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Quelques fonctions sp√©cifiques",
    "text": "Quelques fonctions sp√©cifiques\n\nDatesTableauStatistiques\n\n\nLes fonctions de lubridate()ne sont pas adapt√©es au spark_data_frames.\n\nConvertir une cha√Æne de caract√®re de la forme AAAA-MM-DD en Date\n\ndate_1 <- as.Date(\"2024-05-26\")\n\nCalculer une dur√©e entre deux dates\n\nPJC_spark <- spark_read_parquet(sc,\n                                path = \"hdfs:///dataset/MiDAS_v4/pjc.parquet\",\n                                memory = FALSE)\n\nduree_pjc_df <- PJC_spark %>%\n  rename(date_fin_pjc = as.Date(KDFPJ),\n         date_deb_pjc = as.Date(KDDPJ)) %>%\n  mutate(duree_pjc = datediff(date_fin_pjc, date_deb_pjc) + 1) %>%\n  head(5)\n\nAjouter ou soustraire des jours ou des mois √† une date\n\nduree_pjc_bis_df <- duree_pjc_df %>%\n  mutate(duree_pjc_plus_5 = date_add(duree_pjc, int(5)),\n         duree_pjc_moins_5 = date_sub(duree_pjc, int(5)),\n         duree_pjc_plus_1_mois = add_months(duree_pjc, int(1))) %>%\n  head(5)\n\n\n\n\n\n\n\n\nAdd_months\n\n\nSi la date en entr√©e est le dernier jour d‚Äôun mois, la date retourn√©e avec add_months(date_entree, int(1)) sera le dernier jour calendaire du mois suivant.\n\n\n\n\n\n\n\n\n\nFormat\n\n\nLe int() est important car ces fonctions Hive n‚Äôaccepte que les entiers pour l‚Äôajout de jours : taper uniquement 5 est consid√©r√© comme un flottant dans R.\n\n\n\n\n\n\nTri dans un groupe pour effectuer un calcul s√©quentiel\n\nODD_spark <- spark_read_parquet(sc,\n                                path = \"hdfs:///dataset/MiDAS_v4/odd.parquet\",\n                                memory = FALSE)\n\nODD_premier <- ODD_spark %>%\n  group_by(id_midas) %>%\n  window_order(id_midas, KDPOD) %>%\n  mutate(date_premier_droit = first(KDPOD)) %>%\n  ungroup() %>%\n  distinct(id_midas, KROD3, date_premier_droit) %>%\n  head(5)\n\nTri pour une sortie : sdf_sort() , arrange() ne fonctionne pas\nConcat√©ner les lignes (ou les colonnes sdf_bind_cols())\n\nODD_1 <- ODD_spark %>%\n  filter(KDPOD <= as.Date(\"2017-12-31\")) %>%\n  mutate(groupe = \"temoins\")\n\nODD_2 <- ODD_spark %>%\n  filter(KDPOD >= as.Date(\"2021-12-31\")) %>%\n  mutate(groupe = \"traites\")\n\nODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)\n\nD√©doublonner une table\n\ndroits_dans_PJC <- PJC_spark %>%\n  sdf_distinct(id_midas, KROD3)\n\nprint(head(droits_dans_PJC, 5))\n\nPJC_dedoublonnee <- PJC_spark %>%\n  sdf_drop_duplicates()\n\nprint(head(PJC_dedoublonnee, 5))\n\nPivot : les fonctions du packag tidyr ne fonctionnent pas sur donn√©es spark\n\nODD_sjr_moyen <- ODD_spark %>%\n  mutate(groupe = ifelse(KDPOD <= as.Date(\"2020-12-31\"), \"controles\", \"traites\")) %>%\n  sdf_pivot(groupe ~ KCRGC,\n    fun.aggregate = list(KQCSJP = \"mean\")\n  )\n\n\n\n\n\nR√©sum√© statistique : sdf_describe() , summary()ne fonctionne pas.\nDimension : sdf_dim, la fonction nrow()ne fonctionne pas.\nQuantiles approximatifs : le calcul des quantiles sur donn√©es distirbu√©es renvoie une approximation car toutes les donn√©es ne peuvent pas √™tre rappatri√©es sur la m√™me machine physique du fait de la volum√©trie, sdf_quantile()\nEchantillonnage al√©atoire : sdf_random_split"
  },
  {
    "objectID": "slides.html#une-r√®gle-dor-tester-son-code-pour-collecter-le-moins-possible",
    "href": "slides.html#une-r√®gle-dor-tester-son-code-pour-collecter-le-moins-possible",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Une r√®gle d‚Äôor : tester son code pour collecter le moins possible",
    "text": "Une r√®gle d‚Äôor : tester son code pour collecter le moins possible\nLa programmation en spark doit √™tre adapt√©e aux contraintes de volum√©trie des donn√©es : test de chaque √©tape, puis ne forcer le calcul qu‚Äô√† la fin pour que Catalyst optimise l‚Äôensemble du programme\nLa principale diff√©rence avec la programmation en R classique est que la visualisation de tables compl√®tes volumineuses n‚Äôest pas recommand√©e :\n\ngoulets d‚Äô√©tranglement m√™me avec spark, car toutes les donn√©es sont rapatri√©es vers le driver puis vers la session R ;\nlongue : √©change entre tous les noeuds impliqu√©s dans le calcul et le driver, puis un √©change driver-session R ;\nbeaucoup moins efficace que l‚Äôexport direct en parquet du r√©sultat (presque instantann√©) : charger ensuite sa table finale en data frame R classique pour effectuer l‚Äô√©tude.\n\nS‚Äôil est n√©cessaire de collecter, il faut pr√©voir beaucoup de RAM pour le driver avec le param√®tre ‚Äúspark.driver.memory‚Äù.",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#quelques-tips-doptimisation",
    "href": "slides.html#quelques-tips-doptimisation",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Quelques tips d‚Äôoptimisation",
    "text": "Quelques tips d‚Äôoptimisation\n\nJointuresPersistChargementExport et partitions\n\n\nPour effectuer ce type de jointure avec deux tables de volum√©tries diff√©rentes : A est petite, B est tr√®s volumineuse\n\nSolution rapide :\n\ntable_finale <- table_volumineuse_comme_PJC %>%\n  right_join(petite_table_mon_champ)\n\nSolution lente :\n\ntable_finale <- petite_table_mon_champ %>%\n  left_join(table_volumineuse_comme_PJC)\n\n\n\nLorsqu‚Äôune table interm√©diaire est utilis√©e plusieurs fois dans un traitement, il est possible de la persister, c‚Äôest-√†-dire enregistrer ce spark_data_framesur le disque ou dans la m√©moire des noeuds.\n\ntable_1 <- mon_champ %>%\n  left_join(ODD, by = c(\"id_midas\", \"KROD3\")) %>%\n  rename(duree_potentielle_indemnisation = KPJDXP,\n         SJR = KQCSJP,\n         date_debut_indemnisation = KDPOD) %>%\n  sdf_persist()\n\nduree <- table_1 %>%\n  summarise(duree_moy = mean(duree_potentielle_indemnisation),\n            duree_med = median(duree_potentielle_indemnisation)) %>%\n  collect()\n\nSJR <- table_1 %>%\n  summarise(SJR_moy = mean(SJR),\n            SJR_med = median(SJR)) %>%\n  collect()\n\n\n\nLorsqu‚Äôon charge des donn√©es dans le cluster Spark et que la table est appel√©e plusieurs fois dans le programme, il est conseill√© de la charger en m√©moire vive directement.\nAttention, si beaucoup de tables volumineuses sont charg√©es en m√©moire, la fraction de la m√©moire spark d√©di√©e au stockage peut √™tre insuffisante ou bien il peut ne pas rester assez de spark memory pour l‚Äôex√©cution.\n\n\nLe format .parquet (avec arrow) et le framework spark permettent de g√©rer le partitionnement des donn√©es.\nSi les op√©rations sont souvent effectu√©es par r√©gions par exemple, il est utile de forcer le stockage des donn√©es d‚Äôune m√™me r√©gion au m√™me endroit physique et acc√©l√®re drastiquement le temps de calcul\n\nspark_write_parquet(DE, partition_by = c(\"REGIND\"))\n\n\n\n\n\n\n\nExports simultan√©s\n\n\nHDFS supporte les exports simultan√©s, mais le temp d‚Äôexport est plus long lorsque le NameNode est requ√™t√© par plusieurs personnes simultan√©ment : d‚Äôapr√®s les tests cluster\n\npour un petit export (5 minutes), le temps peut √™tre multipli√© par 4 ;\npour un gros export (15 minutes), le temps peut √™tre multipli√© par 2."
  },
  {
    "objectID": "slides.html#forcer-le-calcul",
    "href": "slides.html#forcer-le-calcul",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Forcer le calcul",
    "text": "Forcer le calcul\nQuelques actions :\n\ncollecter la table enti√®re üõë\n\nspark_data_frame_1 %>%\n  collect()\n\nafficher les premi√®res lignes\n\nspark_data_frame_1 %>%\n  head(10)\n\nMettre les donner en cache\n\nspark_data_frame_1 %>%\n  sdf_register() %>%\n  tbl_cache()\n\nsc %>% spark_session() %>% invoke(\"catalog\") %>% \n  invoke(\"clearCache\")"
  },
  {
    "objectID": "slides.html#les-erreurs-en-sparklyr",
    "href": "slides.html#les-erreurs-en-sparklyr",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Les erreurs en sparklyr",
    "text": "Les erreurs en sparklyr\nsparklyr traduit le code dplyr fourni en scala, mais interpr√®te √©galement les messages d‚Äôerreurs envoy√©s du cluster vers la session R.\nsparklyr n‚Äôest cependant pas performant pour interpr√©ter ces erreurs.\nN‚Äôh√©sitez pas √† enregistrer le code g√©n√©rant un message d‚Äôerreur dans Documents publics/erreurs_sparklyr\nUn test du code pas-√†-pas permet d‚Äôisoler le probl√®me."
  },
  {
    "objectID": "slides.html#bonnes-pratiques",
    "href": "slides.html#bonnes-pratiques",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Bonnes pratiques",
    "text": "Bonnes pratiques\n\nD√©connexion ou fermeture R pour lib√©rer les ressources üõë\nNe plus utiliser spark en local üñ•Ô∏èüñ•Ô∏èüñ•Ô∏è\nPyspark ou Sparklyr pour la production ‚ùì\nUtilisation parcimonieuse des ressources ‚öñÔ∏è\nEnvoi des erreurs sparklyr üì©"
  },
  {
    "objectID": "slides.html#larchitecture-map-reduce",
    "href": "slides.html#larchitecture-map-reduce",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "L‚Äôarchitecture Map Reduce",
    "text": "L‚Äôarchitecture Map Reduce"
  },
  {
    "objectID": "slides.html#la-gestion-de-la-m√©moire-avec-spark",
    "href": "slides.html#la-gestion-de-la-m√©moire-avec-spark",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La gestion de la m√©moire avec spark",
    "text": "La gestion de la m√©moire avec spark\nLes shuffles sont les op√©rations les plus gourmandes en temps.\n\n\n\n\n\n\nQu‚Äôest-ce qu‚Äôun shuffle ?\n\n\nUn shuffle est un √©change de donn√©es entre diff√©rents noeuds du cluster.\nNous avons vu qu‚Äôutiliser spark dans un cluster implique de distribuer √©galement le stockage des donn√©es.\nPar exemple :\n\nje demande un traitement sur la table PJC du FNA\nsi un noeud contenant d√©j√† les donn√©es de PJC est disponible, le cluster manager envoie le traitement √† ce noeud\nsi tous les noeuds contenant les donn√©es de PJC sont d√©j√† r√©serv√©s, alors le cluster manager demande le traitement √† un autre noeud, par exemple le noeud 1\nil demande √† un noeud contenant les donn√©es PJC, par exemple le noeud 4, d‚Äôenvoyer ces donn√©es au noeud 1 qui va ex√©cuter le traitement\ncet √©change de donn√©es est en r√©seau filaire : un √©change filaire est beaucoup plus lent qu‚Äôun envoi interne par le disque du noeud 1 √† la RAM du noeud 1\nc‚Äôest pourquoi pour optimiser un programme spark, il est possible de limiter les shuffles"
  },
  {
    "objectID": "slides.html#utiliser-les-interfaces",
    "href": "slides.html#utiliser-les-interfaces",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Utiliser les interfaces",
    "text": "Utiliser les interfaces\n\nyarn : disponibilit√© des ressources\n\nSparkhistory pour des traitements de sessions ferm√©es\n\nLe sparkhistory entra√Æne l‚Äôenregistrement de logs assez lourdes, il est donc d√©sactiv√© par d√©faut. Pour l‚Äôactiver sur un programme :\n\nconf <- spark_config()\nconf[\"spark.eventLog.enabled\"] <- \"true\"\nconf[\"spark.eventLog.dir\"] <- \"hdfs://midares-deb11-nn-01.midares.local:9000/spark-logs\"\nconf[\"appName\"] <- \"un_nom_de_traitement\"\n\nsc <- spark_connect(master = \"yarn\", config = conf)"
  },
  {
    "objectID": "slides.html#exporter-de-hdfs-au-local",
    "href": "slides.html#exporter-de-hdfs-au-local",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Exporter de HDFS au local",
    "text": "Exporter de HDFS au local"
  },
  {
    "objectID": "slides.html#pyspark-mode-cluster",
    "href": "slides.html#pyspark-mode-cluster",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Pyspark : mode cluster",
    "text": "Pyspark : mode cluster"
  },
  {
    "objectID": "slides.html#les-avantages-de-pyspark",
    "href": "slides.html#les-avantages-de-pyspark",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Les avantages de pyspark",
    "text": "Les avantages de pyspark\n\nMode cluster : une machine du cluster peut prendre le r√¥le de driver üñ•Ô∏è\nSpark context dans le cluster : fermer sa session anaconda ne stoppe pas le traitement ‚ôæÔ∏è\nPlusieurs sessions simultan√©es üë©‚Äçüíªüë©‚Äçüíªüë©‚Äçüíª\nStabilit√© : compatibilit√© assur√©e avec Apache Spark, probl√©matique de production üîÑ\nLisibilit√© du code üëì\nTemps de connexion et d‚Äôex√©cution r√©duit ‚è≤Ô∏è\nUtilisation optimale de SparkUI üìä"
  },
  {
    "objectID": "slides.html#merci-pour-votre-attention",
    "href": "slides.html#merci-pour-votre-attention",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Merci pour votre attention !",
    "text": "Merci pour votre attention !"
  },
  {
    "objectID": "slides.html#mode-local-concurrence-1",
    "href": "slides.html#mode-local-concurrence-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mode local : concurrence",
    "text": "Mode local : concurrence\nEn mode local :\n\nune unique machine Java\nparall√©lisation des t√¢ches sur diff√©rents coeurs de cette machine virtuelle\npas de stockage distribu√©, ca n‚Äôest pas du calcul distribu√© √† proprement parler\nacc√©l√©ration par rapport √† un mode de programmation classique s√©quentiel sur un unique coeur si beaucoup de ressources\nSur la bulle CASD, mauvaise gestion de la r√©partition des ressources en spark local\n‚ñ∂Ô∏èmode local √† √©viter absolument",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#configuration-des-ressources-cluster",
    "href": "slides.html#configuration-des-ressources-cluster",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Configuration des ressources cluster",
    "text": "Configuration des ressources cluster",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#lutilisation-de-la-m√©moire-du-driver-1",
    "href": "slides.html#lutilisation-de-la-m√©moire-du-driver-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "L‚Äôutilisation de la m√©moire du driver",
    "text": "L‚Äôutilisation de la m√©moire du driver\nLorsqu‚Äôil est n√©cessaire de collecter une table volumineuse, il faut donc pr√©voir assez de m√©moire RAM pour le driver.\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n\n\n\n\n\n\n\nBonne pratique de partage des ressources\n\n\nLe driver est instanci√© dans la bulle Midares, qui a vocation √† √™tre r√©duite suite √† la g√©n√©ralisation du cluster.\n\nLa bulle Midares a besoin de RAM minimale pour fonctionner, 100% des ressources ne sont donc pas disponibles pour sparklyr.\nPour permettre le travail simultan√© fluide de 10 utilisateurs, la m√©moire allou√©e au driver recommand√©e pour chaque utilisateur est de 15 Go.\nL‚Äôexport d‚Äôune table sdf directement au format .parquet est une alternative plus rapide, plus efficiente et qui permet par la suite de charger ses donn√©es en R classique et de travailler sur un df R sans utiliser sparklyr."
  },
  {
    "objectID": "slides.html#comment-tester-son-code-pour-collecter-le-moins-possible",
    "href": "slides.html#comment-tester-son-code-pour-collecter-le-moins-possible",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Comment tester son code pour collecter le moins possible ?",
    "text": "Comment tester son code pour collecter le moins possible ?\nLa programmation en spark doit √™tre adapt√©e aux contraintes de volum√©trie des donn√©es : test de chaque √©tape, puis ne forcer le calcul qu‚Äô√† la fin pour que Catalyst optimise l‚Äôensemble du programme\nLa principale diff√©rence avec la programmation en R classique est que la visualisation de tables compl√®tes volumineuses n‚Äôest pas recommand√©e :\n\ngoulets d‚Äô√©tranglement m√™me avec spark, car toutes les donn√©es sont rapatri√©es vers le driver puis vers la session R ;\nlongue : √©change entre tous les noeuds impliqu√©s dans le calcul et le driver, puis un √©change driver-session R ;\nbeaucoup moins efficace que l‚Äôexport direct en parquet du r√©sultat (presque instantann√©) : charger ensuite sa table finale en data frame R classique pour effectuer l‚Äô√©tude.\n\nS‚Äôil est n√©cessaire de collecter, il faut pr√©voir beaucoup de RAM pour le driver avec le param√®tre spark.driver.memory."
  },
  {
    "objectID": "slides.html#sparkui-un-outil-doptimisation",
    "href": "slides.html#sparkui-un-outil-doptimisation",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "SparkUI : un outil d‚Äôoptimisation",
    "text": "SparkUI : un outil d‚Äôoptimisation\nSpark UI permet de consulter le plan logique et physique du traitement demand√©. Trois outils permettent d‚Äôoptimiser les traitements :\n\nDAGGCM√©moire\n\n\n\n\n\nV√©rifier que le gc time est inf√©rieur √† 10% du temps pour ex√©cuter la t√¢che ‚úÖ\n\n\n\nV√©rifier que la storage memory ne sature pas la m√©moire ‚úÖ"
  },
  {
    "objectID": "slides.html#ma-session-ne-sinstancie-jamais",
    "href": "slides.html#ma-session-ne-sinstancie-jamais",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Ma session ne s‚Äôinstancie jamais",
    "text": "Ma session ne s‚Äôinstancie jamais\nSi l‚Äôinstruction sc <- spark_connect(master = \"yarn\", config = conf prend plus de 10 minutes, il est utile d‚Äôouvrir l‚Äôinterface de yarn pour v√©rifier que la file n‚Äôest pas d√©j√† enti√®rement occup√©e. L‚Äôerreur peut ne survenir qu‚Äôau bout d‚Äôune vingtaine de minutes : le job est ACCEPTED dans yarn, ou FAILED si la session n‚Äôa pas pu √™tre instanci√©e par manque de ressources disponibles."
  },
  {
    "objectID": "slides.html#exporter-de-hdfs-au-local-1",
    "href": "slides.html#exporter-de-hdfs-au-local-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Exporter de HDFS au local",
    "text": "Exporter de HDFS au local",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#sparklyr-mode-cluster",
    "href": "slides.html#sparklyr-mode-cluster",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Sparklyr mode cluster",
    "text": "Sparklyr mode cluster",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#un-traitement-peu-co√ªteux-un-traitement-map",
    "href": "slides.html#un-traitement-peu-co√ªteux-un-traitement-map",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Un traitement peu co√ªteux : un traitement MAP",
    "text": "Un traitement peu co√ªteux : un traitement MAP\n\nCe traitement est peu co√ªteux :\n\nchargement d‚Äôune seule colonne en RAM : format parquet orient√© colonnes\npeu de m√©moire d‚Äôex√©cution : R est un langage vectoris√©"
  },
  {
    "objectID": "slides.html#un-traitement-co√ªteux-un-traitement-reduce",
    "href": "slides.html#un-traitement-co√ªteux-un-traitement-reduce",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Un traitement co√ªteux : un traitement REDUCE",
    "text": "Un traitement co√ªteux : un traitement REDUCE\n\nCe traitement n√©cessite :\n\nle chargement de davantage de colonnes en m√©moire vive ;\ndavantage de m√©moire d‚Äôex√©cution pour effectuer l‚Äôintersection (inner_join())."
  },
  {
    "objectID": "slides.html#un-traitement-map-distribu√©",
    "href": "slides.html#un-traitement-map-distribu√©",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Un traitement MAP distribu√©",
    "text": "Un traitement MAP distribu√©\n\nSi les donn√©es sont stock√©es sur diff√©rents ordinateurs :\n\nles calculs peuvent √™tre effectu√©s en parall√®le ;\ngain de temps li√© √† l‚Äôaugmentation des ressources informatiques pour effectuer le calcul et √† la parall√©lisation.\n\nLes traitements MAP se pr√™tent parfaitement au calcul distribu√© et parall√®le."
  },
  {
    "objectID": "slides.html#un-traitement-reduce-distribu√©",
    "href": "slides.html#un-traitement-reduce-distribu√©",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Un traitement REDUCE distribu√©",
    "text": "Un traitement REDUCE distribu√©\n\nSi les donn√©es sont stock√©es sur diff√©rents ordinateurs :\n\nil faut les rappatrier au m√™me endroit pour effectuer la jointure ;\ncet √©change est effectu√© en r√©seau entre les ordinateurs : l‚Äôenvoi r√©seau a un co√ªt non n√©gligeable en temps.\n\nLes traitements REDUCE ne se pr√™tent pas bien au calcul distribu√© et parall√®le."
  },
  {
    "objectID": "slides.html#la-machine-virtuelle-java",
    "href": "slides.html#la-machine-virtuelle-java",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La machine virtuelle Java",
    "text": "La machine virtuelle Java\nSpark est r√©dig√© en scala, un langage qui a besoin d‚Äôune machine virtuelle Java pour √™tre ex√©cut√©. La machine virtuelle Java est scalable : l‚Äôutilisateur peut choisir quelles ressources physiques elle a le droit d‚Äôutiliser sur l‚Äôensemble des ressources physiques disponibles sur l‚Äôordinateur. C‚Äôest un mini ordinateur cr√©√© par spark √† l‚Äôint√©rieur de notre propre ordinateur, qui utilise les ressources de ce dernier.\n\n\n\n\n\n\nMachine virtuelle\n\n\nUne machine virtuelle a les m√™mes caract√©ristiques qu‚Äôun ordinateur :\n\nun syst√®me d‚Äôexploitation : Windows, Linux, MacOS\ndes ressources physiques : CPU, RAM et stockage disque\n\nLa diff√©rence avec un ordinateur : une machine virtuelle peut √™tre cr√©√©e sur un serveur physique en r√©servant une petite partie des ressources du serveur seulement, ce qui permet de cr√©er plusieurs ordinateurs diff√©rents sur une seule infractructure physique"
  },
  {
    "objectID": "slides.html#deux-mani√®res-dutiliser-spark",
    "href": "slides.html#deux-mani√®res-dutiliser-spark",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Deux mani√®res d‚Äôutiliser Spark",
    "text": "Deux mani√®res d‚Äôutiliser Spark\n\n\nAvec un seul ordinateur\nCe mode est appel√© Spark local.\n\nune unique machine virtuelle Java est cr√©√©e pour ex√©cuter le code spark\nt√¢ches parall√©lis√©es sur les diff√©rents coeurs (CPU) du processeur de la machine virtuelle Java\nl‚Äôordinateur sur lequel est cr√©√©e cette machine virtuelle Java est la bulle MiDARES, √©quivalent d‚Äôun unique gros ordinateur\n\n\nSur un cluster de calcul\nUn cluster de calcul est un ensemble d‚Äôordinateurs ou machines virtuelles connect√©s en r√©seau.\n\nune machine virtuelle Java est cr√©√©e par spark dans chaque ordinateur du cluster\nt√¢ches parall√©lis√©es sur les diff√©rents ordinateurs du cluster\nla session R reste sur la bulle MiDARES, le code R est traduit en scala puis envoy√© sur le cluster pour √™tre ex√©cut√©."
  },
  {
    "objectID": "slides.html#mode-local-sch√©ma",
    "href": "slides.html#mode-local-sch√©ma",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mode local : sch√©ma",
    "text": "Mode local : sch√©ma"
  },
  {
    "objectID": "slides.html#mode-local-√†-√©viter",
    "href": "slides.html#mode-local-√†-√©viter",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mode local : √† √©viter",
    "text": "Mode local : √† √©viter\nEn mode local :\n\nles ressources utilis√©es par la machine virtuelle sont celles de la bulle\nil faut allouer suffisamment de coeurs √† la JVM pour parall√©liser\nm√™me si l‚Äôutilisateur choisit des ressources faibles, les ressources r√©elles utilis√©es dans une session spark peuvent √™tre plus √©lev√©es : mauvaise gestion de l‚Äôallocation des ressources\nacc√©l√©ration sensible par rapport √† un mode de programmation classique s√©quentiel sur un unique coeur si beaucoup de ressources\nSur la bulle CASD, mauvaise gestion de la r√©partition des ressources en spark local : l‚Äôutilisation simultan√©e de spark par plusieurs membres de la bulle entra√Ænent des ralentissements consid√©rables\n‚ñ∂Ô∏èmode local √† √©viter absolument"
  },
  {
    "objectID": "slides.html#le-cluster-de-calcul-midares-pr√©sentation",
    "href": "slides.html#le-cluster-de-calcul-midares-pr√©sentation",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le cluster de calcul Midares : pr√©sentation",
    "text": "Le cluster de calcul Midares : pr√©sentation"
  },
  {
    "objectID": "slides.html#se-connecter-√†-spark-sur-un-cluster",
    "href": "slides.html#se-connecter-√†-spark-sur-un-cluster",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Se connecter √† Spark sur un cluster",
    "text": "Se connecter √† Spark sur un cluster\nSe connecter √† spark revient √† demander √† spark de cr√©er toutes les JVM demand√©es capables de lire du scala.\nPour se connecter √† spark depuis R avec le package sparklyr :\n\nlibrary(sparklyr)\n\nconf <- spark_config()\nconf$spark.executor.instances <- 5\nsc <- spark_connect(master = \"yarn\", config = conf)\n\nLe param√®tre spark.executor.instances correspond au nombre d‚Äôordinateurs sur lequel on souhaite parall√©liser le travail d‚Äôex√©cution de code. Ici, l‚Äôutilisateur demande 5 ordinateurs du cluster.\nNous verrons plus loin quels param√®tres nous devons pr√©ciser dans le fichier de configuration."
  },
  {
    "objectID": "slides.html#une-connexion",
    "href": "slides.html#une-connexion",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Une connexion",
    "text": "Une connexion\nToutes les JVM demand√©es (5) sont instanci√©es dans les ordinateurs du cluster, avec les param√®tres d√©finis."
  },
  {
    "objectID": "slides.html#la-vie-dun-programme-r√©dig√©-en-sparklyr",
    "href": "slides.html#la-vie-dun-programme-r√©dig√©-en-sparklyr",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La vie d‚Äôun programme r√©dig√© en sparklyr",
    "text": "La vie d‚Äôun programme r√©dig√© en sparklyr\nAvec sparklyr, il est possible de programmer directement en dplyr pour utiliser spark.\n\n# un data frame que j'envoie dans spark\nun_df <- data.frame(c(1,2,3), c(\"A\", \"B\", \"C\"))\nnames(un_df) <- c(\"col_num\", \"col_char\")\n\n# C'est maintenant un spark_data_frame\ncopy_to(sc, un_df)\n    \nun_df_transforme <- un_df %>%\n    mutate(une_nouvelle_col = col_num*2)\n\nSi j‚Äôex√©cute ce programme, je ne pourrai pas ouvrir un_df_transforme, d‚Äôailleurs, il ne se sera rien pass√©."
  },
  {
    "objectID": "slides.html#la-vie-dun-programme-r√©dig√©-en-sparklyr-1",
    "href": "slides.html#la-vie-dun-programme-r√©dig√©-en-sparklyr-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La vie d‚Äôun programme r√©dig√© en sparklyr",
    "text": "La vie d‚Äôun programme r√©dig√© en sparklyr\nPrenons l‚Äôexemple d‚Äôun programme contenant une action."
  },
  {
    "objectID": "slides.html#le-r√¥le-du-driver",
    "href": "slides.html#le-r√¥le-du-driver",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du driver",
    "text": "Le r√¥le du driver\n\n\nLe programme R est traduit en scala gr√¢ce au package sparklyr\nLe driver √©value le programme, il lit le code scala mais n‚Äôex√©cute rien du tout\nS‚Äôil remarque une erreur, l‚Äôerreur est envoy√©e directement √† l‚Äôutilisateur en session R avant l‚Äôex√©cution du programme : c‚Äôest la force de la lazy evaluation."
  },
  {
    "objectID": "slides.html#le-r√¥le-du-driver-catalyst",
    "href": "slides.html#le-r√¥le-du-driver-catalyst",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du driver : Catalyst",
    "text": "Le r√¥le du driver : Catalyst\nLe driver contient un programme nomm√© Catalyst qui optimise le code scala automatiquement.\nSpark optimise automatiquement les programmes soumis :\n\nCompilation des transformations pour soulever les √©ventuelles erreurs\nInt√©gration dans un plan d‚Äôex√©cution contenant les √©tapes n√©cessaires pour parvenir au r√©sultat demand√© par le programme\nOptimisation du plan logique par le module Catalyst (driver Spark)\n\nPar exemple si j‚Äô√©cris le programme :\n\nnon_optimal <- table_1 %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))\n\nCatalyst r√©√©crit :\n\noptimal <- table_1 %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\")) %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))\n\nCette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu‚Äôune action d√©clenche l‚Äôex√©cution."
  },
  {
    "objectID": "slides.html#le-r√¥le-du-cluster-manager",
    "href": "slides.html#le-r√¥le-du-cluster-manager",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du cluster manager",
    "text": "Le r√¥le du cluster manager\n\nLe cluster manager distribue les traitements physiques aux ordinateurs du cluster :\n\nil conna√Æt le meilleur plan physique fourni par Catalyst ;\nil conna√Æt les ressources disponibles et occup√©es par toutes les machines du cluster ;\nil affecte les ressources disponibles √† la session spark."
  },
  {
    "objectID": "slides.html#le-r√¥le-du-worker",
    "href": "slides.html#le-r√¥le-du-worker",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du worker",
    "text": "Le r√¥le du worker\n\nLe worker effectue le morceau de programme qu‚Äôon lui affecte et renvoie le r√©sultat au driver, qui lui-m√™me affiche le r√©sultat en session R :\n\nil ne conna√Æt que les t√¢ches qu‚Äôon lui a affect√©es ;\nil peut communiquer avec le driver en r√©seau pour renvoyer un r√©sultat ;\nil peut communiquer avec les autres workers en r√©seau pour partager des donn√©es ou des r√©sultats interm√©diaires : c‚Äôest un shuffle."
  },
  {
    "objectID": "slides.html#o√π-sont-les-donn√©es",
    "href": "slides.html#o√π-sont-les-donn√©es",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "O√π sont les donn√©es ?",
    "text": "O√π sont les donn√©es ?"
  },
  {
    "objectID": "slides.html#transfert-de-la-bulle-√†-hdfs",
    "href": "slides.html#transfert-de-la-bulle-√†-hdfs",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Transfert de la bulle √† HDFS",
    "text": "Transfert de la bulle √† HDFS"
  },
  {
    "objectID": "slides.html#transfert-de-hdfs-√†-la-bulle",
    "href": "slides.html#transfert-de-hdfs-√†-la-bulle",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Transfert de HDFS √† la bulle",
    "text": "Transfert de HDFS √† la bulle"
  },
  {
    "objectID": "slides.html#mais-o√π-sont-r√©ellement-les-donn√©es-hdfs",
    "href": "slides.html#mais-o√π-sont-r√©ellement-les-donn√©es-hdfs",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mais o√π sont r√©ellement les donn√©es ? HDFS",
    "text": "Mais o√π sont r√©ellement les donn√©es ? HDFS\nHadoop Distributed File System (HDFS)\n\nstockage sur diff√©rentes machines : ici les noeuds du cluster spark, c‚Äôest-√†-dire les diff√©rents ordinateurs workers du cluster\ndonn√©es divis√©es en blocs plus petits de taille fixe et r√©partis sur les machines : aucune table de MiDAS n‚Äôexiste en entier sur le cluster\nchaque bloc est r√©pliqu√© trois fois : il existe trois fois les 10 premi√®res lignes de la table FNA sur trois ordinateurs diff√©rents du cluster (r√©silience)\nun NameNode supervise les m√©tadonn√©es et g√®re la structure du syst√®me de fichiers\nles DataNodes stockent effectivement les blocs de donn√©es : les datanodes sont en fait les disques des workers du cluster, chaque ordinateur du cluster dispose d‚Äôun disque avec une partie des donn√©es MiDAS\nle syst√®me HDFS est reli√© √† la bulle Midares : possible de charger des donn√©es en clique-bouton de la bulle vers HDFS de mani√®re tr√®s rapide et de t√©l√©charger des tables de HDFS pour les r√©cup√©rer en local"
  },
  {
    "objectID": "slides.html#param√©trer-sa-session",
    "href": "slides.html#param√©trer-sa-session",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Param√©trer sa session",
    "text": "Param√©trer sa session\nIl faut pr√©ciser quelles ressources r√©server pour chaque unit√© spark : le driver, le nombre d‚Äôordinateurs workers (appel√©es instances), la RAM, le nombre de coeurs\nLa configuration par d√©faut est :\nIl est n√©cessaire de configurer la session spark pour √©tablir une connexion entre la session R et un cluster spark. Les param√®tres √† d√©finir sont :\n\nLes ressources physiques utilis√©es :\n\npar le driver : avec spark.driver.memory (avec parcimonie)\npar chaque worker avec spark.executor.memory(valeur max 140 Go) et spark.executor.cores (valeur max 8 coeurs)\nle nombre de workers avec spark.executor.instances (2 ou 3 suffisent)\nLa file sur laquelle on travaille avec spark.yarn.queue (prod ou dev)\n\nle nombre de partitions de chaque spark_data_frame avec spark.sql.shuffle.partitions (200 par d√©faut)\nla limite de taille des r√©sulats qui peuvent √™tre collect√©s par le driver avec spark.driver.maxResultSize (0 est la meilleure option)\n\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"40Go\"\nconf[\"spark.executor.memory\"] <- \"60Go\"\nconf[\"spark.executor.cores\"] <- 4\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)"
  },
  {
    "objectID": "slides.html#mode-cluster-non-concurrence-gr√¢ce-au-cluster-manager",
    "href": "slides.html#mode-cluster-non-concurrence-gr√¢ce-au-cluster-manager",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mode cluster : non concurrence gr√¢ce au cluster manager",
    "text": "Mode cluster : non concurrence gr√¢ce au cluster manager\n\nLe mode cluster permet une r√©elle distribution sur diff√©rents noeuds, qui sont en fait des ordinateurs distincts d‚Äôun serveur. Ces machines communiquent en r√©seau.\nCapture d‚Äô√©cran r√©servation des ressources\nIl est donc n√©cessaire de se d√©connecter pour lib√©rer les ressources : des ressources r√©serv√©es, m√™me lorsqu‚Äôaucun programme ne tourne, ne peuvent jamais √™tre affect√©es √† d‚Äôautres utilisateurs."
  },
  {
    "objectID": "slides.html#importer-les-donn√©es-depuis-hdfs-sous-r",
    "href": "slides.html#importer-les-donn√©es-depuis-hdfs-sous-r",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Importer les donn√©es depuis HDFS sous R",
    "text": "Importer les donn√©es depuis HDFS sous R\nLes donn√©es doivent √™tre disponibles dans les workers sous forme de spark_data_frame :\n\ncach√© en m√©moire directement : si utilis√©es de tr√®s nombreuses fois pour gagner du temps\nlaiss√© sur disque tant qu‚Äôaucune action ne d√©clenche un traitement qui n√©cessite son chargement en m√©moire\n‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : avec la configuration pr√©sent√©e, le chargement du FNA, du FHS et des MMO prend au moins 25 minutes.\nPour passer un data.frame R en spark_data_frame : copy_to()\n\n\npjc_df_spark <- spark_read_parquet(sc,\n                                  path = \"hdfs:///dataset/MiDAS_v4/FNA/pjc.parquet\",\n                                  memory = TRUE)\n\npjc_filtree <- pjc_df_spark %>%\n  filter(KDDPJ >= as.Date(\"2022-01-01\"))\n\nspark_write_parquet(pjc_filtree, \"hdfs:///tmp/pjc_filtree.parquet\")\n\npjc_df_spark <- copy_to(sc, \"PJC\")"
  },
  {
    "objectID": "slides.html#les-exports-sur-hdfs",
    "href": "slides.html#les-exports-sur-hdfs",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Les exports sur HDFS",
    "text": "Les exports sur HDFS\n\n\n\n\n\n\nLes exports sur HDFS\n\n\nLorsqu‚Äôon exporte une table depuis notre session R vers HDFS, celle-ci est automatiquement partitionn√©e, comme le reste des donn√©es.\nAinsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.\nIl est possible de ma√Ætriser le nombre de partitions avec la commande sdf_coalesce(partitions = 5) du package sparklyr.\nL‚Äôid√©al est d‚Äôadapter le nombre de partitions √† la taille d‚Äôun bloc : un bloc mesure 128 MB. Lorsqu‚Äôun bloc disque est utilis√©, m√™me √† 1%, il n‚Äôest pas utilisable pour un autre stockage.\nExporter un fichier de 1MB en 200 partitions r√©serve 200 blocs inutilement."
  },
  {
    "objectID": "slides.html#spark-1",
    "href": "slides.html#spark-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Spark",
    "text": "Spark\nacc√©l√©ration : MAP\nProbl√®me : REDUCE, exports longs",
    "crumbs": [
      "Slides"
    ]
  },
  {
    "objectID": "slides.html#les-shuffles",
    "href": "slides.html#les-shuffles",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Les shuffles",
    "text": "Les shuffles\n\nComme nous l‚Äôavons vu, les traitements REDUCE ne se pr√™tent pas tr√®s bien au calcul distribu√© :\n\naugmenter le nombre de workers augmente la probabilit√© de devoir effectuer des shuffles\nil est recommand√© de se limiter √† deux workers comme dans la configuration propos√©e\nr√©server d‚Äôautres ressources n‚Äôest souvent pas efficient et monopolise les ressources pour les autres utilisateurs."
  },
  {
    "objectID": "slides.html#le-r√¥le-du-driver-catalyst-1",
    "href": "slides.html#le-r√¥le-du-driver-catalyst-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du driver : Catalyst",
    "text": "Le r√¥le du driver : Catalyst"
  },
  {
    "objectID": "slides.html#le-r√¥le-du-driver-catalyst-2",
    "href": "slides.html#le-r√¥le-du-driver-catalyst-2",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du driver : Catalyst",
    "text": "Le r√¥le du driver : Catalyst\n\nR√©alisation de plans physiques possibles et s√©lection du meilleur plan physique (au regard de la localisation des donn√©es requises). Le plan physique est la distribution des diff√©rents calculs aux machines du cluster.\nD√©clencher le moins d‚Äôactions possibles dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.\nPour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique."
  },
  {
    "objectID": "slides.html#o√π-sont-les-donn√©es-1",
    "href": "slides.html#o√π-sont-les-donn√©es-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "O√π sont les donn√©es ?",
    "text": "O√π sont les donn√©es ?"
  },
  {
    "objectID": "slides_v.html#au-programme",
    "href": "slides_v.html#au-programme",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Au programme",
    "text": "Au programme\n\nMiDAS : une base de donn√©es volumineuse\nUtiliser MiDAS avec R : un d√©fi\nSparklyr : l‚Äôoutil ergonomique de spark en R\nOptimiser la m√©moire : pourquoi et comment\nLes bonnes pratiques\nPour aller plus loin"
  },
  {
    "objectID": "slides_v.html#quest-ce-que-midas",
    "href": "slides_v.html#quest-ce-que-midas",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Qu‚Äôest-ce que MiDAS ?",
    "text": "Qu‚Äôest-ce que MiDAS ?"
  },
  {
    "objectID": "slides_v.html#une-des-bases-les-plus-volumineuses-du-ssp",
    "href": "slides_v.html#une-des-bases-les-plus-volumineuses-du-ssp",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Une des bases les plus volumineuses du SSP",
    "text": "Une des bases les plus volumineuses du SSP\n\nLes administrations dont les donn√©es sont comparables √† MiDAS utilisent un cluster Spark : Insee, Drees, Acoss‚Ä¶\n‚ñ∂Ô∏èLe cluster spark est une solution la tr√®s efficiente pour traiter des donn√©es de cette ampleur."
  },
  {
    "objectID": "slides_v.html#concr√®tement-quest-ce-que-midas",
    "href": "slides_v.html#concr√®tement-quest-ce-que-midas",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Concr√®tement, qu‚Äôest-ce que MiDAS ?",
    "text": "Concr√®tement, qu‚Äôest-ce que MiDAS ?\n\n\n\n\n\n\n\nPourquoi Spark ?\n\n\nLa manipulation des donn√©es MiDAS en l‚Äô√©tat implique de nombreuses op√©rations de jointures qui n√©cessitent une puissance de calcul et un temps certains."
  },
  {
    "objectID": "slides_v.html#o√π-est-midas-sur-la-bulle",
    "href": "slides_v.html#o√π-est-midas-sur-la-bulle",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "O√π est MiDAS sur la bulle ?",
    "text": "O√π est MiDAS sur la bulle ?\nDisponible dans l‚Äôespace commun (= Documents publics) : C:\\Users\\Public\\Documents\\MiDAS_parquet\\Vague X\n\nAu format parquet :\n\ncompression efficace des donn√©es : taux de compression de 5 √† 10 par rapport au format csv\norient√© colonnes\nchargement efficace en m√©moire des donn√©es\nstockage partitionn√© des donn√©es avec write_dataset()\ntraiter des donn√©es sur disque\nind√©pendant du logiciel utilis√© : R, python, spark‚Ä¶"
  },
  {
    "objectID": "slides_v.html#la-documentation-en-ligne",
    "href": "slides_v.html#la-documentation-en-ligne",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La documentation en ligne",
    "text": "La documentation en ligne\n\n\n\nDocumentation en ligne\n\nDictionnaire des donn√©es\nFiches pr√©sentant les concepts de l‚Äôindemnisation, du retour √† l‚Äôemploi\nExemples d‚Äôimpl√©mentation en R\nConseils quallit√© des variables"
  },
  {
    "objectID": "slides_v.html#une-bulle-casd",
    "href": "slides_v.html#une-bulle-casd",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Une bulle CASD",
    "text": "Une bulle CASD\nDes ressources partag√©es entre tous les utilsateurs simultan√©s :\n\n512 Go de m√©moire vive (ou RAM) : passage √† 256 Go\nUn processeur (ou CPU) compos√© de 32 coeurs : passage √† 16 coeurs\n\n\n\nBulle CASD = un gros ordinateur partag√© par plusieurs utilisateurs, besoin du voc ordinateur pour comprendre spark"
  },
  {
    "objectID": "slides_v.html#une-bulle-casd-1",
    "href": "slides_v.html#une-bulle-casd-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Une bulle CASD",
    "text": "Une bulle CASD\n\nLa m√©moire viveLe processeur\n\n\nLa m√©moire vive, aussi appel√©e RAM, se distingue de la m√©moire de stockage (disque) :\n\npar sa rapidit√©, notamment pour fournir des donn√©es au processeur pour effectuer des calculs\npar sa volatilit√© (toutes les donn√©es sont perdues si l‚Äôordinateur n‚Äôest plus aliment√©)\npar l‚Äôacc√®s direct aux informations qui y sont stock√©es, quasi instantann√©.\n\n\n\nLe processeur :\n\npermet d‚Äôex√©cuter des t√¢ches et des programmes : convertir un fichier, ex√©cuter un logiciel\nest compos√© d‚Äôun ou de plusieurs coeurs : un coeur ne peut ex√©cuter qu‚Äôune seule t√¢che √† la fois. Si le processeur contient plusieurs coeurs, il peut ex√©cuter autant de t√¢ches en parall√®le qu‚Äôil a de coeurs\nse caract√©rise aussi par sa fr√©quence : elle est globalement proportionnelle au nombre d‚Äôop√©rations qu‚Äôil est capable d‚Äôeffetuer par seconde."
  },
  {
    "objectID": "slides_v.html#traiter-midas-en-r-les-limites",
    "href": "slides_v.html#traiter-midas-en-r-les-limites",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Traiter MiDAS en R : les limites",
    "text": "Traiter MiDAS en R : les limites\n\nCharger les donn√©es en m√©moire vive\n\n\n  path_fna <- \"C:/Users/Public/Documents/MiDAS_parquet/Vague 4/FNA/\"\n  \n  PJC <- read_parquet(paste0(path_fna, \"pjc.parquet\"), memory = TRUE)\n  ODD <- read_parquet(paste0(path_fna, \"odd.parquet\"), memory = TRUE)\n\n\n\nR√©aliser des op√©rations co√ªteuses en ressources\n\n\njointure <- PJC %>%\n  rename(KROD1 = KROD3) %>%\n  left_join(ODD, by = c(\"id_midas\", \"KROD1\"))\n\n\n\n\nLe partage des ressources de la bulle\n\nChaque utilisateur peut mobiliser toutes les ressouces de la bulle.\n\nDonn√©es > RAM et R fonctionne dans la m√©moire vive (pour √ßa que plus rapide que SAS) Jointures co√ªteux : on va voir pourquoi apr√®s tlm sur la m√™me bulle sans allocation des ressources = ralentissements"
  },
  {
    "objectID": "slides_v.html#traitement-l√©ger-versus-traitement-co√ªteux",
    "href": "slides_v.html#traitement-l√©ger-versus-traitement-co√ªteux",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Traitement l√©ger versus traitement co√ªteux",
    "text": "Traitement l√©ger versus traitement co√ªteux\n\nMAPREDUCE\n\n\n\n\n\n\n\nCe traitement est peu co√ªteux :\n\nchargement d‚Äôune seule colonne en RAM : format parquet orient√© colonnes\npeu de m√©moire d‚Äôex√©cution : R est un langage vectoris√©\n\n\n\n\n\n\n\n\nCe traitement n√©cessite :\n\nle chargement de davantage de colonnes en m√©moire vive ;\ndavantage de m√©moire d‚Äôex√©cution pour effectuer l‚Äôintersection (inner_join())."
  },
  {
    "objectID": "slides_v.html#traitement-l√©ger-versus-co√ªteux",
    "href": "slides_v.html#traitement-l√©ger-versus-co√ªteux",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Traitement l√©ger versus co√ªteux",
    "text": "Traitement l√©ger versus co√ªteux\n\nMAP = l√©gerREDUCE = co√ªteuxREDUCE en R\n\n\n\n\n\n\n\n\nCe traitement est peu co√ªteux :\n\nchargement d‚Äôune seule colonne en RAM : format parquet orient√© colonnes\npeu de m√©moire d‚Äôex√©cution : R est un langage vectoris√©\n\n\n\n\n\n\n\n\n\n\nCe traitement n√©cessite :\n\nle chargement de davantage de colonnes en m√©moire vive ;\ndavantage de m√©moire d‚Äôex√©cution pour effectuer l‚Äôintersection (inner_join()).\n\n\n\n\n\nles jointures\nles op√©rations en group_by()\nles op√©rations de tri avec arrange()\ndistinct()\n‚ñ∂Ô∏è Ex√©cution s√©quentielle sur un coeur du processeur + beaucoup de m√©moire vive (donn√©es temporaires)\n‚ñ∂Ô∏è Erreur ‚Äúout of memory‚Äù.\n\n\n\n\n\nParquet orient√© colonne donc ne charge que les colonnes n√©cessaires en m√©moire R vectoris√© : op√©ration appliqu√©e √† tout le vecteur = traitement rapide\nJointure co√ªteuse parce que comparaison ligne √† ligne\nwindow funcions"
  },
  {
    "objectID": "slides_v.html#autres-solutions",
    "href": "slides_v.html#autres-solutions",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Autres solutions",
    "text": "Autres solutions\n\nSAS : lecture/√©criture sur le disque\nMiDAS au format sas >> taille de la m√©moire vive disponible du serveur CASD ‚Äì> format .parquet\nImpossible de charger tout MiDAS en m√©moire vive\nDes solutions existent pour manipuler les donn√©es sous R sans les charger enti√®rement en m√©moire vive :\narrow (avec des requ√™tes dplyr)\nduckDB : recommand√© par le SSPLab pour des donn√©es jusqu‚Äô√† 100Go\n‚ñ∂Ô∏è Insuffisantes pour les traitements les plus co√ªteux sur MiDAS en R : la partie de la m√©moire vive utilis√©e pour stocker les donn√©es correspond √† autant de puissance de calcul indisponible pour les traitements."
  },
  {
    "objectID": "slides_v.html#pourquoi-spark-1",
    "href": "slides_v.html#pourquoi-spark-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Pourquoi spark ?",
    "text": "Pourquoi spark ?\n\n\n\n\n\n\n\n\nSolution test√©e\nAvantage\nLimites rencontr√©e\n\n\n\n\nPackage ¬´ data.table ¬ª\nCalculs parall√©lis√©s\npour bases < RAM\nSyntaxe tr√®s diff√©rente de dplyr\n\n\nFormat ¬´ parquet ¬ª +\npackage ¬´ arrow ¬ª\nStockage moins lourd\nChargement efficient\nTaille en m√©moire inchang√©e\n\n\nDuckDB\nGestionnaire de BDD\nPour des bases < 100 Go\nFonctions et options non cod√©es\n\n\nSpark en mode local\nTraitements distribu√©s\nConsomme beaucoup de ressources\nInadapt√© pour une unique bulle\nN√©cessite le ¬´ collect() ¬ª"
  },
  {
    "objectID": "slides_v.html#pourquoi-spark-2",
    "href": "slides_v.html#pourquoi-spark-2",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Pourquoi spark ?",
    "text": "Pourquoi spark ?\n\n\n\n\n\n\n\n\n\n\nCalcul de la dur√©e moyenne d‚Äôun contrat\nRetour √† l‚Äôemploi salari√© des indemnisables\n\n\n\n\nClassique R\n4 heures\nCrash\n\n\nArrow + duckdb\n8 minutes\n3 heures seul sur la bulle\n\n\nArrow + spark local\n1 minute\n2 minutes"
  },
  {
    "objectID": "slides_v.html#un-gain-de-temps-consid√©rable",
    "href": "slides_v.html#un-gain-de-temps-consid√©rable",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Un gain de temps consid√©rable",
    "text": "Un gain de temps consid√©rable\n\n\n\n\n\n\n\n\n\n\nCalcul de la dur√©e moyenne du premier contrat pour tous les individus MiDAS\nRetour √† l‚Äôemploi salari√© des indemnisables\n\n\n\n\nClassique R\n4 heures\nCrash\n\n\nArrow + duckdb\n8 minutes\n3 heures seul sur la bulle\n\n\nArrow + spark local\n1 minute\n2 minutes\n\n\n\nMais alors, pourquoi le cluster ? ü§î"
  },
  {
    "objectID": "slides_v.html#o√π-est-midas-2√®me-√©dition",
    "href": "slides_v.html#o√π-est-midas-2√®me-√©dition",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "O√π est Midas, 2√®me √©dition",
    "text": "O√π est Midas, 2√®me √©dition\nLe cluster a son propre explorateur de fichiers √† mettre en favori dans son navigateur : https://midares-deb11-nn-01.midares.local:9870/"
  },
  {
    "objectID": "slides_v.html#un-cluster-de-calcul",
    "href": "slides_v.html#un-cluster-de-calcul",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Un cluster de calcul",
    "text": "Un cluster de calcul"
  },
  {
    "objectID": "slides_v.html#connexion",
    "href": "slides_v.html#connexion",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Connexion",
    "text": "Connexion\n\nTraitement l√©gerTraitement lourd\n\n\n\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(dbplyr)\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"20Go\"\nconf[\"spark.executor.memory\"] <- \"60Go\"\nconf[\"spark.executor.cores\"] <- 4\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n\n\n\n\nlibrary(sparklyr)\nlibrary(dplyr)\nlibrary(dbplyr)\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"20Go\"\nconf[\"spark.executor.memory\"] <- \"140Go\"\nconf[\"spark.executor.cores\"] <- 8\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)"
  },
  {
    "objectID": "slides_v.html#sparklyr-cest-comme-dplyr",
    "href": "slides_v.html#sparklyr-cest-comme-dplyr",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Sparklyr, c‚Äôest comme dplyr",
    "text": "Sparklyr, c‚Äôest comme dplyr\n\nEnsuite, vous pouvez programmer avec dplyr !\n\nmmo_17_df_spark <- mmo_17_df_spark %>%\n  rename(debut_contrat = DebutCTT) %>%\n  filter(debut_contrat >= as.Date(\"2017-01-01\") & debut_contrat < as.Date(\"2017-02-01\")) %>%\n  mutate(mois_debut_contrat = substr(debut_contrat,6,7))"
  },
  {
    "objectID": "slides_v.html#enfin-presque",
    "href": "slides_v.html#enfin-presque",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "‚Ä¶ enfin, presque",
    "text": "‚Ä¶ enfin, presque"
  },
  {
    "objectID": "slides_v.html#chargement-des-donn√©es",
    "href": "slides_v.html#chargement-des-donn√©es",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Chargement des donn√©es",
    "text": "Chargement des donn√©es"
  },
  {
    "objectID": "slides_v.html#chargement-des-donn√©es-en-spark",
    "href": "slides_v.html#chargement-des-donn√©es-en-spark",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Chargement des donn√©es en spark",
    "text": "Chargement des donn√©es en spark\n\n\n### Depuis HDFS\nmmo_17_df_spark <- spark_read_parquet(sc,\n                                  path = \"hdfs:///dataset/MiDAS_v4/mmo/mmo_2017.parquet\",\n                                  memory = FALSE)\n\n### Passer un dataframe R en spark\nmon_data_frame <- data.frame(c(\"Anna\", \"Paul\"), c(15, 20))\nmon_data_frame_spark <- copy_to(sc, \"mon_data_frame\")\n\n\n‚ñ∂Ô∏è chargement en m√©moire vive couteux en temps : par d√©faut, memory = FALSE"
  },
  {
    "objectID": "slides_v.html#la-lazy-evaluation",
    "href": "slides_v.html#la-lazy-evaluation",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La lazy evaluation",
    "text": "La lazy evaluation\nSpark distingue deux types d‚Äôop√©rations :\n\nles transformations : prennent en entr√©e un spark_data_frame et retournent un spark_data_frame, elles ne d√©clenchent aucun calcul\nPar exemple, le programme ci-dessous ne d√©clenche pas d‚Äôex√©cution :\n\n\nmmo_17_df_spark_mois <- mmo_17_df_spark %>%\n  rename(debut_contrat = DebutCTT) %>%\n  filter(debut_contrat >= as.Date(\"2017-01-01\") & debut_contrat < as.Date(\"2017-06-01\")) %>%\n  mutate(mois_debut_contrat = substr(debut_contrat,6,7))\n\n\nles actions : forcent le calcul d‚Äôun r√©sultat pour le r√©cup√©rer et d√©clenchent l‚Äôex√©cution de toutes les transformations compil√©es jusqu‚Äô√† l‚Äôappel de l‚Äôaction.\nPar exemple, le programme ci-dessous d√©clenche le calcul de toute la cellule pr√©c√©dente :\n\n\nnb_debut_contrat_fev_17 <- mmo_17_df_spark_mois %>%\n  group_by(mois_debut_contrat) %>%\n  summarise(nb_contrats = n()) %>%\n  print()"
  },
  {
    "objectID": "slides_v.html#r√©cup√©rer-un-r√©sultat",
    "href": "slides_v.html#r√©cup√©rer-un-r√©sultat",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "R√©cup√©rer un r√©sultat",
    "text": "R√©cup√©rer un r√©sultat\nLes principales actions sont :\n\nprint()\ncollect()\nhead()\ntbl_cache() (√©crire un spark_data_frame en m√©moire pour le r√©utiliser)"
  },
  {
    "objectID": "slides_v.html#presque-tout-comme-dplyr",
    "href": "slides_v.html#presque-tout-comme-dplyr",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "‚Ä¶ presque tout comme dplyr",
    "text": "‚Ä¶ presque tout comme dplyr\nLa majorit√© des commandes dplyr fonctionnent sur un spark_data_frame avec le package sparklyr. Les divergences principales sont les suivantes :\n\n\n\n\n\n\n\n\nFonctionnalit√©\ntidyverse\nsparklyr\n\n\n\n\nimport d‚Äôun fichier .parquet\nread_parquet\nspark_read_parquet()\n\n\ntri d‚Äôun tableau\narrange()\nwindow_order() ou sdf_sort()\n\n\nop√©rations sur les dates\nlubridate\nfonctions Hive\n\n\nempiler des tableaux\nbind_rows()\nsdf_bind_rows()\n\n\nnombre de lignes d‚Äôun tableau\nnrow()\nsdf_nrow()\n\n\nfaire pivoter un tableau\ntidyr\nsdf_pivot()\n\n\nexport d‚Äôun spark_data_frame\n\nspark_write_parquet()"
  },
  {
    "objectID": "slides_v.html#exporter-des-donn√©es",
    "href": "slides_v.html#exporter-des-donn√©es",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Exporter des donn√©es",
    "text": "Exporter des donn√©es\nExport des spark data frames directement sous HDFS : √† aucun moment on n‚Äôouvre la table : on peut traiter des donn√©es beaucoup plus volumnieuses que la m√©moire RAM !\n\nma_table <- data.frame(c(\"Anne\", \"Paul\"), c(25,30))\n\nma_table_spark <- copy_to(sc, ma_table)\n\nspark_write_parquet(ma_table_spark, \"hdfs:///resultats/ma_table.parquet\")\n\nPossibilit√© de r√©cup√©rer ce fichier sur la bulle MiDARES = en local.\n\n\n\n\n\n\nExports simultan√©s\n\n\nHDFS supporte les exports simultan√©s, mais le temp d‚Äôexport est plus long lorsque le NameNode est requ√™t√© par plusieurs personnes simultan√©ment : d‚Äôapr√®s les tests cluster\n\npour un petit export (5 minutes), le temps peut √™tre multipli√© par 4 ;\npour un gros export (15 minutes), le temps peut √™tre multipli√© par 2."
  },
  {
    "objectID": "slides_v.html#partitionnement",
    "href": "slides_v.html#partitionnement",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Partitionnement",
    "text": "Partitionnement\nLe format .parquet (avec arrow) et le framework spark permettent de g√©rer le partitionnement des donn√©es.\nSi les op√©rations sont souvent effectu√©es par r√©gions par exemple, il est utile de forcer le stockage des donn√©es d‚Äôune m√™me r√©gion au m√™me endroit physique et acc√©l√®re drastiquement le temps de calcul :\n\nspark_write_parquet(ma_table, \"hdfs:///resultats/ma_table.parquet\", partition_by = c(\"region\"))"
  },
  {
    "objectID": "slides_v.html#t√©l√©charger-des-donn√©es-en-local",
    "href": "slides_v.html#t√©l√©charger-des-donn√©es-en-local",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "T√©l√©charger des donn√©es en local",
    "text": "T√©l√©charger des donn√©es en local"
  },
  {
    "objectID": "slides_v.html#si-on-souhaite-la-r√©cup√©rer-en-local",
    "href": "slides_v.html#si-on-souhaite-la-r√©cup√©rer-en-local",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Si on souhaite la r√©cup√©rer en local",
    "text": "Si on souhaite la r√©cup√©rer en local\n\n\n\n\n\n\nLes exports sur HDFS\n\n\nLorsqu‚Äôon exporte une table depuis notre session R vers HDFS, celle-ci est automatiquement partitionn√©e, comme le reste des donn√©es.\nAinsi, cette table sera stock√©e en plusieurs morceaux sous HDFS et r√©pliqu√©e.\nIl est possible de ma√Ætriser le nombre de partitions avec la commande sdf_coalesce(partitions = 1) du package sparklyr.\nAvec sdf_coalesce(partitions = 1), on n‚Äôaura qu‚Äôun seul fichier √† t√©l√©charger depuis HDFS.\nAvec sdf_coalesce(partitions = 200), on aura 200 morceaux de notre fichier √† t√©l√©charger √† la main (pas possible de faire tout s√©lectionner sous HDFS !).\nL‚Äôid√©al est d‚Äôadapter le nombre de partitions √† la taille d‚Äôun bloc : un bloc mesure 128 MB.\n\n\n\n\nma_table <- data.frame(c(\"Anne\", \"Paul\"), c(25,30))\n\nma_table_spark <- copy_to(sc, ma_table) %>%\n  sdf_coalesce(partitions = 1)\n\nspark_write_parquet(ma_table_spark, \"hdfs:///resultats/ma_table.parquet\")"
  },
  {
    "objectID": "slides_v.html#pas-besoin-doptimiser-son-code",
    "href": "slides_v.html#pas-besoin-doptimiser-son-code",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Pas besoin d‚Äôoptimiser son code !",
    "text": "Pas besoin d‚Äôoptimiser son code !\n\nsource : documentation CASD disponible √† Documentation Data Science"
  },
  {
    "objectID": "slides_v.html#la-m√©moire-du-driver",
    "href": "slides_v.html#la-m√©moire-du-driver",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La m√©moire du driver",
    "text": "La m√©moire du driver"
  },
  {
    "objectID": "slides_v.html#programmer-sans-collecter",
    "href": "slides_v.html#programmer-sans-collecter",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Programmer sans collecter",
    "text": "Programmer sans collecter\nLa programmation en spark doit √™tre adapt√©e aux contraintes de volum√©trie des donn√©es : test de chaque √©tape, puis ne forcer le calcul qu‚Äô√† la fin pour que Catalyst optimise l‚Äôensemble du programme\nLa principale diff√©rence avec la programmation en R classique est que la visualisation de tables compl√®tes volumineuses n‚Äôest pas toujours possible et n‚Äôest pas recommand√©e :\n\ngoulets d‚Äô√©tranglement m√™me avec spark, car toutes les donn√©es sont rapatri√©es vers le driver puis vers la session R : erreurs Out of Memory\nlongue : √©change entre tous les noeuds impliqu√©s dans le calcul et le driver, puis un √©change driver-session R en r√©seau = lent ;\nbeaucoup moins efficace que l‚Äôexport direct en parquet du r√©sultat (qui fonctionne toujours) : charger ensuite sa table finale en data frame R classique pour effectuer l‚Äô√©tude.\n\nS‚Äôil est n√©cessaire de collecter, il faut pr√©voir beaucoup de RAM pour le driver avec le param√®tre spark.driver.memory, ce qui emp√™che les autres utilisateurs de travailler."
  },
  {
    "objectID": "slides_v.html#cacher-une-table",
    "href": "slides_v.html#cacher-une-table",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Cacher une table",
    "text": "Cacher une table"
  },
  {
    "objectID": "slides_v.html#spark-local-non",
    "href": "slides_v.html#spark-local-non",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Spark local : non",
    "text": "Spark local : non"
  },
  {
    "objectID": "slides_v.html#inutile-de-prendre-toutes-les-ressources",
    "href": "slides_v.html#inutile-de-prendre-toutes-les-ressources",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Inutile de prendre toutes les ressources",
    "text": "Inutile de prendre toutes les ressources\n\nComme nous l‚Äôavons vu, les traitements REDUCE ne se pr√™tent pas tr√®s bien au calcul distribu√© :\n\naugmenter le nombre de workers augmente la probabilit√© de devoir effectuer des shuffles\nil est recommand√© de se limiter √† deux workers comme dans la configuration propos√©e\nr√©server d‚Äôautres ressources n‚Äôest souvent pas efficient et monopolise les ressources pour les autres utilisateurs."
  },
  {
    "objectID": "slides_v.html#fermer-sa-session",
    "href": "slides_v.html#fermer-sa-session",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Fermer sa session",
    "text": "Fermer sa session\n\nUne fois les ressources r√©serv√©es, tant que la session R est ouverte, les ressources restent r√©serv√©es √† l‚Äôutilisateur : personne ne peut les prendre\nSi on ne ferme pas sa session, on bloque les autres\nSi une session reste ouverte trop longtemps et bloque les autres, le CASD pourra la ferme √† distance : bien enregistrer ses r√©sultats avant de partir !"
  },
  {
    "objectID": "slides_v.html#mutualiser-les-exp√©riences",
    "href": "slides_v.html#mutualiser-les-exp√©riences",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mutualiser les exp√©riences",
    "text": "Mutualiser les exp√©riences\n\nSessions de passage d‚Äôun code sur le cluster\nContributions √† la documentation MiDAS\nAppeler un coll√®gue si erreur en sparklyr"
  },
  {
    "objectID": "slides_v.html#sparkui",
    "href": "slides_v.html#sparkui",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "SparkUI",
    "text": "SparkUI\nSpark UI permet de consulter le plan logique et physique du traitement demand√©. Trois outils permettent d‚Äôoptimiser les traitements :\n\nDAGGCM√©moire\n\n\n\n\n\nV√©rifier que le gc time est inf√©rieur √† 10% du temps pour ex√©cuter la t√¢che ‚úÖ\n\n\n\nV√©rifier que la storage memory ne sature pas la m√©moire ‚úÖ"
  },
  {
    "objectID": "slides_v.html#yarn",
    "href": "slides_v.html#yarn",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Yarn",
    "text": "Yarn\n\nyarn : disponibilit√© des ressources\n\nSparkhistory pour des traitements de sessions ferm√©es\n\nLe sparkhistory entra√Æne l‚Äôenregistrement de logs assez lourdes, il est donc d√©sactiv√© par d√©faut. Pour l‚Äôactiver sur un programme :\n\nconf <- spark_config()\nconf[\"spark.eventLog.enabled\"] <- \"true\"\nconf[\"spark.eventLog.dir\"] <- \"hdfs://midares-deb11-nn-01.midares.local:9000/spark-logs\"\nconf[\"appName\"] <- \"un_nom_de_traitement\"\n\nsc <- spark_connect(master = \"yarn\", config = conf)"
  },
  {
    "objectID": "slides_v.html#pyspark",
    "href": "slides_v.html#pyspark",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Pyspark",
    "text": "Pyspark"
  },
  {
    "objectID": "slides_v.html#comment-fonctionne-spark",
    "href": "slides_v.html#comment-fonctionne-spark",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Comment fonctionne spark ?",
    "text": "Comment fonctionne spark ?\n\nApache Spark : librairie open source d√©velopp√©e dans le langage scala\n\nval TopHorrorsIGN2022 = Seq(\n  (9, \"Pearl\"),\n  (6, \"The Sadness\"),\n  (6, \"Offseason\"),\n  (7, \"Hatching\"),\n  (8, \"x\")\n).toDF(\"IMDB Rating\", \"IGN Movie Picks\")\n\nimport org.apache.spark.sql.functions.col\n\nval cols = List(col(\"IGN Movie Picks\"), col(\"AVC Movie Picks\"))\n\nval query = TopHorrorsIGN2022(\n  \"IGN Movie Picks\"\n) === TopHorrorsTheAVClub2022(\"AVC Movie Picks\")\n\nval outerJoin = TopHorrorsIGN2022\n  .join(TopHorrorsTheAVClub2022, query, \"outer\")\n  .select(cols: _*)\n\nouterJoin.show()\n\nscala adapt√© pour ma√Ætriser toutes les fonctionnalit√©s de spark et optimiser au maximum les traitements en spark\nspark est compatible avec les langages scala, R, python, java, et peut interpr√©ter des commandes SQL."
  },
  {
    "objectID": "slides_v.html#calcul-distribu√©-calcul-parall√®le",
    "href": "slides_v.html#calcul-distribu√©-calcul-parall√®le",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Calcul distribu√©, calcul parall√®le",
    "text": "Calcul distribu√©, calcul parall√®le"
  },
  {
    "objectID": "slides_v.html#le-r√¥le-du-driver",
    "href": "slides_v.html#le-r√¥le-du-driver",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du driver",
    "text": "Le r√¥le du driver"
  },
  {
    "objectID": "slides_v.html#le-plan-dex√©cution",
    "href": "slides_v.html#le-plan-dex√©cution",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le plan d‚Äôex√©cution",
    "text": "Le plan d‚Äôex√©cution\n\nsource : documentation CASD disponible √† Documentation Data Science\nAJOUTER UN DAG"
  },
  {
    "objectID": "slides_v.html#le-r√¥le-du-driver-catalyst",
    "href": "slides_v.html#le-r√¥le-du-driver-catalyst",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du driver : Catalyst",
    "text": "Le r√¥le du driver : Catalyst\nLe driver contient un programme nomm√© Catalyst qui optimise le code scala automatiquement.\nSpark optimise automatiquement les programmes soumis :\n\nCompilation des transformations pour soulever les √©ventuelles erreurs\nInt√©gration dans un plan d‚Äôex√©cution contenant les √©tapes n√©cessaires pour parvenir au r√©sultat demand√© par le programme\nOptimisation du plan logique par le module Catalyst (driver Spark)\n\nPar exemple si j‚Äô√©cris le programme :\n\nnon_optimal <- table_1 %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))\n\nCatalyst r√©√©crit :\n\noptimal <- table_1 %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\")) %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))\n\nCette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu‚Äôune action d√©clenche l‚Äôex√©cution."
  },
  {
    "objectID": "slides_v.html#le-r√¥le-du-driver-catalyst-1",
    "href": "slides_v.html#le-r√¥le-du-driver-catalyst-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du driver : Catalyst",
    "text": "Le r√¥le du driver : Catalyst"
  },
  {
    "objectID": "slides_v.html#le-r√¥le-du-driver-catalyst-2",
    "href": "slides_v.html#le-r√¥le-du-driver-catalyst-2",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du driver : Catalyst",
    "text": "Le r√¥le du driver : Catalyst\n\nR√©alisation de plans physiques possibles et s√©lection du meilleur plan physique (au regard de la localisation des donn√©es requises). Le plan physique est la distribution des diff√©rents calculs aux machines du cluster.\nD√©clencher le moins d‚Äôactions possibles dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.\nPour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique."
  },
  {
    "objectID": "slides_v.html#lutilisation-de-la-m√©moire-du-driver",
    "href": "slides_v.html#lutilisation-de-la-m√©moire-du-driver",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "L‚Äôutilisation de la m√©moire du driver",
    "text": "L‚Äôutilisation de la m√©moire du driver\nLorsqu‚Äôil est n√©cessaire de collecter une table volumineuse, il faut donc pr√©voir assez de m√©moire RAM pour le driver : tous les r√©sultats sont rappatri√©s vers le driver.\n\nconf <- spark_config()\nconf[\"spark.driver.memory\"] <- \"20Go\"\nconf[\"spark.executor.memory\"] <- \"80Go\"\nconf[\"spark.executor.cores\"] <- 5\nconf[\"spark.executor.instances\"] <- 2\ncont[\"spark.yarn.queue\"] <- \"prod\"\nconf[\"spark.driver.maxResultSize\"] <- 0\nconf[\"spark.sql.shuffle.partitions\"] <- 200\n\nsc <- spark_connect(master = \"yarn\", config = conf)\n\n\n\n\n\n\n\nBonne pratique de partage des ressources\n\n\nLe driver est dans la bulle Midares, qui a vocation √† √™tre r√©duite suite √† la g√©n√©ralisation du cluster.\n\nLa bulle Midares a besoin de RAM pour fonctionner, 100% des ressources ne sont donc pas disponibles pour sparklyr.\nPour permettre le travail simultan√© fluide de 10 utilisateurs, la m√©moire allou√©e au driver recommand√©e pour chaque utilisateur est de 20 Go.\nIl existe des alternatives pour ne pas collecter des r√©sultats trop volumineux dans le driver."
  },
  {
    "objectID": "slides_v.html#une-bonne-allocation-des-ressources-entre-utilisateurs",
    "href": "slides_v.html#une-bonne-allocation-des-ressources-entre-utilisateurs",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Une bonne allocation des ressources entre utilisateurs",
    "text": "Une bonne allocation des ressources entre utilisateurs"
  },
  {
    "objectID": "slides_v.html#quelques-fonctions-sp√©cifiques",
    "href": "slides_v.html#quelques-fonctions-sp√©cifiques",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Quelques fonctions sp√©cifiques",
    "text": "Quelques fonctions sp√©cifiques\n\nDatesTableauStatistiques\n\n\nLes fonctions de lubridate()ne sont pas adapt√©es au spark_data_frames.\n\nConvertir une cha√Æne de caract√®re de la forme AAAA-MM-DD en Date\n\ndate_1 <- as.Date(\"2024-05-26\")\n\nCalculer une dur√©e entre deux dates\n\nPJC_spark <- spark_read_parquet(sc,\n                                path = \"hdfs:///dataset/MiDAS_v4/pjc.parquet\",\n                                memory = FALSE)\n\nduree_pjc_df <- PJC_spark %>%\n  rename(date_fin_pjc = as.Date(KDFPJ),\n         date_deb_pjc = as.Date(KDDPJ)) %>%\n  mutate(duree_pjc = datediff(date_fin_pjc, date_deb_pjc) + 1) %>%\n  head(5)\n\nAjouter ou soustraire des jours ou des mois √† une date\n\nduree_pjc_bis_df <- duree_pjc_df %>%\n  mutate(duree_pjc_plus_5 = date_add(duree_pjc, int(5)),\n         duree_pjc_moins_5 = date_sub(duree_pjc, int(5)),\n         duree_pjc_plus_1_mois = add_months(duree_pjc, int(1))) %>%\n  head(5)\n\n\n\n\n\n\n\n\nAdd_months\n\n\nSi la date en entr√©e est le dernier jour d‚Äôun mois, la date retourn√©e avec add_months(date_entree, int(1)) sera le dernier jour calendaire du mois suivant.\n\n\n\n\n\n\n\n\n\nFormat\n\n\nLe int() est important car ces fonctions Hive n‚Äôaccepte que les entiers pour l‚Äôajout de jours : taper uniquement 5 est consid√©r√© comme un flottant dans R.\n\n\n\n\n\n\nTri dans un groupe pour effectuer un calcul s√©quentiel\n\nODD_spark <- spark_read_parquet(sc,\n                                path = \"hdfs:///dataset/MiDAS_v4/odd.parquet\",\n                                memory = FALSE)\n\nODD_premier <- ODD_spark %>%\n  group_by(id_midas) %>%\n  window_order(id_midas, KDPOD) %>%\n  mutate(date_premier_droit = first(KDPOD)) %>%\n  ungroup() %>%\n  distinct(id_midas, KROD3, date_premier_droit) %>%\n  head(5)\n\nTri pour une sortie : sdf_sort() , arrange() ne fonctionne pas\nConcat√©ner les lignes (ou les colonnes sdf_bind_cols())\n\nODD_1 <- ODD_spark %>%\n  filter(KDPOD <= as.Date(\"2017-12-31\")) %>%\n  mutate(groupe = \"temoins\")\n\nODD_2 <- ODD_spark %>%\n  filter(KDPOD >= as.Date(\"2021-12-31\")) %>%\n  mutate(groupe = \"traites\")\n\nODD_evaluation <- sdf_bind_rows(ODD_1, ODD_2)\n\nD√©doublonner une table\n\ndroits_dans_PJC <- PJC_spark %>%\n  sdf_distinct(id_midas, KROD3)\n\nprint(head(droits_dans_PJC, 5))\n\nPJC_dedoublonnee <- PJC_spark %>%\n  sdf_drop_duplicates()\n\nprint(head(PJC_dedoublonnee, 5))\n\nPivot : les fonctions du packag tidyr ne fonctionnent pas sur donn√©es spark\n\nODD_sjr_moyen <- ODD_spark %>%\n  mutate(groupe = ifelse(KDPOD <= as.Date(\"2020-12-31\"), \"controles\", \"traites\")) %>%\n  sdf_pivot(groupe ~ KCRGC,\n    fun.aggregate = list(KQCSJP = \"mean\")\n  )\n\n\n\n\n\nR√©sum√© statistique : sdf_describe() , summary()ne fonctionne pas.\nDimension : sdf_dim, la fonction nrow()ne fonctionne pas.\nQuantiles approximatifs : le calcul des quantiles sur donn√©es distirbu√©es renvoie une approximation car toutes les donn√©es ne peuvent pas √™tre rappatri√©es sur la m√™me machine physique du fait de la volum√©trie, sdf_quantile()\nEchantillonnage al√©atoire : sdf_random_split"
  },
  {
    "objectID": "slides_v.html#le-driver-en-sparklyr",
    "href": "slides_v.html#le-driver-en-sparklyr",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le driver en sparklyr",
    "text": "Le driver en sparklyr\n\n\nLe programme R est traduit en scala gr√¢ce au package sparklyr\nLe driver √©value le programme, il lit le code scala mais n‚Äôex√©cute rien du tout\nS‚Äôil remarque une erreur, l‚Äôerreur est envoy√©e directement √† l‚Äôutilisateur en session R avant l‚Äôex√©cution du programme : c‚Äôest la force de la lazy evaluation."
  },
  {
    "objectID": "slides_v.html#la-lazy-evaluation-un-gain-de-temps-consid√©rable",
    "href": "slides_v.html#la-lazy-evaluation-un-gain-de-temps-consid√©rable",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "La lazy evaluation : un gain de temps consid√©rable",
    "text": "La lazy evaluation : un gain de temps consid√©rable\n\n\n\n\n\n\n\nLa gestion des erreurs\n\n\nEn r√©alit√©, lorsqu‚Äôon appuie ysur le bouton run, il ne se passe pas ‚Äúrien‚Äù. Le code est compil√© par spark : les erreurs sont rep√©r√©es avant m√™me que le code soit ex√©cut√© !\n\n\n\nINSERER EXEMPLE ERREUR REPEREE A LA COMPILATION"
  },
  {
    "objectID": "slides_v.html#catalyst-optimise-notre-code-pour-nous",
    "href": "slides_v.html#catalyst-optimise-notre-code-pour-nous",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Catalyst optimise notre code pour nous",
    "text": "Catalyst optimise notre code pour nous\nLe driver contient un programme nomm√© Catalyst qui optimise le code scala automatiquement.\nSpark optimise automatiquement les programmes soumis :\n\nCompilation des transformations pour soulever les √©ventuelles erreurs\nInt√©gration dans un plan d‚Äôex√©cution contenant les √©tapes n√©cessaires pour parvenir au r√©sultat demand√© par le programme\nOptimisation du plan logique par le module Catalyst (driver Spark)\n\n\n\n\n\n\n\nLes erreurs en sparklyr\n\n\nPetite pr√©cision sur les erreurs :\n\nsparklyr traduit le code R en scala\nmais √©galement les messages envoy√©s par spark en R\nles erreurs affich√©es en R ne sont pas toujours bien interpr√©tables"
  },
  {
    "objectID": "slides_v.html#catalyst-optimise-notre-code-pour-nous-1",
    "href": "slides_v.html#catalyst-optimise-notre-code-pour-nous-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Catalyst optimise notre code pour nous",
    "text": "Catalyst optimise notre code pour nous\nPar exemple si j‚Äô√©cris le programme :\n\nnon_optimal <- table_1 %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))\n\nCatalyst r√©√©crit :\n\noptimal <- table_1 %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\")) %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))\n\nCette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu‚Äôune action d√©clenche l‚Äôex√©cution."
  },
  {
    "objectID": "slides_v.html#catalyst-optimise-notre-code-pour-nous-2",
    "href": "slides_v.html#catalyst-optimise-notre-code-pour-nous-2",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Catalyst optimise notre code pour nous",
    "text": "Catalyst optimise notre code pour nous"
  },
  {
    "objectID": "slides_v.html#catalyst-optimise-notre-code-pour-nous-laissons-le-travailler",
    "href": "slides_v.html#catalyst-optimise-notre-code-pour-nous-laissons-le-travailler",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Catalyst optimise notre code pour nous : laissons-le travailler !",
    "text": "Catalyst optimise notre code pour nous : laissons-le travailler !\nD√©clencher le moins d‚Äôactions possibles dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.\nPour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique."
  },
  {
    "objectID": "slides_v.html#calcul-distribu√©-et-r√©cup√©ration-des-r√©sultats",
    "href": "slides_v.html#calcul-distribu√©-et-r√©cup√©ration-des-r√©sultats",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Calcul distribu√© et r√©cup√©ration des r√©sultats",
    "text": "Calcul distribu√© et r√©cup√©ration des r√©sultats\n\n\n\n\n\n\n\nLe r√©seau\n\n\n\nLes workers communiquent avec le driver de la bulle MiDARES en r√©seau\nLes workers communiquent entre eux en r√©seau pour s‚Äô√©changer des donn√©es\nLe r√©seau est un mode de communication lent\n\n\n\n\n\nMtn un peu de th√©orie pour comprendre le calcul distribu√© et mieux l‚Äôutiliser"
  },
  {
    "objectID": "slides_v.html#le-stockage-distribu√©-avec-hdfs",
    "href": "slides_v.html#le-stockage-distribu√©-avec-hdfs",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le stockage distribu√© avec HDFS",
    "text": "Le stockage distribu√© avec HDFS"
  },
  {
    "objectID": "slides_v.html#le-r√¥le-du-cluster-manager",
    "href": "slides_v.html#le-r√¥le-du-cluster-manager",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du cluster manager",
    "text": "Le r√¥le du cluster manager\n\nLe cluster manager distribue les traitements physiques aux ordinateurs du cluster :\n\nil conna√Æt le meilleur plan physique fourni par Catalyst ;\nil conna√Æt les ressources disponibles et occup√©es par toutes les machines du cluster ;\nil affecte les ressources disponibles √† la session spark."
  },
  {
    "objectID": "slides_v.html#le-r√¥le-du-worker",
    "href": "slides_v.html#le-r√¥le-du-worker",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le r√¥le du worker",
    "text": "Le r√¥le du worker\n\nLe worker effectue le morceau de programme qu‚Äôon lui affecte :\n\nil ne conna√Æt que les t√¢ches qu‚Äôon lui a affect√©es ;\nil peut communiquer avec le driver en r√©seau pour renvoyer un r√©sultat ;\nil peut communiquer avec les autres workers en r√©seau pour partager des donn√©es ou des r√©sultats interm√©diaires : c‚Äôest un shuffle."
  },
  {
    "objectID": "slides_v.html#traitement-map-distribu√©",
    "href": "slides_v.html#traitement-map-distribu√©",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Traitement MAP distribu√©",
    "text": "Traitement MAP distribu√©"
  },
  {
    "objectID": "slides_v.html#traitement-reduce-distribu√©",
    "href": "slides_v.html#traitement-reduce-distribu√©",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Traitement REDUCE distribu√©",
    "text": "Traitement REDUCE distribu√©"
  },
  {
    "objectID": "slides_v.html#programmer-sans-collecter-1",
    "href": "slides_v.html#programmer-sans-collecter-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Programmer sans collecter",
    "text": "Programmer sans collecter\nLes r√©sultats qu‚Äôil est recommand√© de r√©cup√©rer en m√©moire vive en session R sont de la forme suivante :\n\nune table filtr√©e avec les variables n√©cessaires √† l‚Äô√©tude uniquement : sous MiDAS, toutes les jointures, les calculs de variable et les filtres peuvent √™tre effectu√©s de mani√®re efficiente sous la forme de spark_data_frame, sans jamais collecter les donn√©es MiDAS ;\ndes statistiques descriptives synth√©tiques ;\nles premi√®res lignes de la table pour v√©rifier que le programme retourne bien le r√©sultat attendu ;\nune table agr√©g√©e pour un graphique par exemple, √† l‚Äôaide de la fonction summarise()."
  },
  {
    "objectID": "slides_v.html#programmer-sans-collecter-2",
    "href": "slides_v.html#programmer-sans-collecter-2",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Programmer sans collecter",
    "text": "Programmer sans collecter\nJe sais que la cr√©ation de ma table donne le r√©sultat souhait√©e (car j‚Äôai regard√© ce dont elle a l‚Äôair avvec head()), maintenant je vais l‚Äôappeler une dizaine de fois pour collecter uniquement des statistiques descriptives.\nQue se passe-t-il √† chaque fois que je collecte une statistique descriptive ?\n\nLa cr√©ation de la table va √™tre ex√©cut√©e √† nouveau : tr√®s long ?\nComment faire ?\n\nCachePersist\n\n\nLa cr√©ation de la table est ex√©cut√©e une seule fois, le r√©sultat est conserv√© en m√©moire vive\n\nma_table_spark <- MMO_2017 %>%\n  filter(DebutCTT > as.Date(\"2017-06-01\")) %>%\n  mutate(duree_CTT = DATEDIFF(FinCTT,DebutCTT) + 1) %>%\n  sdf_register(name = \"ma_table_spark\")\n\ntbl_cache(\"ma_table_spark\")\n\n\n\nLa cr√©ation de la table est ex√©cut√©e une seule fois, le r√©sultat est conserv√© sur le disque\n\nma_table_spark <- MMO_2017 %>%\n  filter(DebutCTT > as.Date(\"2017-06-01\")) %>%\n  mutate(duree_CTT = DATEDIFF(FinCTT,DebutCTT) + 1) %>%\n  sdf_persist(storage.level = \"DISK_ONLY\")\n\ntbl_cache(\"ma_table_spark\")\n\n\n\n\n\nR√©ponse attendue : c‚Äôest une action donc ca d√©clenche la cr√©ation de la table Indice : cr√©ation de table contient uniquement des transformations"
  },
  {
    "objectID": "slides_v.html#mode-local-sch√©ma",
    "href": "slides_v.html#mode-local-sch√©ma",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mode local : sch√©ma",
    "text": "Mode local : sch√©ma"
  },
  {
    "objectID": "slides_v.html#mode-local-√†-√©viter",
    "href": "slides_v.html#mode-local-√†-√©viter",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Mode local : √† √©viter",
    "text": "Mode local : √† √©viter\nEn mode local :\n\nles ressources utilis√©es sont celles de la bulle uniquement : bloque les autres utilisateurs\nil faut allouer suffisamment de coeurs √† la JVM pour parall√©liser\nm√™me si l‚Äôutilisateur choisit des ressources faibles, les ressources r√©elles utilis√©es dans une session spark peuvent √™tre plus √©lev√©es : mauvaise gestion de l‚Äôallocation des ressources entre utilisateurs\nacc√©l√©ration sensible par rapport √† un mode de programmation classique s√©quentiel sur un unique coeur si beaucoup de ressources\nSur la bulle CASD, mauvaise gestion de la r√©partition des ressources en spark local : l‚Äôutilisation simultan√©e de spark par plusieurs membres de la bulle entra√Ænent des ralentissements consid√©rables\n‚ñ∂Ô∏èmode local √† √©viter absolument"
  },
  {
    "objectID": "slides_v.html#catalyst-optimise-le-code-pour-nous",
    "href": "slides_v.html#catalyst-optimise-le-code-pour-nous",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Catalyst optimise le code pour nous",
    "text": "Catalyst optimise le code pour nous\nLe driver contient un programme nomm√© Catalyst qui optimise le code scala automatiquement.\nSpark optimise automatiquement les programmes soumis :\n\nCompilation des transformations pour soulever les √©ventuelles erreurs\nInt√©gration dans un plan d‚Äôex√©cution contenant les √©tapes n√©cessaires pour parvenir au r√©sultat demand√© par le programme\nOptimisation du plan logique par le module Catalyst (driver Spark)\n\n\n\n\n\n\n\nLes erreurs en sparklyr\n\n\nPetite pr√©cision sur les erreurs :\n\nsparklyr traduit le code R en scala\nmais √©galement les messages envoy√©s par spark en R\nles erreurs affich√©es en R ne sont pas toujours bien interpr√©tables"
  },
  {
    "objectID": "slides_v.html#catalyst-optimise-le-code-pour-nous-1",
    "href": "slides_v.html#catalyst-optimise-le-code-pour-nous-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Catalyst optimise le code pour nous",
    "text": "Catalyst optimise le code pour nous"
  },
  {
    "objectID": "slides_v.html#catalyst-optimise-le-code-pour-nous-2",
    "href": "slides_v.html#catalyst-optimise-le-code-pour-nous-2",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Catalyst optimise le code pour nous",
    "text": "Catalyst optimise le code pour nous\nPar exemple si j‚Äô√©cris le programme :\n\nnon_optimal <- table_1 %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))\n\n\nCatalyst r√©√©crit :\n\n\noptimal <- table_1 %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\")) %>%   \n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat))\n\nCette optimisation est r√©alis√©e sur toutes les transformations compil√©e avant qu‚Äôune action d√©clenche l‚Äôex√©cution."
  },
  {
    "objectID": "slides_v.html#catalyst-optimise-le-code-pour-nous-laissons-le-travailler",
    "href": "slides_v.html#catalyst-optimise-le-code-pour-nous-laissons-le-travailler",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Catalyst optimise le code pour nous : laissons-le travailler !",
    "text": "Catalyst optimise le code pour nous : laissons-le travailler !\nD√©clencher le moins d‚Äôactions possibles dans son programme permet de tirer pleinement parti de Catalyst et de gagner un temps certain.\nPour profiter des avantages de spark, la mani√®re de programmer recommand√©e est diff√©rente de celle pr√©dominante en R classique. On √©vite quoi ?\n\nOn √©vite :\n\nde mettre des collect()sur chaque table interm√©diaire\nde collect() une table enti√®re\nde print() √† chaque √©tape\n\n\n\nSinon Catalyst n‚Äôa pas assez de code pour optimiser !"
  },
  {
    "objectID": "slides_v.html#et-ensuite",
    "href": "slides_v.html#et-ensuite",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Et ensuite ?",
    "text": "Et ensuite ?\nSpark est un outil de traitement de donn√©es volumineuses. Il n‚Äôest pas toujours adapt√© :\n\npour de toutes petites tables : il ne va pas engendrer de gain de temps\npour faire de l‚Äô√©conom√©trie pouss√©e : tous les packages R ne sont pas traduits en spark\npour ouvrir sa table : on perd les avantages de spark si on collecte toute la table en m√©moire RAM\n\nConseils :\n\nCr√©er sa table d‚Äô√©tude en appariant les tables de MiDAS avec le cluster spark\nL‚Äôexporter sous HDFS\nLa t√©l√©charger en local\nLa charger en R classique pour faire de l‚Äô√©conom√©trie"
  },
  {
    "objectID": "slides_v.html#catalyst-optimise-le-code-pour-nous-laissons-le-travailler-1",
    "href": "slides_v.html#catalyst-optimise-le-code-pour-nous-laissons-le-travailler-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Catalyst optimise le code pour nous : laissons-le travailler !",
    "text": "Catalyst optimise le code pour nous : laissons-le travailler !\n\nnon_optimal <- table_1 %>% \n    collect() %>%\n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))\n\n\nversus\n\nnon_optimal <- table_1 %>% \n    collect() %>%\n    mutate(duree_contrat = DATEDIFF(fin_contrat, debut_contrat)) %>%   \n    filter(debut_contrat >= as.Date(\"2023-01-01\"))"
  },
  {
    "objectID": "slides_v.html#le-stockage-distribu√©-avec-hdfs-1",
    "href": "slides_v.html#le-stockage-distribu√©-avec-hdfs-1",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Le stockage distribu√© avec HDFS",
    "text": "Le stockage distribu√© avec HDFS\nHadoop Distributed File System (HDFS)\n\nstockage sur diff√©rentes machines : les diff√©rents ordinateurs workers du cluster\ndonn√©es divis√©es en blocs plus petits de taille fixe et r√©partis sur les machines : aucune table de MiDAS n‚Äôexiste en entier sur le cluster\nchaque bloc est r√©pliqu√© trois fois : il existe trois fois les 10 premi√®res lignes de la table FNA sur trois ordinateurs diff√©rents du cluster (r√©silience)\nun NameNode supervise les m√©tadonn√©es et g√®re la structure du syst√®me de fichiers : il sait o√π sont quels fichiers\nles DataNodes stockent effectivement les blocs de donn√©es : les datanodes sont en fait les disques durs des workers du cluster, chaque ordinateur du cluster dispose d‚Äôun disque avec une partie des donn√©es MiDAS\nle syst√®me HDFS est reli√© √† la bulle Midares : possible de charger des donn√©es en clique-bouton de la bulle vers HDFS de mani√®re tr√®s rapide et de t√©l√©charger des tables de HDFS pour les r√©cup√©rer en local"
  },
  {
    "objectID": "slides_v.html#jointures-un-cas-particulier",
    "href": "slides_v.html#jointures-un-cas-particulier",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Jointures : un cas particulier",
    "text": "Jointures : un cas particulier\nPour effectuer ce type de jointure avec deux tables de volum√©tries diff√©rentes : A est petite, B est tr√®s volumineuse\n\nSolution rapide :\n\ntable_finale <- table_volumineuse_comme_PJC %>%\n  right_join(petite_table_mon_champ)\n\nSolution lente :\n\ntable_finale <- petite_table_mon_champ %>%\n  left_join(table_volumineuse_comme_PJC)"
  },
  {
    "objectID": "slides_v.html#optimiser-la-m√©moire-conclusion",
    "href": "slides_v.html#optimiser-la-m√©moire-conclusion",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Optimiser la m√©moire : conclusion",
    "text": "Optimiser la m√©moire : conclusion\nPour programmer en spark sans aucune erreur :\n\nD√©clencher une action avec plusieurs transformations pour laisser Catalyst optimiser\nNe pas collecter tout une table\nPersister ou cacher une table qu‚Äôon va appeler plusieurs fois pour ne collecter que des statistiques descriptives\nNe pas persister trop de tables : occupe de la m√©moire RAM\nConsulter le programme exemple sur la bulle CASD si besoin"
  },
  {
    "objectID": "slides_v.html#yarn-.smaller-.-scrollable",
    "href": "slides_v.html#yarn-.smaller-.-scrollable",
    "title": "Initiation √† Spark avec R en mode cluster",
    "section": "Yarn {.smaller . scrollable}",
    "text": "Yarn {.smaller . scrollable}\n\nyarn : disponibilit√© des ressources\n\nSparkhistory pour des traitements de sessions ferm√©es\n\nLe sparkhistory entra√Æne l‚Äôenregistrement de logs assez lourdes, il est donc d√©sactiv√© par d√©faut. Pour l‚Äôactiver sur un programme :\n\nconf <- spark_config()\nconf[\"spark.eventLog.enabled\"] <- \"true\"\nconf[\"spark.eventLog.dir\"] <- \"hdfs://midares-deb11-nn-01.midares.local:9000/spark-logs\"\nconf[\"appName\"] <- \"un_nom_de_traitement\"\n\nsc <- spark_connect(master = \"yarn\", config = conf)"
  }
]