---
title: "Bonnes pratiques"
---

# Les bonnes pratiques ü§ù

## Mode local : inadapt√© et mauvaise pratique {.smaller}

![](images/mode_local.PNG)

<br>

Spark et le mode local :

-   un seul ordinateur alors que spark est fait pour **plusieurs ordinateurs** distincts

-   beaucoup **moins de ressources** disponibles sur la bulle que sur le cluster

-   mauvaise gestion de l'allocation des ressources entre utilisateurs : **pas faite pour plusieurs utilisateurs**

-   ralentissements consid√©rables et bugs : **bloque les autres utilisateurs**

    ‚ñ∂Ô∏èspark n'est adapt√© que pour le cluster de calcul, la bulle pour faire du R sans spark sur des donn√©es peu volumineuses

## Utiliser les configuratoins recommand√©es {.smaller}

![](images/reduce_distribue.drawio.png){fig-align="center"}

Les ordinateurs du cluster ont besoin de **s'envoyer des donn√©es par le r√©seau** : c'est la partie la plus lente d'un programme spark !

Si j'augmente les ressources : par exemple, je r√©serve 3 ordinateurs du cluster plut√¥t que 2

1.  **Effet puissance de calcul** : plus de ressources pour faire les calculs = r√©duction du temps de calcul

2.  **Effet augmentation des √©changes r√©seau (shuffles)** : augmentation du temps de calcul

3.  **G√™ne des autre utilisateurs**

## Ne pas collecter {.smaller}

::: callout-note
## Collecter, c'est quoi ?

Collecter c'est utiliser l'instruction `collect()`. Elle permet de rapatrier l'ensemble des r√©sultats du cluster vers la bulle et la session R de l'utilisateur en format R, par exemple des `data.frames`.

`Collect()` :

1.  est une **action** : elle d√©clencher tous les calculs

2.  implique des **√©changes r√©seau** tr√®s importants : entre ordinateurs du cluster et du cluster vers la bulle : c'est extr√™mement long, moins efficient que l'enregistrement sur disque directement depuis spark

3.  rappatrie les r√©sultats (une table) dans la m√©moire vive de R, qui est sur la bulle : si le r√©sultat est volumineux, cela **bloque les autres utilisateurs**
:::

Recommandations :

-   Ne pas collecter des tables de plus de 15 Go

-   Utiliser les autres m√©thodes propos√©es pour ne pas bloquer les utilisateurs qui ont besoin de R en mode classique

-   Ne pas changer les configurations

## Fermer sa session {.smaller}


Il faut imp√©rativement fermer sa session spark apr√®s une session de travail. Deux moyens pour √ßa :

-   fermer R Studio

-   si on ne ferme pas RStudio, utiliser la fonction `spark_disconnect_all()` dans son code

Si on souhaite lancer un code le soir en partant, on n'oublie pas le `spark_disconnect_all()` √† la fin du code.

::: callout-warning
## Partage des ressources

Les ressources r√©serv√©s par un utilisateur ne sont lib√©r√©es pour les autres que lorsqu'il se d√©connecte. Ne pas se d√©connecter, c'est bloquer les ressources. Si j'ai r√©serv√© deux ordinateurs du cluster sur 15, personne d'autres ne peut les r√©server tant que je n'ai pas d√©connecter ma session spark.

Nous fermerons les sessions ouvertes trop longtemps (d√©part de cong√©s sans d√©connexion) si des utilisateurs pr√©sents en ont besoin : risque de perte du travail non enregistr√©.
:::


Pour ne pas bloquer les coll√®gues üë®‚Äçüíª

## Yarn {.smaller}

Yarn permet de consulter la r√©servation des ressources par les utilisateurs.

On peut y acc√©der en copiant le lien suivant dans Google chrome sur la bulle (mettre en favori) : midares-deb11-nn-01.midares.local:8088/cluster

V√©rifier que notre session est ferm√©e et qu'on ne prend pas trop de ressources : **yarn**

![](images/yarn_scheduler.PNG)

## Mutualiser les exp√©riences {.smaller}

-   Aide au passage d'un code sur le cluster

-   Programmer entre coll√®gues

-   Contributions √† la documentation MiDAS : section fiches, √† l'aide de pull requests sur github

![](images/documentation_midas_fiches.PNG){fig-align="center"}