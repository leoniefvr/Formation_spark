---
title: "Out of memory"
---

# Comment √©conomiser de la m√©moire RAM (et du temps) ?

## Collecter le moins possible ü§è

-   L'export direct d'un spark data frame en parquet est quasiment instantann√© : tu peux ensuite charger la table parquet en data frame R si tu souhaites la traiter en m√©moire vive.

-   Cet export direct n'est pas fonctionnel en spark local : encore une raison de passer sur le cluster Spark !

-   Si le `collect()`est in√©vitable, il faut que la m√©moire RAM allou√©e au driver soit assez importante pour r√©cup√©rer le r√©sultat : elle est param√©trable avec l'option `spark.driver.memory` de la configuration spark. Lorsque tu utilises une session sparklyr, le driver est dans la bulle Midares, donc th√©oriquement la limite physique de RAM que tu peux allouer au driver correspond √† la taille de bulle (mais d'autres coll√®gues auront aussi besoin de ces ressources).

## Eviter les fonctions sp√©cifiques √† sparklyr ‚ö†Ô∏è

-   Si tu as utilis√© des fonctions telles que `compute()` dans ton programme, elles peuvent √™tre √† l'origine d'une erreur `Out of memory` : ces commandes ne sont pas bien adapt√©es √† Spark et les r√©sultats temporaires stock√©s en m√©moire vive ne sont pas visibles dans l'espace d√©di√© sur SparkUI onglet Storage, il semblerait que ces r√©sultats temporaires soient stock√©s "au mauvais endroit" et occupent de l'espace sans que l'utilisateur y ait acc√®s.

-   Privil√©gier les fonctions `tbl_cache()` pour forcer l'ex√©cution du programme.

## Laisser Spark travailler pour nous üíª

-   Forcer l'ex√©cution du programme le plus tard possible pour permettre √† Spark d'optimiser tout le programme et d'utiiliser les ressources de la mani√®re la plus parcimonieuse possible.

-   Tester son programme sur une toute petite partie des tables, √©tape par √©tape, en for√ßant l'ex√©cution (appel d'une action telle que `print()` ou `collect()` ) √† chaque √©tape pour la phase de d√©buggage, puis supprimer toutes les actions interm√©diaires non n√©cessaires du programme pour que Spark optimise tout le programme.

## Optimiser le chargement en cache des donn√©es üíø

-   Si une table est charg√©e avec la fonction `spark_read_parquet(sc, path = "mon_chemin_vers_la_table", memory = FALSE)` et l'option `memory=FALSE` , les donn√©es ne seront charg√©es du disque √† la m√©moire cache qu'en cas de n√©cessit√©, c'est-√†-dire si une action d√©clenche des transformations qui utilisent une partie de ces donn√©es.

-   Charger une table en cache avec `memory = TRUE` force la mise en cache de toutes les partitions de cette table, ce qui immobilise des ressources et peut favoriser la survenue d'erreurs `Ouf of memory`. Si cette table n'est pas utilis√©e en totalit√© plusieurs fois dans le programme, ce chargement n'est pas optimal.

-   S'il s'av√®re optimal de charger les donn√©es en cache, alors il faut donner √† chaque ex√©cuteur une quantit√© de m√©moire vive suffisante pour laisser des ressources pour l'ex√©cution.

-   Pour consulter la taille des donn√©es charg√©es en cache, utiliser **SparkUI, onglet Storage.**

## Si tout ceci ne fonctionne pas : augmenter les ressources dans la configuration

Par souci de parcimonie et pour faciliter le travail de nos coll√®gues sur des ressources partag√©es, cette option doit rester l'ultime recours pour √©viter l'erreur `Out of memory` ü§ù
