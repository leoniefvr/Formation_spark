---
title: "Out of memory"
---

# Comment √©conomiser de la m√©moire RAM (et du temps) ?

## Collecter le moins possible ü§è

-   L'export direct d'un spark data frame en parquet sur HDFS est une meilleure alternative : tu peux ensuite charger la table parquet en data frame R si tu souhaites la traiter en m√©moire vive. 

-   Contrairement au `collect()`, quelle que soit la taille de la table, exporter sous HDFS ne renverra jamais d'erreur, tandis que le `collect()`ne fonctionne pas pour les tables volumineuses.

-   Cet export direct n'est pas fonctionnel en spark local : encore une raison de passer sur le cluster Spark !

-   Si tu souhaites voir ta table, tu peux collecter les premi√®res lignes de celle-ci en combinant les fonctions `head()`et `collect()`.

## Eviter les fonctions arrow ‚ö†Ô∏è

-   Si tu as utilis√© des fonctions telles que `compute()` dans ton programme, elles peuvent √™tre √† l'origine d'une erreur `Out of memory` : ces commandes ne sont pas bien adapt√©es √† Spark et les r√©sultats temporaires stock√©s en m√©moire vive ne sont pas visibles dans l'espace d√©di√© sur SparkUI onglet Storage, il semblerait que ces r√©sultats temporaires soient stock√©s "au mauvais endroit" et occupent de l'espace sans que l'utilisateur y ait acc√®s.

-   Privil√©gier les fonctions `tbl_cache()` avec `sdf_register()`pour forcer l'ex√©cution du programme.

## Laisser Spark travailler pour nous üíª

-   Forcer l'ex√©cution du programme le plus tard possible pour permettre √† Spark d'optimiser tout le programme et d'utiiliser les ressources de la mani√®re la plus parcimonieuse possible.

-   Tester son programme sur une toute petite partie des tables, √©tape par √©tape, en for√ßant l'ex√©cution (appel d'une action telle que `print()` ou `collect()` ) √† chaque √©tape pour la phase de d√©buggage, puis supprimer toutes les actions interm√©diaires non n√©cessaires du programme pour que Spark optimise tout le programme.


## Si tout ceci ne fonctionne pas : passer √† la configuration traitement tr√®s lourd

Par souci de parcimonie et pour faciliter le travail de nos coll√®gues sur des ressources partag√©es, cette option doit rester l'ultime recours pour √©viter l'erreur `Out of memory` ü§ù
